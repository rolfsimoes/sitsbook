\documentclass[a4paper,]{tufte-book}

% ams
\usepackage{amssymb,amsmath}

\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \makeatletter
  \@ifpackageloaded{fontspec}{}{\usepackage{fontspec}}
  \makeatother
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
  \makeatletter
  \@ifpackageloaded{soul}{
     \renewcommand\allcapsspacing[1]{{\addfontfeature{LetterSpace=15}#1}}
     \renewcommand\smallcapsspacing[1]{{\addfontfeature{LetterSpace=10}#1}}
   }{}
  \makeatother

\fi

% graphix
\usepackage{graphicx}
\setkeys{Gin}{width=\linewidth,totalheight=\textheight,keepaspectratio}

% booktabs
\usepackage{booktabs}

% url
\usepackage{url}

% hyperref
\usepackage{hyperref}

% units.
\usepackage{units}


\setcounter{secnumdepth}{2}

% citations
\usepackage{natbib}
\bibliographystyle{apalike}


% pandoc syntax highlighting
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\newenvironment{Shaded}{}{}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{#1}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}

% longtable
\usepackage{longtable,booktabs}

% multiplecol
\usepackage{multicol}

% strikeout
\usepackage[normalem]{ulem}

% morefloats
\usepackage{morefloats}


% tightlist macro required by pandoc >= 1.14
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

% title / author / date
\title{\textbf{sits}: Data Analysis and Machine Learning for Data Cubes using Satellite Image Time Series}
\author{Rolf Simoes \and Gilberto Camara \and Felipe Souza \and Lorena Santos \and Pedro R. Andrade \and Alexandre Carvalho \and Karine Ferreira \and Gilberto Queiroz}
\date{2021-03-31}

\lstset{
  breaklines=true
}

\begin{document}

\maketitle



{
\setcounter{tocdepth}{1}
\tableofcontents
}

\hypertarget{preface}{%
\chapter*{Preface}\label{preface}}
\addcontentsline{toc}{chapter}{Preface}

Using time series derived from big Earth Observation data sets is one of the leading research trends in Land Use Science and Remote Sensing. One of the more promising uses of satellite time series is its application to classify land use and land cover since our growing demand for natural resources has caused significant environmental impacts.

This book presents the \textbf{sits}, an open-source R package for satellite image time series analysis. The package supports the application of machine learning techniques for classification image time series obtained from data cubes. Methods available include linear and quadratic discrimination analysis, support vector machines, random forests, boosting, deep learning, and convolution neural. Out of the box, \textbf{sits} also provides functions to post-classification (e.g., spatial bayesian smoothing) and sample evaluation (e.g., self-organizing maps clustering) and more!

So, check it out to learn about satellite image time series analysis and classification using several techniques and methods through \textbf{sits} package.

\hypertarget{who-this-book-is-for}{%
\section*{Who this book is for}\label{who-this-book-is-for}}
\addcontentsline{toc}{section}{Who this book is for}

This book is recommended for all those who wish to learn the main concepts and techniques of time series analysis and classification of remotely sensed images through the \textbf{sits} package. The approach taken by this book is practical, and all examples are designed to be self-contained, making the learning experience more accessible, even for those with minimal programming experience.

\hypertarget{how-to-use-this-book}{%
\section*{How to use this book}\label{how-to-use-this-book}}
\addcontentsline{toc}{section}{How to use this book}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.12}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.88}}@{}}
\toprule
\textbf{Chapter} & \textbf{Description} \\
\midrule
\endhead
\href{https://e-sensing.github.io/sitsbook/introduction.html}{Chr 1} & Provides an overview of the \textbf{sits} packages with some applications. \\
\href{https://e-sensing.github.io/sitsbook/earth-observation-data-cubes.html}{Chr 2} & Describes how to work with Earth observation data cubes in \textbf{sits}. \\
\href{https://e-sensing.github.io/sitsbook/acessing-time-series-information-in-sits.html}{Chr 3} & Describes how to access information from time series in \textbf{sits}. \\
\href{https://e-sensing.github.io/sitsbook/time-series-clustering-to-improve-the-quality-of-training-samples.html}{Chr 4} & Describes the methods and techniques provided by \textbf{sits} to improve the quality of the samples used in traning models \\
\href{https://e-sensing.github.io/sitsbook/machine-learning-for-data-cubes-using-the-sits-package.html}{Chr 5} & Presents the machine learning techniques available in \textbf{sits}. \\
\href{https://e-sensing.github.io/sitsbook/classification-of-images-in-data-cubes-using-satellite-image-time-series.html}{Chr 6} & Describes how to classify satellite images associated with Earth observation data cubes. \\
\href{https://e-sensing.github.io/sitsbook/post-classification-smoothing-using-bayesian-techniques-in-sits.html}{Chr 7} & Describes smoothing method to reclassify the pixels based on the machine learning probabilities \\
\href{https://e-sensing.github.io/sitsbook/validation-and-accuracy-measurements-in-sits.html}{Chr 8} & Presents the validation and accuracy measures available in the \textbf{sits} package. \\
\bottomrule
\end{longtable}

\hypertarget{publications-using-sits}{%
\section*{\texorpdfstring{Publications using \textbf{sits}}{Publications using sits}}\label{publications-using-sits}}
\addcontentsline{toc}{section}{Publications using \textbf{sits}}

This section gathers the publications that have used SITS to generate the results. The list is presented below.

\textbf{2021}

\begin{itemize}
\tightlist
\item
  {[}1{]} Santos, L.A.; Ferreira, K.; Picoli, M.; Camara, G.; Zurita-Milla, R.; Augustijn, E.-W. Identifying Spatiotemporal Patterns in Land Use and Cover Samples from Satellite Image Time Series. Remote Sens. 2021, 13, 974.
\end{itemize}

\textbf{2020}

\begin{itemize}
\item
  {[}2{]} Picoli, M. C. A.; Simoes, R.; Chaves, M.; Santos, L. A.; Sanchez, A.; Soares, A.; Sanches, I. D.; Ferreira, K. R. and Queiroz, G. R.. CBERS Data Cube: A Powerful Technology for Mapping and Monitoring Brazilian Biomes. In: XXIVth International Society for Photogrammery and Remote Sensing (ISPRS) Congress. Virtual Event. August 31 to September 2, 2020.
\item
  {[}3{]} Rolf Simoes, Michelle C. A. Picoli, Gilberto Camara, Adeline Maciel, Lorena Santos, Pedro R. Andrade, Alber Sánchez, Karine Ferreira \& Alexandre Carvalho. Land use and cover maps for Mato Grosso State in Brazil from 2001 to 2017. Sci Data 7, 34 (2020).
\item
  {[}4{]} Picoli, M.C.A.; Rorato, A.; Leitão, P.; Camara, G.; Maciel, A.; Hostert, P.; Sanches, I.D. Impacts of Public and Private Sector Policies on Soybean and Pasture Expansion in Mato Grosso -- Brazil from 2001 to 2017. Land 2020, 9, 20.
\item
  {[}5{]} Ferreira, K.R.; Queiroz, G.R.; Vinhas, L.; Marujo, R.F.B.; Simoes, R.E.O.; Picoli, M.C.A.; Camara, G.; Cartaxo, R.; Gomes, V.C.F.; Santos, L.A.; Sanchez, A.H.; Arcanjo, J.S.; Fronza, J.G.; Noronha, C.A.; Costa, R.W.; Zaglia, M.C.; Zioti, F.; Korting, T.S.; Soares, A.R.; Chaves, M.E.D.; Fonseca, L.M.G. Earth Observation Data Cubes for Brazil: Requirements, Methodology and Products. Remote Sens. 2020, 12, 4033.
\end{itemize}

\textbf{2019}

\begin{itemize}
\item
  {[}6{]} Alber Sanchez, Michelle Picoli, Pedro R. Andrade, Rolf Simões, Lorena Santos, Michel Chaves, Rodrigo Begotti, Gilberto Camara. Land Cover Classifications of Clear-cut Deforestation Using Deep Learning. In: SIMPÓSIO BRASILEIRO DE GEOINFORMÁTICA (GEOINFO), 2019, São José dos Campos. Anais do 20º Simpósio Brasileiro de Geoinformática. São José dos Campos: INPE, 2019. On-line.
\item
  {[}7{]} Lorena Santos, Karine Reis Ferreira, Michelle Picoli, Gilberto Camara. Self-Organizing Maps in Earth Observation Data Cubes Analysis. 13th International Workshop on Self-Organizing Maps and Learning Vector Quantization, Clustering and Data Visualization (WSOM+ 2019), Barcelona, Spain, June 26-28, 2019.
\end{itemize}

\hypertarget{setup}{%
\chapter*{Setup}\label{setup}}
\addcontentsline{toc}{chapter}{Setup}

\textbf{sits} is currently available on \href{https://github.com/e-sensing/sits}{GitHub}. Thus, installing the package can be accomplished via \href{https://cran.r-project.org/web/packages/devtools/index.html}{devtools}, as presented by the code snippet below:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{devtools}\SpecialCharTok{::}\FunctionTok{install\_github}\NormalTok{(}\StringTok{"e{-}sensing/sits"}\NormalTok{, }\AttributeTok{dependencies =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{docker-images}{%
\section*{Docker images}\label{docker-images}}
\addcontentsline{toc}{section}{Docker images}

Installing the \textbf{sits} package has several dependencies that increase its installation and build time. To speed up the use of \textbf{sits} and the required dependencies in the R environment, the \href{https://github.com/brazil-data-cube}{Brazil Data Cube} (BDC) project maintains \href{https://hub.docker.com/r/brazildatacube/sits-rstudio}{Docker images} of the RStudio Server already configured with \textbf{sits}. The command below shows how this image can be used in Docker.

\begin{verbatim}
docker run --detach \
           --publish 127.0.0.1:8787:8787 \
           --name my-sits-rstudio \
           --volume ${PWD}/data:/data \
           brazildatacube/sits-rstudio:1.4.1103 
\end{verbatim}

After the execution of above command, open the URL \texttt{http://127.0.0.1:8787} in a web browser, in order to access the RStudio:

\begin{quote}
firefox \url{http://127.0.0.1:8787}
\end{quote}

\texttt{To\ login\ use\ \textquotesingle{}sits\textquotesingle{}\ as\ user\ and\ password.}

If you prefer a customized build of the SITS Docker images, please, visit the \href{https://github.com/e-sensing/sits}{sits-docker GitHub repository}.

\hypertarget{acknowledgements}{%
\chapter*{Acknowledgements}\label{acknowledgements}}
\addcontentsline{toc}{chapter}{Acknowledgements}

The authors would like to thank all the researchers that provided data samples used in the examples: Alexandre Coutinho, Julio Esquerdo, and Joao Antunes (Brazilian Agricultural Research Agency, Brazil) who provided ground samples for ``soybean-fallow'', ``fallow-cotton'', ``soybean-cotton'', ``soybean-corn'', ``soybean-millet'', ``soybean-sunflower'', and ``pasture'' classes; Rodrigo Bergotti (National Institute for Space Research, Brazil) who provided samples for ``cerrado'' and ``forest'' classes; and Damien Arvor (Rennes University, France) who provided ground samples for ``soybean-fallow'' class.

This work was partially funded by the São Paulo Research Foundation (FAPESP) through the eScience Program grant 2014/08398-6. We thank the Coordination for the Improvement of Higher Education Personnel (CAPES) and National Council for Scientific and Technological Development (CNPq) grants 312151/2014-4 (GC) and 140684/2016-6 (RS). We thank Ricardo Cartaxo and Lúbia Vinhas, who provided insight and expertise to support this work.

This work has also been supported by the International Climate Initiative of the Germany Federal Ministry for the Environment, Nature Conservation, Building and Nuclear Safety under Grant Agreement 17-III-084-Global-A-RESTORE+ (``RESTORE+: Addressing Landscape Restoration on Degraded Land in Indonesia and Brazil'\,').

\hypertarget{part-overview}{%
\part{Overview}\label{part-overview}}

\hypertarget{introduction}{%
\chapter{Introduction}\label{introduction}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

This chapter present a broad overview of \textbf{sits}, showing its main functionality. For detailed description of the functions, please see the following chapters.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Earth observation satellites provide a common and consistent set of information about the planet's land and oceans. Recently, most space agencies have adopted open data policies, making unprecedented amounts of satellite data available for research and operational use. This data deluge has brought about a significant challenge: \emph{How to design and build technologies that allow the Earth observation community to analyze big data sets?}

The approach taken in \textbf{sits} is to develop data analysis methods that work with satellite image time series, obtained by taking calibrated and comparable measures of the same location in Earth at different times. These measures can be obtained by a single sensor (e.g., MODIS) or by combining various sensors (e.g., Landsat 8 and Sentinel-2). If acquired by frequent revisits, these data sets' temporal resolution can capture significant land use changes.

Time series of remote sensing data show that land cover can occur not only progressively and gradually, but they may also show discontinuities with abrupt changes [@Lambin2003]. Analyses of multiyear time series of land surface attributes, their fine-scale spatial pattern, and their seasonal evolution lead to a broader view of land-cover change. Satellite image time series have already been used in applications such as mapping for detecting forest disturbance [@Kennedy2010], ecology dynamics [@Pasquarella2016], agricultural intensification [@Galford2008], and its impacts on deforestation [@Arvor2012]. Algorithms for processing image time series include BFAST for detecting breaks [@Verbesselt2010], TIMESAT for modeling and measuring phenological attributes [@Jonsson2004], and methods based on Dynamic Time Warping (DTW) for land use and land cover classification \citep{Petitjean2012}\citep{Maus2016}.

In this work, we present \textbf{sits}, an open-source R package for satellite image time series analysis. It provides support on how to use machine learning techniques with image time series. These methods include linear and quadratic discrimination analysis, support vector machines, random forests, and neural networks. One important contribution of the package is to support the complete cycle of data analysis for time series classification, including data acquisition, visualization, filtering, clustering, classification, validation, and post-classification adjustments.

Most studies using satellite image time series for land cover classification use a \emph{space-first, time-later} approach. For multiyear studies, most researchers first derive best-fit yearly composites and then classify each composite image \citep{Gomez2016}. As an alternative, the \textbf{sits} package provides support for the classification of time series, preserving the full temporal resolution of the input data, using a \emph{time-first, space-later} approach. The idea is to have as many temporal attributes as possible, increasing the classification space's dimension. Each temporal instance of a time series is taken as an independent dimension in the classifier's feature space. To the authors' best knowledge, the classification techniques for image time series included in the package are not previously available in other R or python packages. Furthermore, the package provides filtering, clustering, and post-processing methods that have not been published in the literature.

Current approaches to image time series analysis still use a limited number of attributes. A common approach is deriving a small set of phenological parameters from vegetation indices, like the beginning, peak, and length of growing season \citep{Brown2013}, \citep{Kastens2017}, \citep{Estel2015}, \citep{Pelletier2016}. These phenological parameters are then fed in specialized classifiers such as TIMESAT \citep{Jonsson2004}. These approaches do not use the power of advanced statistical learning techniques to work on high-dimensional spaces with big training data sets \citep{James2013}. Package \textbf{sits} uses the full depth of satellite image time series to create larger dimensional spaces, an approach we consider to be more appropriate to use with machine learning.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth,height=0.8\textheight]{images/time_series_general_view} 

}

\caption[Using time series for land classification (source]{Using time series for land classification (source: Tan et al., 2017)}\label{fig:unnamed-chunk-5}
\end{figure}

\hypertarget{workflow}{%
\section{Workflow}\label{workflow}}

The main aim of \textbf{sits} is to support land cover and land change classification of image data cubes using machine learning methods. The basic workflow is:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Create a data cube using analysis-ready-data image collections available in the cloud or local machines.
\item
  Extract time series from the data cube, which is used as training data.
\item
  Perform quality control and filtering on the samples.
\item
  Train a machine learning model using the extracted samples.
\item
  Classify the data cube using the trained model.
\item
  Smoothen the probability data to reduce classification noise.
\item
  Post-process the classified images.
\end{enumerate}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth,height=0.8\textheight]{images/sits_workflow} 

}

\caption[Workflow of using satellite image time series for classification]{Workflow of using satellite image time series for classification}\label{fig:unnamed-chunk-6}
\end{figure}

\hypertarget{handling-data-cubes-in-sits}{%
\section{\texorpdfstring{Handling Data Cubes in \textbf{sits}}{Handling Data Cubes in sits}}\label{handling-data-cubes-in-sits}}

Currently, \textbf{sits} supports data cubes available in the following cloud services:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Sentinel-2/2A level 2A images in Amazon Web Services (AWS);
\item
  Collections of Sentinel, Landsat, and CBERS images in the Brazil Data Cube (BDC);
\item
  Collections available in Digital Earth Africa;
\item
  Data cubes produced by the \href{https://github.com/appelmar/gdalcubes}{gdalcubes package};
\item
  Local image collections.
\end{enumerate}

In order, to access different STAC cloud services supported by \textbf{sits}, the \href{http://github.com/brazil-data-cube/rstac}{rstac} package is used. This package is developed under the Brazil Data Cube project and provides features for consuming STAC services. Besides, the \href{https://github.com/cloudyr/aws.s3}{aws.s3} package is used to access data in AWS.

The use of different providers in the \textbf{sits} package is done with as few change as possible for users. The user can define a data cube by selecting a cloud service collection and determining a space-time extent. The code below shows the definition of a data cube using AWS Sentinel-2/2A images to exemplify how it is used.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{s2\_cube }\OtherTok{\textless{}{-}} \FunctionTok{sits\_cube}\NormalTok{(}
    \AttributeTok{source        =} \StringTok{"AWS"}\NormalTok{,}
    \AttributeTok{name          =} \StringTok{"T20LKP\_2018\_2019"}\NormalTok{,}
    \AttributeTok{collection    =} \StringTok{"sentinel{-}s2{-}l2a"}\NormalTok{,}
    \AttributeTok{bands         =} \FunctionTok{c}\NormalTok{(}\StringTok{"B08"}\NormalTok{, }\StringTok{"SCL"}\NormalTok{),}
    \AttributeTok{tiles         =} \StringTok{"20LKP"}\NormalTok{,}
    \AttributeTok{start\_date    =} \FunctionTok{as.Date}\NormalTok{(}\StringTok{"2018{-}07{-}18"}\NormalTok{),}
    \AttributeTok{end\_date      =} \FunctionTok{as.Date}\NormalTok{(}\StringTok{"2018{-}08{-}18"}\NormalTok{),}
    \AttributeTok{s2\_resolution =} \DecValTok{60}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

In the above example, the user has selected the ``Sentinel-2 Level 2'' collection in the AWS cloud services. The data cube's geographical area is defined by the tile ``20LKP'' and the temporal extent by a start and end date. Access to other cloud services works in similar ways (See Chapter 2 for more details),

To define a data cube using plain files (without STAC information), all image files should have the same spatial resolution and same projection. Each file contains a single image band for a single date. Timeline and bands are deduced from filenames. For example, \texttt{CBERS-4\_AWFI\_B13\_2018-02-02.tif} is a valid name. The user has to provide parsing information to allow \textbf{sits} to extract the band and the date. In the example above, the parsing info is \texttt{c("X1",\ "X2",\ "band",\ "date")} and the delimiter is \texttt{"\_"}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(sits)}
\CommentTok{\# Create a cube based on a stack of CBERS data}
\NormalTok{data\_dir }\OtherTok{\textless{}{-}} \FunctionTok{system.file}\NormalTok{(}\StringTok{"extdata/raster/cbers"}\NormalTok{, }\AttributeTok{package =} \StringTok{"sits"}\NormalTok{)}

\CommentTok{\# files are named using the convention }
\CommentTok{\# "CBERS{-}4\_AWFI\_B13\_2018{-}02{-}02.tif"}
\NormalTok{cbers\_cube }\OtherTok{\textless{}{-}} \FunctionTok{sits\_cube}\NormalTok{(}
      \AttributeTok{source =} \StringTok{"LOCAL"}\NormalTok{,}
      \AttributeTok{name =} \StringTok{"022024"}\NormalTok{,}
      \AttributeTok{satellite =} \StringTok{"CBERS{-}4"}\NormalTok{,}
      \AttributeTok{sensor =} \StringTok{"AWFI"}\NormalTok{,}
      \AttributeTok{data\_dir =}\NormalTok{ data\_dir,}
      \AttributeTok{delim =} \StringTok{"\_"}\NormalTok{,}
      \AttributeTok{parse\_info =} \FunctionTok{c}\NormalTok{(}\StringTok{"X1"}\NormalTok{, }\StringTok{"X2"}\NormalTok{, }\StringTok{"band"}\NormalTok{, }\StringTok{"date"}\NormalTok{)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
#> Loading required namespace: terra
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# print the timeline of the cube}
\FunctionTok{sits\_timeline}\NormalTok{(cbers\_cube)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
#>  [1] "2018-02-02" "2018-02-18" "2018-03-06" "2018-03-22" "2018-04-07"
#>  [6] "2018-04-23" "2018-05-09" "2018-05-25" "2018-06-10" "2018-06-26"
#> [11] "2018-07-12" "2018-07-28" "2018-08-13" "2018-08-29"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# print the bounding box of the cube}
\FunctionTok{sits\_bbox}\NormalTok{(cbers\_cube)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
#>    xmin    xmax    ymin    ymax 
#> 5794837 5798037 9773148 9776348
\end{verbatim}

\hypertarget{handling-satellite-image-time-series-in-sits}{%
\section{\texorpdfstring{Handling satellite image time series in \textbf{sits}}{Handling satellite image time series in sits}}\label{handling-satellite-image-time-series-in-sits}}

\hypertarget{data-structure}{%
\subsection{Data structure}\label{data-structure}}

Training a machine learning model in \textbf{sits} requires a set of time series describing properties in spatio-temporal locations of interest. This set consists of samples provided by experts that take \emph{in-situ} field observations or recognize land classes using high-resolution images for land use classification. The package can also be used for any type of classification, provided that the timeline and bands of the time series (used for training) match that of the data cubes.

The package uses a \texttt{sits\ tibble} to organize time series data with associated spatial information for handling time series. A \texttt{tibble} is a generalization of a \texttt{data.frame}, the usual way in \emph{R} to organize data in tables. Tibbles is part of the \texttt{tidyverse}, a collection of R packages designed to work together in data manipulation \citep{Wickham2017}. As an example of how the \textbf{sits} tibble works, the following code shows the first three lines of a tibble containing \(1,218\) labeled samples of land cover in the Mato Grosso state of Brazil, with four classes: ``Forest'', ``Cerrado'', ``Pasture'', ``Soybean-Corn''.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# data set of samples}
\FunctionTok{data}\NormalTok{(}\StringTok{"samples\_modis\_4bands"}\NormalTok{)}
\NormalTok{samples\_modis\_4bands[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{3}\NormalTok{,]}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{r|r|l|l|l|l|l}
\hline
longitude & latitude & start\_date & end\_date & label & cube & time\_series\\
\hline
-55.1852 & -10.8378 & 2013-09-14 & 2014-08-29 & Pasture & MOD13Q1 & 15962.0000, 15978.0000, 15994.0000, 16010.0000, 16026.0000, 16042.0000, 16058.0000, 16071.0000, 16087.0000, 16103.0000, 16119.0000, 16135.0000, 16151.0000, 16167.0000, 16183.0000, 16199.0000, 16215.0000, 16231.0000, 16247.0000, 16263.0000, 16279.0000, 16295.0000, 16311.0000, 0.3880, 0.4905, 0.5273, 0.6599, 0.6772, 0.2029, 0.7937, 0.8157, 0.7970, 0.4309, 0.1526, 0.8542, 0.7004, 0.7187, 0.7061, 0.6677, 0.6056, 0.5041, 0.4937, 0.4405, 0.4166, 0.4273, 0.4422, 0.2526, 0.2772, 0.3181, 0.3978, 0.4665, 0.2329, 0.5712, 0.7405, 0.7487, 0.4233, 0.1825, 0.5057, 0.5388, 0.5325, 0.4537, 0.4526, 0.3624, 0.2952, 0.2928, 0.2635, 0.2708, 0.2684, 0.2841, 0.3160, 0.2747, 0.2857, 0.2953, 0.3653, 0.5106, 0.3626, 0.5440, 0.5409, 0.4630, 0.5286, 0.2862, 0.4251, 0.3862, 0.3223, 0.3443, 0.2834, 0.2806, 0.2806, 0.2889, 0.3264, 0.3048, 0.3243, 0.3067, 0.1697, 0.2050, 0.1036, 0.1051, 0.1885, 0.0507, 0.1027, 0.1393, 0.1852, 0.2035, 0.0837, 0.1087, 0.1134, 0.0882, 0.1171, 0.1340, 0.1370, 0.1685, 0.1545, 0.1979, 0.1861, 0.2239\\
\hline
-57.7940 & -9.7573 & 2006-09-14 & 2007-08-29 & Pasture & MOD13Q1 & 13405.0000, 13421.0000, 13437.0000, 13453.0000, 13469.0000, 13485.0000, 13501.0000, 13514.0000, 13530.0000, 13546.0000, 13562.0000, 13578.0000, 13594.0000, 13610.0000, 13626.0000, 13642.0000, 13658.0000, 13674.0000, 13690.0000, 13706.0000, 13722.0000, 13738.0000, 13754.0000, 0.4995, 0.4853, 0.7161, 0.4954, 0.5911, 0.4336, 0.7336, 0.7390, 0.6233, 0.7968, 0.7982, 0.6780, 0.7543, 0.5025, 0.7458, 0.7291, 0.6806, 0.5938, 0.5018, 0.5389, 0.4645, 0.4401, 0.3101, 0.2628, 0.3299, 0.3968, 0.3277, 0.4332, 0.3501, 0.4445, 0.5015, 0.4148, 0.5498, 0.5334, 0.5951, 0.4949, 0.3667, 0.3904, 0.5442, 0.4495, 0.3701, 0.3019, 0.3172, 0.2490, 0.2370, 0.1898, 0.2298, 0.3585, 0.2642, 0.2691, 0.4001, 0.3420, 0.2948, 0.3478, 0.2944, 0.3547, 0.3637, 0.4540, 0.3335, 0.4540, 0.2384, 0.3793, 0.3294, 0.3092, 0.2825, 0.2757, 0.2366, 0.2341, 0.2488, 0.1392, 0.1608, 0.0757, 0.1194, 0.1722, 0.1113, 0.0784, 0.0887, 0.0875, 0.0634, 0.0707, 0.0813, 0.0758, 0.1130, 0.0437, 0.0947, 0.0918, 0.1136, 0.1339, 0.1293, 0.1493, 0.1529, 0.1774\\
\hline
-51.9412 & -13.4198 & 2014-09-14 & 2015-08-29 & Pasture & MOD13Q1 & 16327.0000, 16343.0000, 16359.0000, 16375.0000, 16391.0000, 16407.0000, 16423.0000, 16436.0000, 16452.0000, 16468.0000, 16484.0000, 16500.0000, 16516.0000, 16532.0000, 16548.0000, 16564.0000, 16580.0000, 16596.0000, 16612.0000, 16628.0000, 16644.0000, 16660.0000, 16676.0000, 0.3504, 0.3446, 0.3636, 0.4292, 0.5162, 0.4245, 0.6604, 0.6164, 0.5804, 0.6514, 0.6199, 0.6333, 0.6976, 0.7649, 0.7348, 0.6831, 0.6303, 0.5559, 0.4813, 0.4133, 0.3700, 0.3444, 0.3262, 0.1936, 0.1640, 0.2185, 0.2518, 0.4155, 0.3602, 0.4269, 0.4031, 0.3760, 0.3619, 0.3734, 0.3547, 0.4689, 0.4729, 0.4865, 0.3867, 0.3490, 0.2668, 0.2376, 0.1973, 0.1849, 0.1877, 0.1807, 0.2345, 0.1976, 0.2852, 0.2717, 0.3601, 0.3659, 0.3237, 0.3127, 0.3262, 0.2525, 0.2809, 0.2557, 0.3532, 0.3094, 0.3317, 0.2640, 0.2629, 0.2008, 0.2088, 0.2060, 0.2227, 0.2539, 0.2510, 0.2047, 0.1522, 0.1979, 0.1830, 0.1650, 0.1840, 0.1257, 0.1437, 0.1575, 0.1275, 0.1436, 0.1113, 0.1021, 0.0725, 0.0957, 0.0988, 0.1069, 0.1273, 0.1512, 0.1356, 0.1519, 0.1671, 0.2102\\
\hline
\end{tabular}

A \texttt{sits\ tibble} contains data and metadata. The first six columns contain the metadata: spatial and temporal information, the label assigned to the sample, and the data cube from where the data has been extracted. The spatial location is given in longitude and latitude coordinates for the ``WGS84'' ellipsoid. For example, the first sample has been labeled ``Pasture'' at location (\(-55.1852\), \(-10.8378\)) and is valid for the period (2013-09-14, 2014-08-29). The \texttt{time\_series} column contains the actual data.

\hypertarget{obtaining-time-series-data}{%
\subsection{Obtaining time series data}\label{obtaining-time-series-data}}

To get a time series in \textbf{sits}, first is must necessarily create a data cube. Users can request one or more time series points from a data cube using \texttt{sits\_get\_data()}. This function provides a general means of access to image time series. Given data cue, the user provides the latitude and longitude of the desired location, the bands, and the start date and end date of the time series. If the start and end dates are not provided, it retrieves all the available periods. The result is a tibble that can be visualized using \texttt{plot()}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(sits)}
\NormalTok{data\_dir }\OtherTok{\textless{}{-}} \FunctionTok{system.file}\NormalTok{(}\StringTok{"extdata/raster/mod13q1"}\NormalTok{, }\AttributeTok{package =} \StringTok{"sits"}\NormalTok{)}
\NormalTok{modis\_cube }\OtherTok{\textless{}{-}} \FunctionTok{sits\_cube}\NormalTok{(}
    \AttributeTok{source =} \StringTok{"LOCAL"}\NormalTok{,}
    \AttributeTok{name =} \StringTok{"sinop{-}2014"}\NormalTok{,}
    \AttributeTok{satellite =} \StringTok{"TERRA"}\NormalTok{,}
    \AttributeTok{sensor =} \StringTok{"MODIS"}\NormalTok{,}
    \AttributeTok{data\_dir =}\NormalTok{ data\_dir,}
    \AttributeTok{delim =} \StringTok{"\_"}\NormalTok{,}
    \AttributeTok{parse\_info =} \FunctionTok{c}\NormalTok{(}\StringTok{"X1"}\NormalTok{, }\StringTok{"X2"}\NormalTok{, }\StringTok{"band"}\NormalTok{, }\StringTok{"date"}\NormalTok{)}
\NormalTok{)}

\CommentTok{\# obtain a set of locations defined by a CSV file}
\NormalTok{csv\_raster\_file }\OtherTok{\textless{}{-}} \FunctionTok{system.file}\NormalTok{(}\StringTok{"extdata/samples/samples\_sinop\_crop.csv"}\NormalTok{,}
                               \AttributeTok{package =} \StringTok{"sits"}\NormalTok{)}

\CommentTok{\# retrieve the points from the data cube}
\NormalTok{points }\OtherTok{\textless{}{-}} \FunctionTok{sits\_get\_data}\NormalTok{(modis\_cube, }\AttributeTok{file =}\NormalTok{ csv\_raster\_file)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
#> Loading required namespace: terra
#> Loading required namespace: terra
\end{verbatim}

\begin{verbatim}
#> All points have been retrieved
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# plot the first point}
\FunctionTok{plot}\NormalTok{(points[}\DecValTok{1}\NormalTok{,])}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{sitsbook_files/figure-latex/unnamed-chunk-10-1} 

}

\caption[A one year time series of MOD13Q1 data for bands NDVI and EVI]{A one year time series of MOD13Q1 data for bands NDVI and EVI}\label{fig:unnamed-chunk-10}
\end{figure}

\hypertarget{filtering-techniques}{%
\section{Filtering techniques}\label{filtering-techniques}}

The literature on satellite image time series has several filtering applications to correct or smooth vegetation index data. The following filters are available in \textbf{sits}. They are described in more detail in the vignette ``Satellite Image Time Series Filtering with SITS'':

\begin{itemize}
\tightlist
\item
  Savitzky--Golay filter (\texttt{sits\_sgolay})
\item
  Whittaker filter (\texttt{sits\_whittaker})
\item
  Envelope filter (\texttt{sits\_envelope})
\end{itemize}

The \textbf{sits} package uses a common interface to all filter functions with the \texttt{sits\_filter}. The function has two parameters: the \texttt{dataset} to be filtered and the \texttt{filter} function applied. To aid in data visualization, all filtered bands have a suffix that is appended, as shown in the examples below. Here we show an example using the Whittaker smoother, proposed in the literature \citep{Atzberger2011} as arguably the most appropriate one to use for satellite image time series. The Whittaker smoother attempts to fit a curve representing the raw data but is penalized if subsequent points vary too much \citep{Atzberger2011}. It balances between the residual to the original data and the ``smoothness'' of the fitted curve. It uses the parameter \texttt{lambda} to control the degree of smoothing.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Take a NDVI time series, apply Whittaker filter and plot the series}
\NormalTok{point\_ndvi }\OtherTok{\textless{}{-}} \FunctionTok{sits\_select}\NormalTok{(point\_mt\_6bands, }\AttributeTok{bands =} \StringTok{"NDVI"}\NormalTok{)}
\NormalTok{point\_whit }\OtherTok{\textless{}{-}} \FunctionTok{sits\_whittaker}\NormalTok{(point\_ndvi, }\AttributeTok{lambda =} \FloatTok{5.0}\NormalTok{)}

\CommentTok{\# merge with original data and plot the original and the filtered data}
\NormalTok{point\_whit }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{sits\_merge}\NormalTok{(point\_ndvi) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{plot}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{sitsbook_files/figure-latex/unnamed-chunk-11-1} 

}

\caption[Whittaker smoother filter applied on one-year NDVI time series]{Whittaker smoother filter applied on one-year NDVI time series. The example uses default $\lambda=3$ parameter.}\label{fig:unnamed-chunk-11}
\end{figure}

\hypertarget{clustering-for-sample-quality-control-using-self-organizing-maps}{%
\section{Clustering for sample quality control using self-organizing maps}\label{clustering-for-sample-quality-control-using-self-organizing-maps}}

One of the key challenges of machine learning classification models is assessing the training data sets' quality. It helps apply pre-processing methods to improve the samples' quality and remove those that might have been wrongly labeled or have low discriminatory power. Good samples lead to good classification maps. \textbf{sits} provides support for two clustering methods to test sample quality: (a) Agglomerative Hierarchical Clustering (AHC); (b) Self-organizing Maps (SOM). Full details of the cluster methods used in \textbf{sits} are available in the vignette \href{https://github.com/e-sensing/sits-docs/blob/master/doc/clustering.pdf}{`Clustering of Satellite Image Time Series with SITS'}.

\hypertarget{classification-using-machine-learning}{%
\section{Classification using machine learning}\label{classification-using-machine-learning}}

There has been much recent interest in using classifiers such as support vector machines \citep{Mountrakis2011} and random forests \citep{Belgiu2016} for remote sensing images. Most often, researchers use a \emph{space-first, time-later} approach. The dimension of the decision space is limited to the number of spectral bands or their transformations. Sometimes, the decision space is extended with temporal attributes. To do this, researchers filter the raw data to get smoother time series \citep{Brown2013, Kastens2017}. Using software such as TIMESAT \citep{Jonsson2004}, they derive a small set of phenological parameters from vegetation indexes, like the beginning, peak, and length of the growing season \citep{Estel2015, Pelletier2016}.

In a recent review of machine learning methods to classify remote sensing data \citep{Maxwell2018}, the authors note that many factors influence these classifiers' performance, including the size and quality of the training dataset dimension of the feature space and the choice of the parameters.

\textbf{sits} provides functionality to explore the full depth of satellite image time series data, treating time series as a feature vector. The idea is to have as many temporal attributes as possible, increasing the classification space's dimension. In this scenario, statistical learning models are the natural candidates to deal with high-dimensional data: learning to distinguish all land cover and land use classes from trusted samples exemplars (the training data) to infer classes of a larger data set.

There is a common interface to all machine learning models, using the \texttt{sits\_train} function. This function takes two parameters: the input samples and the ML method (\texttt{ml\_method}), as shown below. After the model is estimated, it can classify individual time series or full data cubes using the \texttt{sits\_classify} function. In the examples that follow, we show how to apply each method to classify a single time series. The trained model is then used to classify a time series from Mato Grosso Brazilian state, using \texttt{sits\_classify}. The results can be shown in text format using the function \texttt{sits\_show\_prediction} or graphically using the \texttt{plot} function.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#select the data for classification}

\CommentTok{\# Train a machine learning model using Random Forest}
\NormalTok{rfor\_model }\OtherTok{\textless{}{-}} \FunctionTok{sits\_train}\NormalTok{(}\AttributeTok{data =}\NormalTok{ samples\_modis\_4bands, }
                    \AttributeTok{ml\_method =} \FunctionTok{sits\_rfor}\NormalTok{(}\AttributeTok{num\_trees =} \DecValTok{1000}\NormalTok{))}

\CommentTok{\# get a point to be classified}
\NormalTok{point\_4bands }\OtherTok{\textless{}{-}} \FunctionTok{sits\_select}\NormalTok{(point\_mt\_6bands, }
                            \AttributeTok{bands =} \FunctionTok{c}\NormalTok{(}\StringTok{"NDVI"}\NormalTok{, }\StringTok{"EVI"}\NormalTok{, }\StringTok{"NIR"}\NormalTok{, }\StringTok{"MIR"}\NormalTok{))}

\CommentTok{\# Classify using random forest model and plot the result}
\NormalTok{class }\OtherTok{\textless{}{-}} \FunctionTok{sits\_classify}\NormalTok{(point\_4bands, rfor\_model)}
\CommentTok{\# plot the results of the prediction}
\FunctionTok{plot}\NormalTok{(class)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{sitsbook_files/figure-latex/unnamed-chunk-12-1} 

}

\caption[Random forest classification of a $16$ years time series]{Random forest classification of a $16$ years time series. The location (latitude, longitude) shown at the top of the graph is in geographic coordinate system (WGS84 {\it datum}).}\label{fig:unnamed-chunk-12}
\end{figure}

The following methods are available in \textbf{sits} for training machine learning models:

\begin{itemize}
\tightlist
\item
  Linear discriminant analysis (\texttt{sits\_lda})
\item
  Quadratic discriminant analysis (\texttt{sits\_qda})
\item
  Multinomial logit and its variants `lasso' and `ridge' (\texttt{sits\_mlr})
\item
  Support vector machines (\texttt{sits\_svm})
\item
  Random forests (\texttt{sits\_rfor})
\item
  Extreme gradient boosting (\texttt{sits\_xgboost})
\item
  Deep learning (DL) using multi-layer perceptrons (\texttt{sits\_deeplearning})
\item
  DL with 1D convolutional neural networks (\texttt{sits\_CNN}),
\item
  DL combining 1D CNN and multi-layer perceptron networks (\texttt{sits\_tempCNN})
\item
  DL using 1D version of ResNet (\texttt{sits\_ResNet}).
\item
  DL using a combination of long-short term memory (LSTM) and 1D CNN (\texttt{sits\_LSTM\_FCN})
\end{itemize}

For more details on each method, please see Chapter 5.

\hypertarget{validation-techniques}{%
\section{Validation techniques}\label{validation-techniques}}

Validation is a process undertaken on models to estimate some errors associated with them. Hence, it has been used widely in different scientific disciplines. Here, we are interested in assessing the prediction error associated with some models. For this purpose, we concentrate on the \emph{cross-validation} approach, probably the most used validation technique \citep{Hastie2009}. \texttt{sits\_kfold\_validate()} supports the k-fold validation in \textbf{sits}. The following code gives an example of how to proceed \emph{k-fold cross-validation} in the package. It performs a five-fold validation using the SVM classification model as a default classifier. We can see in the output text the corresponding confusion matrix and the accuracy statistics (overall and by class).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# perform a five fold validation for the "cerrado\_2classes" data set}
\CommentTok{\# Random Forest machine learning method using default parameters}
\NormalTok{acc }\OtherTok{\textless{}{-}} \FunctionTok{sits\_kfold\_validate}\NormalTok{(cerrado\_2classes, }
                           \AttributeTok{folds =} \DecValTok{5}\NormalTok{, }
                           \AttributeTok{ml\_method =} \FunctionTok{sits\_rfor}\NormalTok{(}\AttributeTok{num\_trees =} \DecValTok{1000}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\hypertarget{cube-classification}{%
\section{Cube classification}\label{cube-classification}}

To classify a data cube, use the function \texttt{sits\_classify()} as described below. Once a data cube that has associated files is defined, the steps for classification are:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Select a set of training samples;
\item
  Train a machine learning model;
\item
  Classify the data cubes using the model, producing a data cube with class probabilities;
\item
  Label the cube with probabilities, including data smoothing if desired.
\end{enumerate}

To reduce processing time, it is necessary to adjust \texttt{sits\_classify()} according to the server's capabilities. The package tries to keep memory use to a minimum, performing garbage collection to free memory as often as possible. Nevertheless, there is an inevitable trade-off between computing time, memory use, and I/O operations. The best trade-off must be determined by the user, considering disk read speed, number of cores in the server, and CPU performance.

The first parameter is \texttt{memsize}. It controls the size of the main memory (in GBytes) to be used for classification. The second factor controlling the performance of raster classification is \texttt{multicores}, which specifies the number of cores are assigned to classification.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Retrieve the set of samples for the Mato Grosso region }
\CommentTok{\# Select the data for classification}
\NormalTok{samples\_2bands  }\OtherTok{\textless{}{-}} \FunctionTok{sits\_select}\NormalTok{(samples\_modis\_4bands, }
                               \AttributeTok{bands =} \FunctionTok{c}\NormalTok{(}\StringTok{"NDVI"}\NormalTok{, }\StringTok{"EVI"}\NormalTok{))}

\CommentTok{\# build a machine learning model for this area}
\NormalTok{svm\_model }\OtherTok{\textless{}{-}} \FunctionTok{sits\_train}\NormalTok{(samples\_2bands, }\FunctionTok{sits\_svm}\NormalTok{())}

\CommentTok{\# create a data cube to be classified}
\CommentTok{\# Cube is composed of MOD13Q1 images from the Sinop region in Mato Grosso (Brazil)}
\NormalTok{data\_dir }\OtherTok{\textless{}{-}} \FunctionTok{system.file}\NormalTok{(}\StringTok{"extdata/raster/mod13q1"}\NormalTok{, }\AttributeTok{package =} \StringTok{"sits"}\NormalTok{)}
\NormalTok{sinop }\OtherTok{\textless{}{-}} \FunctionTok{sits\_cube}\NormalTok{(}
    \AttributeTok{source =} \StringTok{"LOCAL"}\NormalTok{,}
    \AttributeTok{name =} \StringTok{"sinop{-}2014"}\NormalTok{,}
    \AttributeTok{satellite =} \StringTok{"TERRA"}\NormalTok{,}
    \AttributeTok{sensor =} \StringTok{"MODIS"}\NormalTok{,}
    \AttributeTok{data\_dir =}\NormalTok{ data\_dir,}
    \AttributeTok{parse\_info =} \FunctionTok{c}\NormalTok{(}\StringTok{"X1"}\NormalTok{, }\StringTok{"X2"}\NormalTok{, }\StringTok{"band"}\NormalTok{, }\StringTok{"date"}\NormalTok{)}
\NormalTok{)}
\CommentTok{\# Classify the raster cube, generating a probability file}
\NormalTok{probs\_cube }\OtherTok{\textless{}{-}} \FunctionTok{sits\_classify}\NormalTok{(sinop, }
                            \AttributeTok{ml\_model =}\NormalTok{ svm\_model, }
                            \AttributeTok{output\_dir =} \FunctionTok{tempdir}\NormalTok{(),}
                            \AttributeTok{memsize =} \DecValTok{16}\NormalTok{,}
                            \AttributeTok{multicores =} \DecValTok{4}\NormalTok{,}
                            \AttributeTok{verbose =} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
#> Loading required namespace: terra
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# plot the probabilities cubes}
\FunctionTok{plot}\NormalTok{(probs\_cube)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{sitsbook_files/figure-latex/unnamed-chunk-14-1} 

}

\caption[Class probabilities for each pixel]{Class probabilities for each pixel}\label{fig:unnamed-chunk-14}
\end{figure}

\hypertarget{smoothing-and-labelling-of-raster-data-after-classification}{%
\section{Smoothing and Labelling of raster data after classification}\label{smoothing-and-labelling-of-raster-data-after-classification}}

Doing post-processing using Bayesian smoothing in \textbf{sits} is straightforward. The result of the \texttt{sits\_classify} function applied to a data cube is a set of more probability images, one per requested classification interval. The next step is to use the \texttt{sits\_smooth} function. By default, this function selects the most likely class for each pixel, using a Bayesian estimator that considers the neighbors. The following example takes the previously produced classification output and applies a Bayesian smoothing.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# smooth the result with a bayesian filter}
\NormalTok{sinop\_bayes }\OtherTok{\textless{}{-}} \FunctionTok{sits\_smooth}\NormalTok{(probs\_cube, }\AttributeTok{output\_dir =} \FunctionTok{tempdir}\NormalTok{())}
\CommentTok{\# label the resulting image}
\NormalTok{label\_bayes }\OtherTok{\textless{}{-}} \FunctionTok{sits\_label\_classification}\NormalTok{(sinop\_bayes, }\AttributeTok{output\_dir =} \FunctionTok{tempdir}\NormalTok{())}
\CommentTok{\# plot the result}
\FunctionTok{plot}\NormalTok{(label\_bayes)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth,height=0.9\textheight]{sitsbook_files/figure-latex/unnamed-chunk-15-1} 

}

\caption[Classified image post-processed with Bayesian smoothing]{Classified image post-processed with Bayesian smoothing}\label{fig:unnamed-chunk-15}
\end{figure}

\hypertarget{earth-observation-data-cubes}{%
\chapter{Earth observation data cubes}\label{earth-observation-data-cubes}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

This chapter describes how to use Earth observation data cubes in SITS.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{image-data-cubes-as-the-basis-for-big-earth-observation-data-analysis}{%
\section{Image data cubes as the basis for big Earth observation data analysis}\label{image-data-cubes-as-the-basis-for-big-earth-observation-data-analysis}}

In broad terms, the cloud computing model is one where large satellite-generated data sets are archived on cloud services, providing computing facilities to process them. By using cloud services, users can share big Earth observation databases and minimize data download. Investment in infrastructure is minimized, and sharing of data and software increases. However, data available in the cloud is best organised for analysis by creating data cubes.

Generalizing \citet{Appel2019}, we consider that a data cube is a four-dimensional structure with dimensions x (longitude or easting), y (latitude or northing), time, and bands. Its spatial dimensions refer to a single spatial reference system (SRS). Cells of a data cube have a constant spatial size (concerning the cube's SRS). A set of intervals specifies the temporal dimension. For every combination of dimensions, a cell has a single value. Data cubes are particularly amenable for machine learning techniques; their data can be transformed into arrays in memory, fed to training and classification algorithms. Given the widespread availability of large data sets of Earth observation data, there is a growing interest in organising large data sets into ``data cubes''.

\hypertarget{using-stac-to-access-image-data-cubes}{%
\section{Using STAC to Access Image Data Cubes}\label{using-stac-to-access-image-data-cubes}}

One of the distinguishing features of \textbf{sits} is that it has been designed to work with big satellite image data sets which reside on the cloud and with data cubes. Many \emph{R} packages working with remote sensing images require data to be accessible in a local computer. However, with the coming of age of big Earth observation data, it is not always practical to transfer large data sets. Users have to rely on web services to provide access to these data sets. In this context, \textbf{sits} is based on access to data cubes using the information provided by STAC (Spatio-temporal Access Catalogue).

\hypertarget{accessing-data-cubes-in-amazon-web-services}{%
\section{Accessing data cubes in Amazon Web Services}\label{accessing-data-cubes-in-amazon-web-services}}

Users who have access to Amazon Web Services (AWS) can access image collections
available in the `Earth on AWS' services using \textbf{sits}. For AWS, \textbf{sits} currently
only works with collection ``s2\_l2a''. This will be extended in later packages.

To work with AWS, users need to provide credentials using environment variables.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{Sys.setenv}\NormalTok{(}
    \StringTok{"AWS\_ACCESS\_KEY\_ID"}     \OtherTok{=} \ErrorTok{\textless{}}\NormalTok{your\_access\_key}\SpecialCharTok{\textgreater{}}\NormalTok{,}
    \StringTok{"AWS\_SECRET\_ACCESS\_KEY"} \OtherTok{=} \ErrorTok{\textless{}}\NormalTok{your\_secret\_access\_key}\SpecialCharTok{\textgreater{}}\NormalTok{,}
    \StringTok{"AWS\_DEFAULT\_REGION"}    \OtherTok{=} \ErrorTok{\textless{}}\NormalTok{your AWS region}\SpecialCharTok{\textgreater{}}\NormalTok{,}
    \StringTok{"AWS\_ENDPOINT"} \OtherTok{=} \StringTok{"sentinel{-}s2{-}l2a.s3.amazonaws.com"}\NormalTok{,}
    \StringTok{"AWS\_REQUEST\_PAYER"}     \OtherTok{=} \StringTok{"requester"}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Note that Sentinel-2/2A level 2A files in AWS are organized by sensor resolution.
The AWS bands in 10m resolution are ``B02'', ``B03'', ``B04'', and ``B08''.
The 20m bands are ``B02'', ``B03'', ``B04'', ``B05'', ``B06'', ``BO7'', B08``,''B8A``,''B11``, and''B12".
All 12 bands are available at 60m resolution.
For creating data cubes from Sentinel-2/2A, users also have to specify
the \texttt{s2\_resolution} parameter, as shown in the following example.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# creating a data cube in AWS}
\NormalTok{s2\_cube }\OtherTok{\textless{}{-}} \FunctionTok{sits\_cube}\NormalTok{(}\AttributeTok{source =} \StringTok{"AWS"}\NormalTok{,}
                     \AttributeTok{name =} \StringTok{"T20LKP\_2018\_2019"}\NormalTok{,}
                     \AttributeTok{collection =} \StringTok{"sentinel{-}s2{-}l2a"}\NormalTok{,}
                     \AttributeTok{tiles =} \FunctionTok{c}\NormalTok{(}\StringTok{"20LKP"}\NormalTok{,}\StringTok{"20LLP"}\NormalTok{),}
                     \AttributeTok{start\_date =} \FunctionTok{as.Date}\NormalTok{(}\StringTok{"2018{-}07{-}18"}\NormalTok{),}
                     \AttributeTok{end\_date =} \FunctionTok{as.Date}\NormalTok{(}\StringTok{"2018{-}07{-}23"}\NormalTok{),}
                     \AttributeTok{s2\_resolution =} \DecValTok{20}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

In the above example, the user has selected two Sentinel-2A tiles following the
S2A tiling system. Each S2A tile is an 100x100 km2 orthoimage in UTM/WGS84 projection.

\hypertarget{accessing-data-cubes-in-the-brazil-data-cube}{%
\section{Accessing data cubes in the Brazil Data Cube}\label{accessing-data-cubes-in-the-brazil-data-cube}}

The Brazil Data Cube \footnote{ \url{http://brazildatacube.org/} } (BDC) is being developed by Brazil's National Institute for Space Research (INPE). Its goal is to create multidimensional data cubes of analysis-ready data from medium-resolution EO images for all Brazil.

The organization of data cubes in BDC is based on a spatial partition of the territory. This partition is represented by a grid of tiles where every pixel can be efficiently located within a tile. Considering the spatial resolution of the images and aimed at maintaining files that can be easily manageable, three hierarchical grids were defined using an Albers Equal Area projection and SIRGAS 2000 datum. The three grids are generated taking -54 longitude as the central reference and defining tiles of \(6\times4\), \(3\times2\) and \(1.5\times1\) degrees, referred as \emph{BDC\_LG} (large), \emph{BDC\_MD} (medium) and \emph{BDC\_SM} (small),

\begin{figure}

{\centering \includegraphics[width=0.5\linewidth,height=0.5\textheight]{images/bdc_grid} 

}

\caption[Hierarchical BDC tiling system showing overlayed on Brazilian Biomes (a), illustrating that one large tile (b) contains four medium tiles (c) and that medium tile contains four small tiles]{Hierarchical BDC tiling system showing overlayed on Brazilian Biomes (a), illustrating that one large tile (b) contains four medium tiles (c) and that medium tile contains four small tiles}\label{fig:unnamed-chunk-19}
\end{figure}

The large grid is composed by tiles of approximately \(672\times440\)\textasciitilde km and is used to organize CBERS-4 AWFI collections, each tile represents an image of \(10,504\times6,865\) pixels. The medium grid is used in the Landsat-8 OLI collections, the tiles have an extension of 336 x 220 kilometers and images of 11,204 x 7,324 pixels. The small grid present tiles of approximately 168 x 110 kilometers and is used on Sentinel-2 MSI collections (10m), with images of 16,806 x 10,986 pixels.

To access BDC, users need to provide their credentials using environmental variables.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{Sys.setenv}\NormalTok{(}
    \StringTok{"BDC\_ACCESS\_KEY"} \OtherTok{=} \ErrorTok{\textless{}}\NormalTok{your\_bdc\_access\_key}\SpecialCharTok{\textgreater{}}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Creating a data cube using the BDC is similar to what is required for AWS. The user
needs to specific the image collection. In the example, we have selected the
``CB4\_64\_16D\_STK-1'' collection (CBERS AWFI images at 16 days) that complies with
the BDC large tile specification. Other collections include ``LC8\_30\_16D\_STK-1''
(Landsat OLI images at 16 days) and ``S2\_10\_16D\_STK-1'' (Sentinel-2 MSI images
at 16 days).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cbers\_tile }\OtherTok{\textless{}{-}} \FunctionTok{sits\_cube}\NormalTok{(}
    \AttributeTok{source =} \StringTok{"BDC"}\NormalTok{,}
    \AttributeTok{collection =} \StringTok{"CB4\_64\_16D\_STK{-}1"}\NormalTok{,}
    \AttributeTok{name =} \StringTok{"cbers\_022024"}\NormalTok{,}
    \AttributeTok{bands =} \FunctionTok{c}\NormalTok{(}\StringTok{"NDVI"}\NormalTok{, }\StringTok{"EVI"}\NormalTok{),}
    \AttributeTok{tiles =} \StringTok{"022024"}\NormalTok{,}
    \AttributeTok{start\_date =} \StringTok{"2018{-}09{-}01"}\NormalTok{,}
    \AttributeTok{end\_date =} \StringTok{"2019{-}08{-}28"}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{defining-a-data-cube-using-files}{%
\section{Defining a data cube using files}\label{defining-a-data-cube-using-files}}

To define a data cube using plain files (without STAC information), all image files should have the same spatial resolution and same projection. Each file contains a single image band for a single date. Since raster files in popular formats (e.g., GeoTiff and JPEG 2000) do not include time information, each file's name needs to include the date and band information. Timeline and bands are deduced from filenames. For example, \texttt{CBERS-4\_AWFI\_B13\_2018-02-02.tif} is a valid name. The user has to provide parsing information to allow \textbf{sits} to extract the band and the date. In the example above, the parsing info is \texttt{c("X1",\ "X2",\ "band",\ "date")} and the delimiter is \texttt{"\_"}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(sits)}
\CommentTok{\# Create a cube based on a stack of CBERS data}
\NormalTok{data\_dir }\OtherTok{\textless{}{-}} \FunctionTok{system.file}\NormalTok{(}\StringTok{"extdata/raster/cbers"}\NormalTok{, }\AttributeTok{package =} \StringTok{"sits"}\NormalTok{)}

\CommentTok{\# files are named using the convention }
\CommentTok{\# "CBERS{-}4\_AWFI\_B13\_2018{-}02{-}02.tif"}
\NormalTok{cbers\_cube }\OtherTok{\textless{}{-}} \FunctionTok{sits\_cube}\NormalTok{(}
      \AttributeTok{source =} \StringTok{"LOCAL"}\NormalTok{,}
      \AttributeTok{name =} \StringTok{"022024"}\NormalTok{,}
      \AttributeTok{satellite =} \StringTok{"CBERS{-}4"}\NormalTok{,}
      \AttributeTok{sensor =} \StringTok{"AWFI"}\NormalTok{,}
      \AttributeTok{data\_dir =}\NormalTok{ data\_dir,}
      \AttributeTok{delim =} \StringTok{"\_"}\NormalTok{,}
      \AttributeTok{parse\_info =} \FunctionTok{c}\NormalTok{(}\StringTok{"X1"}\NormalTok{, }\StringTok{"X2"}\NormalTok{, }\StringTok{"band"}\NormalTok{, }\StringTok{"date"}\NormalTok{)}
\NormalTok{)}

\CommentTok{\# print the timeline of the cube}
\FunctionTok{sits\_timeline}\NormalTok{(cbers\_cube)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
#>  [1] "2018-02-02" "2018-02-18" "2018-03-06" "2018-03-22" "2018-04-07"
#>  [6] "2018-04-23" "2018-05-09" "2018-05-25" "2018-06-10" "2018-06-26"
#> [11] "2018-07-12" "2018-07-28" "2018-08-13" "2018-08-29"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# print the bounding box of the cube}
\FunctionTok{sits\_bbox}\NormalTok{(cbers\_cube)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
#>    xmin    xmax    ymin    ymax 
#> 5794837 5798037 9773148 9776348
\end{verbatim}

\hypertarget{regularizing-data-cubes}{%
\section{Regularizing data cubes}\label{regularizing-data-cubes}}

Users can derive data cubes from ARD data that have pre-defined temporal resolutions. For example, a user may want to define the best Sentinel-2 pixel in a one-month period, as shown below. This can be done in \textbf{sits} by the \texttt{sits\_regularize}, which calls the ``gdalcubes'' package.
For details in gdalcubes, please see \url{https://github.com/appelmar/gdalcubes}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gc\_cube }\OtherTok{\textless{}{-}} \FunctionTok{sits\_regularize}\NormalTok{(}
          \AttributeTok{cube       =}\NormalTok{ s2\_cube,}
          \AttributeTok{name       =} \StringTok{"T20LKP\_2018\_2019\_1M"}\NormalTok{,}
          \AttributeTok{dir\_images =} \FunctionTok{tempdir}\NormalTok{(),}
          \AttributeTok{period     =} \StringTok{"P1M"}\NormalTok{,}
          \AttributeTok{agg\_method =} \StringTok{"median"}\NormalTok{,}
          \AttributeTok{resampling =} \StringTok{"bilinear"}\NormalTok{,}
          \AttributeTok{cloud\_mask =} \ConstantTok{TRUE}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{defining-a-data-cube-using-files-1}{%
\subsection{Defining a data cube using files}\label{defining-a-data-cube-using-files-1}}

To define a data cube using plain files (without STAC information), all image files should have the same spatial resolution and same projection. Each file contains a single image band for a single date. Since raster files in popular formats (e.g., GeoTiff and JPEG 2000) do not include time information, each file's name needs to include the date and band information. Timeline and bands are deduced from filenames. For example, \texttt{CBERS-4\_AWFI\_B13\_2018-02-02.tif} is a valid name. The user has to provide parsing information to allow \textbf{sits} to extract the band and the date. In the example above, the parsing info is \texttt{c("X1",\ "X2",\ "band",\ "date")} and the delimiter is \texttt{"\_"}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(sits)}
\CommentTok{\# Create a cube based on a stack of CBERS data}
\NormalTok{data\_dir }\OtherTok{\textless{}{-}} \FunctionTok{system.file}\NormalTok{(}\StringTok{"extdata/raster/cbers"}\NormalTok{, }\AttributeTok{package =} \StringTok{"sits"}\NormalTok{)}

\CommentTok{\# files are named using the convention }
\CommentTok{\# "CBERS{-}4\_AWFI\_B13\_2018{-}02{-}02.tif"}
\NormalTok{cbers\_cube }\OtherTok{\textless{}{-}} \FunctionTok{sits\_cube}\NormalTok{(}
      \AttributeTok{source =} \StringTok{"LOCAL"}\NormalTok{,}
      \AttributeTok{name =} \StringTok{"022024"}\NormalTok{,}
      \AttributeTok{satellite =} \StringTok{"CBERS{-}4"}\NormalTok{,}
      \AttributeTok{sensor =} \StringTok{"AWFI"}\NormalTok{,}
      \AttributeTok{data\_dir =}\NormalTok{ data\_dir,}
      \AttributeTok{delim =} \StringTok{"\_"}\NormalTok{,}
      \AttributeTok{parse\_info =} \FunctionTok{c}\NormalTok{(}\StringTok{"X1"}\NormalTok{, }\StringTok{"X2"}\NormalTok{, }\StringTok{"band"}\NormalTok{, }\StringTok{"date"}\NormalTok{)}
\NormalTok{)}

\CommentTok{\# print the timeline of the cube}
\FunctionTok{sits\_timeline}\NormalTok{(cbers\_cube)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
#>  [1] "2018-02-02" "2018-02-18" "2018-03-06" "2018-03-22" "2018-04-07"
#>  [6] "2018-04-23" "2018-05-09" "2018-05-25" "2018-06-10" "2018-06-26"
#> [11] "2018-07-12" "2018-07-28" "2018-08-13" "2018-08-29"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# print the bounding box of the cube}
\FunctionTok{sits\_bbox}\NormalTok{(cbers\_cube)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
#>    xmin    xmax    ymin    ymax 
#> 5794837 5798037 9773148 9776348
\end{verbatim}

\hypertarget{working-with-time-series}{%
\chapter{Working with time series}\label{working-with-time-series}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

This chapter describes how to access information from time series in SITS.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{data-structures-for-satellite-time-series}{%
\section{Data structures for satellite time series}\label{data-structures-for-satellite-time-series}}

The \textbf{sits} package requires a set of time series data, describing properties in spatio-temporal locations of interest. For land use classification, this set consists of samples provided by experts that take \emph{in-situ} field observations or recognize land classes using high-resolution images. The package can also be used for any type of classification, provided that the timeline and bands of the time series (used for training) match that of the data cubes.

For handling time series, the package uses a \texttt{sits\ tibble} to organize time series data with associated spatial information. A \texttt{tibble} is a generalization of a \texttt{data.frame}, the usual way in R to organise data in tables. Tibbles are part of the \texttt{tidyverse}, a collection of R packages designed to work together in data manipulation \citep{Wickham2017}. As an example of how the \texttt{sits} tibble works, the following code shows the first three lines of a tibble containing \(1,882\) labelled samples of land cover in Mato Grosso state of Brazil. The samples contain time series extracted from the MODIS MOD13Q1 product from 2000 to 2016, provided every \(16\) days at \(250\)-meter spatial resolution in the Sinusoidal projection. Based on ground surveys and high-resolution imagery, it includes samples of nine classes: ``Forest'', ``Cerrado'', ``Pasture'', ``Soybean-fallow'', ``Fallow-Cotton'', ``Soybean-Cotton'', ``Soybean-Corn'', ``Soybean-Millet'', and ``Soybean-Sunflower''.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# data set of samples}
\FunctionTok{data}\NormalTok{(}\StringTok{"samples\_matogrosso\_mod13q1"}\NormalTok{)}
\NormalTok{samples\_matogrosso\_mod13q1[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{3}\NormalTok{,]}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{r|r|l|l|l|l|l}
\hline
longitude & latitude & start\_date & end\_date & label & cube & time\_series\\
\hline
-55.1852 & -10.8378 & 2013-09-14 & 2014-08-29 & Pasture & MOD13Q1 & 15962.0000, 15978.0000, 15994.0000, 16010.0000, 16026.0000, 16042.0000, 16058.0000, 16071.0000, 16087.0000, 16103.0000, 16119.0000, 16135.0000, 16151.0000, 16167.0000, 16183.0000, 16199.0000, 16215.0000, 16231.0000, 16247.0000, 16263.0000, 16279.0000, 16295.0000, 16311.0000, 0.3880, 0.4905, 0.5273, 0.6599, 0.6772, 0.2029, 0.7937, 0.8157, 0.7970, 0.4309, 0.1526, 0.8542, 0.7004, 0.7187, 0.7061, 0.6677, 0.6056, 0.5041, 0.4937, 0.4405, 0.4166, 0.4273, 0.4422, 0.2526, 0.2772, 0.3181, 0.3978, 0.4665, 0.2329, 0.5712, 0.7405, 0.7487, 0.4233, 0.1825, 0.5057, 0.5388, 0.5325, 0.4537, 0.4526, 0.3624, 0.2952, 0.2928, 0.2635, 0.2708, 0.2684, 0.2841, 0.3160, 0.2747, 0.2857, 0.2953, 0.3653, 0.5106, 0.3626, 0.5440, 0.5409, 0.4630, 0.5286, 0.2862, 0.4251, 0.3862, 0.3223, 0.3443, 0.2834, 0.2806, 0.2806, 0.2889, 0.3264, 0.3048, 0.3243, 0.3067, 0.1697, 0.2050, 0.1036, 0.1051, 0.1885, 0.0507, 0.1027, 0.1393, 0.1852, 0.2035, 0.0837, 0.1087, 0.1134, 0.0882, 0.1171, 0.1340, 0.1370, 0.1685, 0.1545, 0.1979, 0.1861, 0.2239\\
\hline
-57.7940 & -9.7573 & 2006-09-14 & 2007-08-29 & Pasture & MOD13Q1 & 13405.0000, 13421.0000, 13437.0000, 13453.0000, 13469.0000, 13485.0000, 13501.0000, 13514.0000, 13530.0000, 13546.0000, 13562.0000, 13578.0000, 13594.0000, 13610.0000, 13626.0000, 13642.0000, 13658.0000, 13674.0000, 13690.0000, 13706.0000, 13722.0000, 13738.0000, 13754.0000, 0.4995, 0.4853, 0.7161, 0.4954, 0.5911, 0.4336, 0.7336, 0.7390, 0.6233, 0.7968, 0.7982, 0.6780, 0.7543, 0.5025, 0.7458, 0.7291, 0.6806, 0.5938, 0.5018, 0.5389, 0.4645, 0.4401, 0.3101, 0.2628, 0.3299, 0.3968, 0.3277, 0.4332, 0.3501, 0.4445, 0.5015, 0.4148, 0.5498, 0.5334, 0.5951, 0.4949, 0.3667, 0.3904, 0.5442, 0.4495, 0.3701, 0.3019, 0.3172, 0.2490, 0.2370, 0.1898, 0.2298, 0.3585, 0.2642, 0.2691, 0.4001, 0.3420, 0.2948, 0.3478, 0.2944, 0.3547, 0.3637, 0.4540, 0.3335, 0.4540, 0.2384, 0.3793, 0.3294, 0.3092, 0.2825, 0.2757, 0.2366, 0.2341, 0.2488, 0.1392, 0.1608, 0.0757, 0.1194, 0.1722, 0.1113, 0.0784, 0.0887, 0.0875, 0.0634, 0.0707, 0.0813, 0.0758, 0.1130, 0.0437, 0.0947, 0.0918, 0.1136, 0.1339, 0.1293, 0.1493, 0.1529, 0.1774\\
\hline
-51.9412 & -13.4198 & 2014-09-14 & 2015-08-29 & Pasture & MOD13Q1 & 16327.0000, 16343.0000, 16359.0000, 16375.0000, 16391.0000, 16407.0000, 16423.0000, 16436.0000, 16452.0000, 16468.0000, 16484.0000, 16500.0000, 16516.0000, 16532.0000, 16548.0000, 16564.0000, 16580.0000, 16596.0000, 16612.0000, 16628.0000, 16644.0000, 16660.0000, 16676.0000, 0.3504, 0.3446, 0.3636, 0.4292, 0.5162, 0.4245, 0.6604, 0.6164, 0.5804, 0.6514, 0.6199, 0.6333, 0.6976, 0.7649, 0.7348, 0.6831, 0.6303, 0.5559, 0.4813, 0.4133, 0.3700, 0.3444, 0.3262, 0.1936, 0.1640, 0.2185, 0.2518, 0.4155, 0.3602, 0.4269, 0.4031, 0.3760, 0.3619, 0.3734, 0.3547, 0.4689, 0.4729, 0.4865, 0.3867, 0.3490, 0.2668, 0.2376, 0.1973, 0.1849, 0.1877, 0.1807, 0.2345, 0.1976, 0.2852, 0.2717, 0.3601, 0.3659, 0.3237, 0.3127, 0.3262, 0.2525, 0.2809, 0.2557, 0.3532, 0.3094, 0.3317, 0.2640, 0.2629, 0.2008, 0.2088, 0.2060, 0.2227, 0.2539, 0.2510, 0.2047, 0.1522, 0.1979, 0.1830, 0.1650, 0.1840, 0.1257, 0.1437, 0.1575, 0.1275, 0.1436, 0.1113, 0.1021, 0.0725, 0.0957, 0.0988, 0.1069, 0.1273, 0.1512, 0.1356, 0.1519, 0.1671, 0.2102\\
\hline
\end{tabular}

A \texttt{sits\ tibble} contains data and metadata. The first six columns contain the metadata: spatial and temporal information, the label assigned to the sample, and the data cube from where the data has been extracted. The spatial location is given in longitude and latitude coordinates for the ``WGS84'' ellipsoid. For example, the first sample has been labelled "Cerrado, at location (\(-58.5631\), \(-13.8844\)), and is considered valid for the period (2007-09-14, 2008-08-28). Informing the dates where the label is valid is crucial for correct classification. In this case, the researchers involved in labeling the samples chose to use the agricultural calendar in Brazil, where the spring crop is planted in the months of September and October, and the autumn crop is planted in the months of February and March. For other applications and other countries, the relevant dates will most likely be different from those used in the example. The \texttt{time\_series} column contains the time series data for each spatiotemporal location. This data is also organized as a tibble, with a column with the dates and the other columns with the values for each spectral band.

\hypertarget{utilities-for-handling-time-series}{%
\section{Utilities for handling time series}\label{utilities-for-handling-time-series}}

The \textbf{sits} package provides functions for data manipulation and displaying information for \texttt{sits\ tibble}. For example, \texttt{sits\_labels\_summary()} shows the labels of the sample set and their frequencies.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sits\_labels\_summary}\NormalTok{(samples\_matogrosso\_mod13q1)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|r|r}
\hline
label & count & prop\\
\hline
Cerrado & 379 & 0.2003171\\
\hline
Fallow\_Cotton & 29 & 0.0153277\\
\hline
Forest & 131 & 0.0692389\\
\hline
Pasture & 344 & 0.1818182\\
\hline
Soy\_Corn & 364 & 0.1923890\\
\hline
Soy\_Cotton & 352 & 0.1860465\\
\hline
Soy\_Fallow & 87 & 0.0459831\\
\hline
Soy\_Millet & 180 & 0.0951374\\
\hline
Soy\_Sunflower & 26 & 0.0137421\\
\hline
\end{tabular}

In many cases, it is helpful to relabel the data set. For example, there may be situations when one wants to use a smaller set of labels, since samples in one label on the original set may not be distinguishable from samples with other labels. We then could use \texttt{sits\_relabel()}, which requires a conversion list (for details, see \texttt{?sits\_relabel}).

Given that we have used the tibble data format for the metadata and the embedded time series, one can use the functions from \texttt{dplyr}, \texttt{tidyr}, and \texttt{purrr} packages of the \texttt{tidyverse} \citep{Wickham2017} to process the data. For example, the following code uses \texttt{sits\_select()} to get a subset of the sample data set with two bands (NDVI and EVI) and then uses the \texttt{dplyr::filter()} to select the samples labelled either as ``Cerrado'' or ``Pasture''.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# select NDVI band}
\NormalTok{samples\_ndvi }\OtherTok{\textless{}{-}} \FunctionTok{sits\_select}\NormalTok{(samples\_matogrosso\_mod13q1, }
                            \AttributeTok{bands =} \StringTok{"NDVI"}\NormalTok{)}

\CommentTok{\# select only samples with Cerrado label}
\NormalTok{samples\_cerrado }\OtherTok{\textless{}{-}}
\NormalTok{    dplyr}\SpecialCharTok{::}\FunctionTok{filter}\NormalTok{(samples\_ndvi, }
\NormalTok{                  label }\SpecialCharTok{==} \StringTok{"Cerrado"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{time-series-visualisation}{%
\section{Time series visualisation}\label{time-series-visualisation}}

Given a small number of samples to display, \texttt{plot} tries to group as many spatial locations together. In the following example, the first 15 samples of ``Cerrado'' class refer to the same spatial location in consecutive time periods. For this reason, these samples are plotted together.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# plot the first 15 samples}
\FunctionTok{plot}\NormalTok{(samples\_cerrado[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{15}\NormalTok{,])}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{sitsbook_files/figure-latex/cerrado-15-1} \includegraphics[width=0.7\linewidth]{sitsbook_files/figure-latex/cerrado-15-2} 

}

\caption[Plot of the first 'Cerrado' sample from data set]{Plot of the first 'Cerrado' sample from data set}\label{fig:cerrado-15}
\end{figure}

For a large number of samples, where the number of individual plots would be substantial, the default visualization combines all samples together in a single temporal interval (even if they belong to different years). All samples with the same band and label are aligned to a common time interval. This plot is useful to show the spread of values for the time series of each band. The strong red line in the plot shows the median of the values, while the two orange lines are the first and third interquartile ranges. The documentation of \texttt{plot.sits()} has more details about the different ways it can display data.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# plot all cerrado samples together}
\FunctionTok{plot}\NormalTok{(samples\_cerrado)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{sitsbook_files/figure-latex/unnamed-chunk-29-1} 

}

\caption[Plot of all Cerrado samples from data set]{Plot of all Cerrado samples from data set}\label{fig:unnamed-chunk-29}
\end{figure}

\hypertarget{obtaining-time-series-data-from-data-cubes}{%
\section{Obtaining time series data from data cubes}\label{obtaining-time-series-data-from-data-cubes}}

To get a time series in \textbf{sits}, one has to create a data cube first, as described above. Users can request one or more time series points from a data cube by using \texttt{sits\_get\_data()}. This function provides a general means of access to image time series. Given a data cube, the user provides the latitude and longitude of the desired location, the bands, and the start date and end date of the time series. If the start and end dates are not provided, it retrieves all the available periods. The result is a tibble that can be visualized using \texttt{plot()}.

The \textbf{sits} package enables the creation of a data cube based on files. In this case, these files should be organized as \texttt{raster\ stacks}. A raster stack is a single-layer raster object. Each file refers to a one-time instance and one spectral band. To allow users to create data cubes based on files, SITS needs to know the names of satellite and sensor and the directory names that contain the files.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Obtain a raster cube with 23 instances for one year}
\CommentTok{\# Select the band "ndvi", "evi" from images available in the "sitsdata" package}
\NormalTok{data\_dir }\OtherTok{\textless{}{-}} \FunctionTok{system.file}\NormalTok{(}\StringTok{"extdata/sinop"}\NormalTok{, }\AttributeTok{package =} \StringTok{"sitsdata"}\NormalTok{)}

\CommentTok{\# create a raster metadata file based on the information about the files}
\NormalTok{raster\_cube }\OtherTok{\textless{}{-}} \FunctionTok{sits\_cube}\NormalTok{(}
    \AttributeTok{source     =} \StringTok{"LOCAL"}\NormalTok{,}
    \AttributeTok{satellite  =} \StringTok{"TERRA"}\NormalTok{,}
    \AttributeTok{sensor     =} \StringTok{"MODIS"}\NormalTok{,}
    \AttributeTok{name       =} \StringTok{"Sinop"}\NormalTok{,}
    \AttributeTok{data\_dir   =}\NormalTok{ data\_dir,}
    \AttributeTok{parse\_info =} \FunctionTok{c}\NormalTok{(}\StringTok{"X1"}\NormalTok{, }\StringTok{"X2"}\NormalTok{, }\StringTok{"band"}\NormalTok{, }\StringTok{"date"}\NormalTok{),}
\NormalTok{)}

\CommentTok{\# a point in the transition forest to pasture in Northern MT}
\CommentTok{\# obtain a time series from the raster cube for this point}
\NormalTok{series.tb }\OtherTok{\textless{}{-}} \FunctionTok{sits\_get\_data}\NormalTok{(}\AttributeTok{cube      =}\NormalTok{ raster\_cube,}
                           \AttributeTok{longitude =} \SpecialCharTok{{-}}\FloatTok{55.57320}\NormalTok{, }
                           \AttributeTok{latitude  =} \SpecialCharTok{{-}}\FloatTok{11.50566}\NormalTok{,}
                           \AttributeTok{bands     =} \FunctionTok{c}\NormalTok{(}\StringTok{"NDVI"}\NormalTok{, }\StringTok{"EVI"}\NormalTok{))}
\FunctionTok{plot}\NormalTok{(series.tb)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{sitsbook_files/figure-latex/unnamed-chunk-30-1} 

}

\caption[NDVI and EVI time series fetched from local raster cube]{NDVI and EVI time series fetched from local raster cube.}\label{fig:unnamed-chunk-30}
\end{figure}

A useful case is when a set of labelled samples are available to be used as a training data set. In this case, one usually has trusted observations that are labelled and commonly stored in plain text CSV files. Function \texttt{sits\_get\_data()} can get a CSV file path as an argument. The CSV file must provide, for each time series, its latitude and longitude, the start and end dates, and a label associated with a ground sample. An example of a CSV file used is shown below:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# retrieve a list of samples described by a CSV file}
\NormalTok{samples.csv }\OtherTok{\textless{}{-}} \FunctionTok{system.file}\NormalTok{(}\StringTok{"extdata/samples/samples\_sinop\_crop.csv"}\NormalTok{,}
                           \AttributeTok{package =} \StringTok{"sits"}\NormalTok{)}
\CommentTok{\# get the points from a data cube in raster brick format}
\NormalTok{points }\OtherTok{\textless{}{-}} \FunctionTok{sits\_get\_data}\NormalTok{(raster\_cube, }\AttributeTok{file =}\NormalTok{ samples.csv)}


\CommentTok{\# show the tibble with the points}
\NormalTok{points}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{r|r|l|l|l|l|l}
\hline
longitude & latitude & start\_date & end\_date & label & cube & time\_series\\
\hline
-55.65931 & -11.76267 & 2013-09-14 & 2014-08-29 & Pasture & Sinop & 15962.0000, 15978.0000, 15994.0000, 16010.0000, 16026.0000, 16042.0000, 16058.0000, 16071.0000, 16087.0000, 16103.0000, 16119.0000, 16135.0000, 16151.0000, 16167.0000, 16183.0000, 16199.0000, 16215.0000, 16231.0000, 16247.0000, 16263.0000, 16279.0000, 16295.0000, 16311.0000, 0.2106, 0.3169, 0.2674, 0.3430, 0.3897, 0.4803, 0.5254, 0.5254, 0.4680, 0.4708, 0.1790, 0.3151, 0.4756, 0.4006, 0.4509, 0.4284, 0.3551, 0.3730, 0.3146, 0.2480, 0.1967, 0.1883, 0.2211, 0.3386, 0.4327, 0.4608, 0.5664, 0.4799, 0.5867, 0.6543, 0.6543, 0.6912, 0.6439, 0.1721, 0.7537, 0.7299, 0.6144, 0.6653, 0.6510, 0.5940, 0.6135, 0.5229, 0.4271, 0.3451, 0.3182, 0.3272\\
\hline
-55.64833 & -11.76385 & 2013-09-14 & 2014-08-29 & Pasture & Sinop & 15962.0000, 15978.0000, 15994.0000, 16010.0000, 16026.0000, 16042.0000, 16058.0000, 16071.0000, 16087.0000, 16103.0000, 16119.0000, 16135.0000, 16151.0000, 16167.0000, 16183.0000, 16199.0000, 16215.0000, 16231.0000, 16247.0000, 16263.0000, 16279.0000, 16295.0000, 16311.0000, 0.1821, 0.3181, 0.3749, 0.3559, 0.3828, 0.4503, 0.5247, 0.5247, 0.4292, 0.4224, 0.1899, 0.5114, 0.4837, 0.4044, 0.4377, 0.4130, 0.2957, 0.3827, 0.3194, 0.2206, 0.2550, 0.1925, 0.1860, 0.3123, 0.4437, 0.4792, 0.4583, 0.5112, 0.5438, 0.6699, 0.6699, 0.6707, 0.6145, 0.2235, 0.5373, 0.7263, 0.6260, 0.6515, 0.6205, 0.5181, 0.6425, 0.5558, 0.4182, 0.4451, 0.3429, 0.3309\\
\hline
-55.66738 & -11.78032 & 2013-09-14 & 2014-08-29 & Forest & Sinop & 15962.0000, 15978.0000, 15994.0000, 16010.0000, 16026.0000, 16042.0000, 16058.0000, 16071.0000, 16087.0000, 16103.0000, 16119.0000, 16135.0000, 16151.0000, 16167.0000, 16183.0000, 16199.0000, 16215.0000, 16231.0000, 16247.0000, 16263.0000, 16279.0000, 16295.0000, 16311.0000, 0.5536, 0.4968, 0.5135, 0.4770, 0.5706, 0.5779, 0.6282, 0.6282, 0.4847, 0.4121, 0.1624, 0.4525, 0.3854, 0.4338, 0.4575, 0.4302, 0.4053, 0.4036, 0.4098, 0.3976, 0.4292, 0.4671, 0.5526, 0.8204, 0.8025, 0.8601, 0.8928, 0.7993, 0.8830, 0.8442, 0.8442, 0.8314, 0.7653, 0.1876, 0.8417, 0.8159, 0.8936, 0.8430, 0.8233, 0.8315, 0.8170, 0.8280, 0.8152, 0.8042, 0.8297, 0.8163\\
\hline
-55.64747 & -11.75276 & 2013-09-14 & 2014-08-29 & Pasture & Sinop & 15962.0000, 15978.0000, 15994.0000, 16010.0000, 16026.0000, 16042.0000, 16058.0000, 16071.0000, 16087.0000, 16103.0000, 16119.0000, 16135.0000, 16151.0000, 16167.0000, 16183.0000, 16199.0000, 16215.0000, 16231.0000, 16247.0000, 16263.0000, 16279.0000, 16295.0000, 16311.0000, 0.2247, 0.4029, 0.3971, 0.4078, 0.5195, 0.2035, 0.4845, 0.4845, 0.3585, 0.4180, 0.1665, 0.3372, 0.4607, 0.5058, 0.4437, 0.4752, 0.4436, 0.4260, 0.3703, 0.3440, 0.2294, 0.2071, 0.2474, 0.3874, 0.5595, 0.6492, 0.6678, 0.6694, 0.7014, 0.6578, 0.6578, 0.6390, 0.6531, 0.1597, 0.7326, 0.8026, 0.7231, 0.7063, 0.7258, 0.7134, 0.6923, 0.6250, 0.5139, 0.4426, 0.3771, 0.3797\\
\hline
-55.65742 & -11.78788 & 2013-09-14 & 2014-08-29 & Forest & Sinop & 15962.0000, 15978.0000, 15994.0000, 16010.0000, 16026.0000, 16042.0000, 16058.0000, 16071.0000, 16087.0000, 16103.0000, 16119.0000, 16135.0000, 16151.0000, 16167.0000, 16183.0000, 16199.0000, 16215.0000, 16231.0000, 16247.0000, 16263.0000, 16279.0000, 16295.0000, 16311.0000, 0.5605, 0.6484, 0.5080, 0.4875, 0.5068, 0.5846, 0.6460, 0.6460, 0.4688, 0.4296, 0.3878, 0.4737, 0.3844, 0.4489, 0.4821, 0.4359, 0.4216, 0.4441, 0.4362, 0.4189, 0.4753, 0.4872, 0.5718, 0.8162, 0.8565, 0.8462, 0.8888, 0.6586, 0.7573, 0.8503, 0.8503, 0.8795, 0.7667, 0.4833, 0.8732, 0.7963, 0.8960, 0.8481, 0.8143, 0.8338, 0.8358, 0.8320, 0.8230, 0.8246, 0.8289, 0.8176\\
\hline
-55.63168 & -11.74771 & 2013-09-14 & 2014-08-29 & Forest & Sinop & 15962.0000, 15978.0000, 15994.0000, 16010.0000, 16026.0000, 16042.0000, 16058.0000, 16071.0000, 16087.0000, 16103.0000, 16119.0000, 16135.0000, 16151.0000, 16167.0000, 16183.0000, 16199.0000, 16215.0000, 16231.0000, 16247.0000, 16263.0000, 16279.0000, 16295.0000, 16311.0000, 0.5824, 0.5818, 0.8599, 0.5516, 0.6343, 0.4512, 0.6794, 0.6794, 0.5848, 0.5166, 0.1826, 0.5290, 0.4596, 0.5806, 0.5151, 0.4809, 0.4829, 0.4800, 0.4783, 0.4742, 0.5258, 0.5125, 0.5123, 0.8221, 0.7788, 0.8035, 0.9335, 0.8097, 0.7807, 0.8566, 0.8566, 0.8328, 0.7916, 0.1849, 0.5555, 0.9129, 0.8662, 0.8724, 0.8733, 0.8630, 0.8558, 0.8622, 0.8428, 0.8240, 0.8538, 0.8048\\
\hline
-55.68369 & -11.73679 & 2013-09-14 & 2014-08-29 & Soy\_Corn & Sinop & 15962.0000, 15978.0000, 15994.0000, 16010.0000, 16026.0000, 16042.0000, 16058.0000, 16071.0000, 16087.0000, 16103.0000, 16119.0000, 16135.0000, 16151.0000, 16167.0000, 16183.0000, 16199.0000, 16215.0000, 16231.0000, 16247.0000, 16263.0000, 16279.0000, 16295.0000, 16311.0000, 0.2072, 0.2556, 0.2018, 0.3815, 0.7054, 0.7746, 0.9114, 0.9114, 0.4614, 0.3390, 0.1854, 0.3345, 0.6734, 0.7287, 0.5240, 0.4794, 0.2875, 0.1519, 0.1449, 0.2071, 0.1951, 0.1772, 0.1883, 0.3221, 0.4473, 0.3528, 0.6031, 0.7612, 0.9093, 0.9075, 0.9075, 0.7468, 0.4270, 0.2223, 0.4795, 0.8871, 0.8750, 0.7953, 0.7399, 0.5815, 0.3968, 0.3972, 0.3070, 0.3094, 0.2924, 0.2824\\
\hline
-55.69004 & -11.73343 & 2013-09-14 & 2014-08-29 & Soy\_Corn & Sinop & 15962.0000, 15978.0000, 15994.0000, 16010.0000, 16026.0000, 16042.0000, 16058.0000, 16071.0000, 16087.0000, 16103.0000, 16119.0000, 16135.0000, 16151.0000, 16167.0000, 16183.0000, 16199.0000, 16215.0000, 16231.0000, 16247.0000, 16263.0000, 16279.0000, 16295.0000, 16311.0000, 0.3217, 0.3853, 0.2150, 0.4453, 0.6527, 0.7917, 0.8634, 0.8634, 0.4487, 0.3814, 0.1949, 0.5043, 0.6269, 0.6629, 0.4856, 0.4896, 0.3183, 0.2722, 0.2732, 0.2377, 0.2776, 0.2445, 0.2516, 0.4698, 0.5536, 0.4744, 0.6551, 0.7564, 0.9145, 0.9012, 0.9012, 0.7189, 0.4592, 0.2702, 0.8491, 0.8830, 0.8438, 0.7649, 0.7770, 0.6354, 0.5589, 0.5087, 0.3583, 0.4094, 0.3540, 0.3651\\
\hline
-55.67854 & -11.74519 & 2013-09-14 & 2014-08-29 & Soy\_Corn & Sinop & 15962.0000, 15978.0000, 15994.0000, 16010.0000, 16026.0000, 16042.0000, 16058.0000, 16071.0000, 16087.0000, 16103.0000, 16119.0000, 16135.0000, 16151.0000, 16167.0000, 16183.0000, 16199.0000, 16215.0000, 16231.0000, 16247.0000, 16263.0000, 16279.0000, 16295.0000, 16311.0000, 0.1719, 0.4090, 0.2154, 0.3792, 0.7109, 0.6029, 0.8743, 0.8743, 0.4735, 0.2303, 0.1756, 0.4597, 0.6270, 0.6993, 0.5604, 0.4342, 0.2631, 0.1480, 0.1474, 0.1969, 0.1821, 0.1688, 0.1809, 0.3241, 0.5656, 0.3882, 0.6302, 0.7511, 0.8453, 0.9032, 0.9032, 0.7265, 0.4157, 0.1983, 0.6366, 0.8600, 0.8459, 0.7965, 0.6942, 0.5467, 0.3763, 0.3680, 0.2914, 0.2797, 0.2750, 0.2723\\
\hline
-55.64215 & -11.77595 & 2013-09-14 & 2014-08-29 & Soy\_Corn & Sinop & 15962.0000, 15978.0000, 15994.0000, 16010.0000, 16026.0000, 16042.0000, 16058.0000, 16071.0000, 16087.0000, 16103.0000, 16119.0000, 16135.0000, 16151.0000, 16167.0000, 16183.0000, 16199.0000, 16215.0000, 16231.0000, 16247.0000, 16263.0000, 16279.0000, 16295.0000, 16311.0000, 0.2072, 0.4254, 0.1714, 0.0958, 0.4431, 0.4881, 0.9343, 0.9343, 0.5287, 0.6429, 0.1340, 0.2886, 0.2528, 0.2562, 0.7464, 0.6057, 0.5026, 0.5303, 0.4079, 0.2299, 0.2245, 0.2097, 0.2203, 0.3600, 0.6210, 0.3983, 0.3620, 0.5789, 0.7079, 0.9130, 0.9130, 0.8990, 0.8099, 0.1285, 0.3374, 0.4117, 0.4844, 0.8807, 0.8220, 0.7986, 0.8105, 0.7086, 0.4770, 0.4758, 0.4164, 0.3162\\
\hline
-55.63219 & -11.77259 & 2013-09-14 & 2014-08-29 & Soy\_Corn & Sinop & 15962.0000, 15978.0000, 15994.0000, 16010.0000, 16026.0000, 16042.0000, 16058.0000, 16071.0000, 16087.0000, 16103.0000, 16119.0000, 16135.0000, 16151.0000, 16167.0000, 16183.0000, 16199.0000, 16215.0000, 16231.0000, 16247.0000, 16263.0000, 16279.0000, 16295.0000, 16311.0000, 0.2123, 0.2858, 0.2943, 0.4443, 0.6387, 0.8904, 0.8313, 0.8313, 0.1522, 0.4060, 0.1945, 0.6161, 0.6814, 0.6756, 0.5343, 0.4388, 0.2009, 0.1489, 0.1799, 0.1813, 0.1797, 0.1682, 0.1794, 0.3416, 0.4209, 0.3567, 0.7116, 0.7840, 0.9087, 0.8830, 0.8830, 0.3506, 0.4644, 0.1663, 0.8067, 0.8530, 0.8518, 0.7567, 0.6846, 0.4575, 0.3752, 0.3557, 0.3148, 0.3022, 0.2868, 0.2807\\
\hline
-55.62223 & -11.78653 & 2013-09-14 & 2014-08-29 & Soy\_Corn & Sinop & 15962.0000, 15978.0000, 15994.0000, 16010.0000, 16026.0000, 16042.0000, 16058.0000, 16071.0000, 16087.0000, 16103.0000, 16119.0000, 16135.0000, 16151.0000, 16167.0000, 16183.0000, 16199.0000, 16215.0000, 16231.0000, 16247.0000, 16263.0000, 16279.0000, 16295.0000, 16311.0000, 0.1649, 0.2778, 0.2826, 0.2067, 0.6649, 0.7982, 0.9159, 0.9159, 0.6115, 0.5144, 0.1761, 0.1928, 0.5677, 0.7282, 0.5955, 0.5739, 0.4590, 0.2825, 0.1684, 0.1984, 0.1931, 0.1834, 0.1859, 0.2511, 0.3842, 0.3368, 0.3712, 0.7648, 0.9142, 0.9198, 0.9198, 0.8292, 0.5962, 0.1958, 0.3768, 0.8255, 0.8937, 0.8263, 0.8142, 0.7157, 0.5217, 0.3969, 0.3146, 0.2907, 0.2844, 0.2717\\
\hline
\end{tabular}

A common situation is when users have samples available as shapefiles in point format. Since shapefiles contain only geometries, we need to provide information about the start and end times for which each label is valid. In this case, one should use the function \texttt{sits\_get\_data()} to retrieve data from a data cube based on the contents of the shapefile. The parameter \texttt{shp\_attr} (optional) indicates the name of the column on the shapefile, which contains the label to be associated with each time series; the parameter \texttt{.n\_shp\_pol} (defaults to 20) determines the number of samples to be extracted from each polygon.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# define the input shapefile (consisting of POLYGONS)}
\NormalTok{shp\_file }\OtherTok{\textless{}{-}} \FunctionTok{system.file}\NormalTok{(}\StringTok{"extdata/shapes/agriculture/parcel\_agriculture.shp"}\NormalTok{, }
                        \AttributeTok{package =} \StringTok{"sitsdata"}\NormalTok{)}

\CommentTok{\# set the start and end dates }
\NormalTok{start\_date }\OtherTok{\textless{}{-}} \StringTok{"2013{-}09{-}14"}
\NormalTok{end\_date   }\OtherTok{\textless{}{-}} \StringTok{"2014{-}08{-}29"}

\CommentTok{\# define the name of attribute of the shapefile that contains the label}
\NormalTok{shp\_attr }\OtherTok{\textless{}{-}} \StringTok{"ext\_na"}

\CommentTok{\# define the number of samples to extract from each polygon}
\NormalTok{.n\_shp\_pol }\OtherTok{\textless{}{-}} \DecValTok{10}

\CommentTok{\# read the points in the shapefile and produce a CSV file}
\NormalTok{data }\OtherTok{\textless{}{-}} \FunctionTok{sits\_get\_data}\NormalTok{(}\AttributeTok{cube       =}\NormalTok{ raster\_cube, }
                      \AttributeTok{file       =}\NormalTok{ shp\_file, }
                      \AttributeTok{start\_date =}\NormalTok{ start\_date, }
                      \AttributeTok{end\_date   =}\NormalTok{ end\_date, }
                      \AttributeTok{shp\_attr   =}\NormalTok{ shp\_attr, }
                      \AttributeTok{.n\_shp\_pol =}\NormalTok{ .n\_shp\_pol)}
\NormalTok{data}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{r|r|l|l|l|l|l}
\hline
longitude & latitude & start\_date & end\_date & label & cube & time\_series\\
\hline
-55.59679 & -11.84425 & 2013-09-14 & 2014-08-29 & NA & Sinop & 15962.0000, 15978.0000, 15994.0000, 16010.0000, 16026.0000, 16042.0000, 16058.0000, 16071.0000, 16087.0000, 16103.0000, 16119.0000, 16135.0000, 16151.0000, 16167.0000, 16183.0000, 16199.0000, 16215.0000, 16231.0000, 16247.0000, 16263.0000, 16279.0000, 16295.0000, 16311.0000, 0.2000, 0.2568, 0.2958, 0.4534, 0.9824, 0.9227, 0.7506, 0.7506, 0.1882, 0.2250, 0.2279, 0.4190, 0.3820, 0.6526, 0.6420, 0.6301, 0.5837, 0.4338, 0.3018, 0.2172, 0.2045, 0.1923, 0.2179, 0.2982, 0.3531, 0.4723, 0.7466, 0.9612, 0.9267, 0.8480, 0.8480, 0.4684, 0.2743, 0.2654, 0.4775, 0.6364, 0.8372, 0.8211, 0.8274, 0.8083, 0.6897, 0.5004, 0.3445, 0.3191, 0.3094, 0.3321\\
\hline
-55.59432 & -11.84724 & 2013-09-14 & 2014-08-29 & NA & Sinop & 15962.0000, 15978.0000, 15994.0000, 16010.0000, 16026.0000, 16042.0000, 16058.0000, 16071.0000, 16087.0000, 16103.0000, 16119.0000, 16135.0000, 16151.0000, 16167.0000, 16183.0000, 16199.0000, 16215.0000, 16231.0000, 16247.0000, 16263.0000, 16279.0000, 16295.0000, 16311.0000, 0.2584, 0.2568, 0.2591, 0.4802, 0.9748, 0.9327, 0.7788, 0.7788, 0.2216, 0.2282, 0.2254, 0.4350, 0.4072, 0.6974, 0.7626, 0.7328, 0.5999, 0.4708, 0.3411, 0.2128, 0.2085, 0.1873, 0.2240, 0.4718, 0.3531, 0.4507, 0.7744, 0.9479, 0.9299, 0.8601, 0.8601, 0.4874, 0.2807, 0.2600, 0.4916, 0.6832, 0.8547, 0.8785, 0.8720, 0.8210, 0.7227, 0.5506, 0.3620, 0.3561, 0.3059, 0.3416\\
\hline
-55.59023 & -11.84886 & 2013-09-14 & 2014-08-29 & NA & Sinop & 15962.0000, 15978.0000, 15994.0000, 16010.0000, 16026.0000, 16042.0000, 16058.0000, 16071.0000, 16087.0000, 16103.0000, 16119.0000, 16135.0000, 16151.0000, 16167.0000, 16183.0000, 16199.0000, 16215.0000, 16231.0000, 16247.0000, 16263.0000, 16279.0000, 16295.0000, 16311.0000, 0.2003, 0.2700, 0.2035, 0.4896, 0.8545, 0.9205, 0.7394, 0.7394, 0.2310, 0.2207, 0.2201, 0.3883, 0.1738, 0.7134, 0.7734, 0.7654, 0.5583, 0.4705, 0.3599, 0.1979, 0.2175, 0.1998, 0.2233, 0.3083, 0.3427, 0.4135, 0.7775, 0.8870, 0.9218, 0.8373, 0.8373, 0.4775, 0.2729, 0.2613, 0.4983, 0.2516, 0.8674, 0.8707, 0.8851, 0.7510, 0.7248, 0.5697, 0.3637, 0.3402, 0.3240, 0.3398\\
\hline
-55.59174 & -11.84449 & 2013-09-14 & 2014-08-29 & NA & Sinop & 15962.0000, 15978.0000, 15994.0000, 16010.0000, 16026.0000, 16042.0000, 16058.0000, 16071.0000, 16087.0000, 16103.0000, 16119.0000, 16135.0000, 16151.0000, 16167.0000, 16183.0000, 16199.0000, 16215.0000, 16231.0000, 16247.0000, 16263.0000, 16279.0000, 16295.0000, 16311.0000, 0.2539, 0.2786, 0.2598, 0.4623, 0.9749, 0.9221, 0.7573, 0.7573, 0.2349, 0.2278, 0.2333, 0.4295, 0.5350, 0.6954, 0.7663, 0.7313, 0.5301, 0.4519, 0.2962, 0.1814, 0.1990, 0.1919, 0.2122, 0.4657, 0.3397, 0.4504, 0.7599, 0.9461, 0.9264, 0.8532, 0.8532, 0.4758, 0.2831, 0.2691, 0.5185, 0.6953, 0.8650, 0.8818, 0.8765, 0.7298, 0.7177, 0.4812, 0.3488, 0.3337, 0.3110, 0.3250\\
\hline
-55.59251 & -11.84143 & 2013-09-14 & 2014-08-29 & NA & Sinop & 15962.0000, 15978.0000, 15994.0000, 16010.0000, 16026.0000, 16042.0000, 16058.0000, 16071.0000, 16087.0000, 16103.0000, 16119.0000, 16135.0000, 16151.0000, 16167.0000, 16183.0000, 16199.0000, 16215.0000, 16231.0000, 16247.0000, 16263.0000, 16279.0000, 16295.0000, 16311.0000, 0.2053, 0.2581, 0.2877, 0.4203, 0.7729, 0.9096, 0.7168, 0.7168, 0.2429, 0.2345, 0.2280, 0.3757, 0.4195, 0.6960, 0.7532, 0.6875, 0.5367, 0.3720, 0.2462, 0.1941, 0.1772, 0.1753, 0.1858, 0.3211, 0.3519, 0.4397, 0.7239, 0.8535, 0.9207, 0.8348, 0.8348, 0.4967, 0.2880, 0.2697, 0.5276, 0.5950, 0.8658, 0.8719, 0.8571, 0.7882, 0.6518, 0.4233, 0.3449, 0.3082, 0.2919, 0.2925\\
\hline
-55.59666 & -11.84644 & 2013-09-14 & 2014-08-29 & NA & Sinop & 15962.0000, 15978.0000, 15994.0000, 16010.0000, 16026.0000, 16042.0000, 16058.0000, 16071.0000, 16087.0000, 16103.0000, 16119.0000, 16135.0000, 16151.0000, 16167.0000, 16183.0000, 16199.0000, 16215.0000, 16231.0000, 16247.0000, 16263.0000, 16279.0000, 16295.0000, 16311.0000, 0.2576, 0.2581, 0.2867, 0.4734, 0.9648, 0.9327, 0.7788, 0.7788, 0.2008, 0.2282, 0.2294, 0.4476, 0.4072, 0.6974, 0.7606, 0.7328, 0.5837, 0.4793, 0.3411, 0.2229, 0.2048, 0.1873, 0.2240, 0.4704, 0.3554, 0.4667, 0.7680, 0.9407, 0.9299, 0.8601, 0.8601, 0.4747, 0.2807, 0.2636, 0.5078, 0.6832, 0.8547, 0.8770, 0.8720, 0.8083, 0.7453, 0.5506, 0.3657, 0.3366, 0.3059, 0.3416\\
\hline
-55.59167 & -11.84652 & 2013-09-14 & 2014-08-29 & NA & Sinop & 15962.0000, 15978.0000, 15994.0000, 16010.0000, 16026.0000, 16042.0000, 16058.0000, 16071.0000, 16087.0000, 16103.0000, 16119.0000, 16135.0000, 16151.0000, 16167.0000, 16183.0000, 16199.0000, 16215.0000, 16231.0000, 16247.0000, 16263.0000, 16279.0000, 16295.0000, 16311.0000, 0.2588, 0.2551, 0.2626, 0.4866, 0.9855, 0.9205, 0.7706, 0.7706, 0.2335, 0.2282, 0.2289, 0.2643, 0.4194, 0.6954, 0.7778, 0.7384, 0.5894, 0.4921, 0.3389, 0.1916, 0.2187, 0.1889, 0.2231, 0.4687, 0.3419, 0.4516, 0.7800, 0.9547, 0.9218, 0.8563, 0.8563, 0.4887, 0.2807, 0.2654, 0.4303, 0.5851, 0.8650, 0.8825, 0.8793, 0.8135, 0.7516, 0.5472, 0.3595, 0.3386, 0.3085, 0.3386\\
\hline
-55.59580 & -11.84370 & 2013-09-14 & 2014-08-29 & NA & Sinop & 15962.0000, 15978.0000, 15994.0000, 16010.0000, 16026.0000, 16042.0000, 16058.0000, 16071.0000, 16087.0000, 16103.0000, 16119.0000, 16135.0000, 16151.0000, 16167.0000, 16183.0000, 16199.0000, 16215.0000, 16231.0000, 16247.0000, 16263.0000, 16279.0000, 16295.0000, 16311.0000, 0.2546, 0.2571, 0.2914, 0.4637, 0.9825, 0.9227, 0.7516, 0.7516, 0.2040, 0.2278, 0.2339, 0.4082, 0.4105, 0.7326, 0.7314, 0.7126, 0.5753, 0.4338, 0.3411, 0.2229, 0.2179, 0.1740, 0.2042, 0.4676, 0.3534, 0.4692, 0.7589, 0.9612, 0.9267, 0.8498, 0.8498, 0.4586, 0.2831, 0.2718, 0.4799, 0.6069, 0.8752, 0.8635, 0.8642, 0.8078, 0.6897, 0.5506, 0.3657, 0.3381, 0.2872, 0.3159\\
\hline
-55.59723 & -11.84482 & 2013-09-14 & 2014-08-29 & NA & Sinop & 15962.0000, 15978.0000, 15994.0000, 16010.0000, 16026.0000, 16042.0000, 16058.0000, 16071.0000, 16087.0000, 16103.0000, 16119.0000, 16135.0000, 16151.0000, 16167.0000, 16183.0000, 16199.0000, 16215.0000, 16231.0000, 16247.0000, 16263.0000, 16279.0000, 16295.0000, 16311.0000, 0.2000, 0.2568, 0.2958, 0.4534, 0.9824, 0.9227, 0.7506, 0.7506, 0.1882, 0.2250, 0.2279, 0.4190, 0.3820, 0.6526, 0.6420, 0.6301, 0.5837, 0.4338, 0.3018, 0.2172, 0.2045, 0.1923, 0.2179, 0.2982, 0.3531, 0.4723, 0.7466, 0.9612, 0.9267, 0.8480, 0.8480, 0.4684, 0.2743, 0.2654, 0.4775, 0.6364, 0.8372, 0.8211, 0.8274, 0.8083, 0.6897, 0.5004, 0.3445, 0.3191, 0.3094, 0.3321\\
\hline
-55.59663 & -11.84334 & 2013-09-14 & 2014-08-29 & NA & Sinop & 15962.0000, 15978.0000, 15994.0000, 16010.0000, 16026.0000, 16042.0000, 16058.0000, 16071.0000, 16087.0000, 16103.0000, 16119.0000, 16135.0000, 16151.0000, 16167.0000, 16183.0000, 16199.0000, 16215.0000, 16231.0000, 16247.0000, 16263.0000, 16279.0000, 16295.0000, 16311.0000, 0.1864, 0.2134, 0.3045, 0.4475, 0.9774, 0.9227, 0.7185, 0.7185, 0.1894, 0.2263, 0.2233, 0.3985, 0.4087, 0.6080, 0.7050, 0.6213, 0.3990, 0.3297, 0.2595, 0.1992, 0.1840, 0.1749, 0.2086, 0.2816, 0.3362, 0.4673, 0.7471, 0.9609, 0.9267, 0.8328, 0.8328, 0.4769, 0.2766, 0.2652, 0.4616, 0.6050, 0.8158, 0.8494, 0.8181, 0.6656, 0.5802, 0.4088, 0.3177, 0.3252, 0.2846, 0.3201\\
\hline
\end{tabular}

\hypertarget{filtering-techniques-for-time-series}{%
\section{Filtering techniques for time series}\label{filtering-techniques-for-time-series}}

Satellite image time series generally is contaminated by atmospheric influence, geolocation error, and directional effects \citep{Lambin2006}. Atmospheric noise, sun angle, interferences on observations or different equipment specifications, as well as the very nature of the climate-land dynamics can be sources of variability \citep{Atkinson2012}. Inter-annual climate variability also changes the phenological cycles of the vegetation, resulting in time series whose periods and intensities do not match on a year-to-year basis. To make the best use of available satellite data archives, methods for satellite image time series analysis need to deal with \emph{noisy} and \emph{non-homogeneous} data sets. In this vignette, we discuss filtering techniques to improve time series data that present missing values or noise.

The literature on satellite image time series has several applications of filtering to correct or smooth vegetation index data. The \texttt{sits} have support for Savitzky--Golay (\texttt{sits\_sgolay()}), Whitaker (\texttt{sits\_whittaker()}), envelope (\texttt{sits\_envelope()}) filters. The first two filters are commonly used in the literature, while the remaining two have been developed by the authors.

Various somewhat conflicting results have been expressed in relation to the time series filtering techniques for phenology applications. For example, in an investigation of phenological parameter estimation, \citet{Atkinson2012} found that the Whittaker and Fourier transform approaches were preferable to the double logistic and asymmetric Gaussian models. They applied the filters to preprocess MERIS NDVI time series for estimating phenological parameters in India. Comparing the same filters as in the previous work, \citet{Shao2016} found that only Fourier transform and Whittaker techniques improved interclass separability for crop classes and significantly improved overall classification accuracy. The authors used MODIS NDVI time series from the Great Lakes region in North America. \citet{Zhou2016} found that the asymmetric Gaussian model outperforms other filters over high latitude boreal biomes, while the Savitzky-Golay model gives the best reconstruction performance in tropical evergreen broadleaf forests. In the remaining biomes, Whittaker gives superior results. The authors compare all previously mentioned filters plus the Savitzky-Golay method for noise removal in MODIS NDVI data from sites spread worldwide in different climatological conditions. Many other techniques can be found in applications of satellite image time series such as curve fitting \citep{Bradley2007}, wavelet decomposition \citep{Sakamoto2005}, mean-value iteration, ARMD3-ARMA5, and 4253H \citep{Hird2009}. Therefore, any comparative analysis of smoothing algorithms depends on the adopted performance measurement.

One of the main uses of time series filtering is to reduce the noise and miss data produced by clouds in tropical areas. The following examples use data produced by the PRODES project \citep{INPE2017}, which detects deforestation in the Brazilian Amazon rain forest through visual interpretation. This data set is called \texttt{samples\_para\_mixl8mod} and is provided together with the \textbf{sits} package. It has \(617\) samples from a region corresponding to the standard Landsat Path/Row 226/064. This is an area in the East of the Brazilian Pará state. It was chosen because of its huge cloud cover from November to March, which is a significant factor in degrading time series quality. Its NDVI and EVI time series were extracted from a combination of MOD13Q1 and Landsat8 images (to best visualize the effects of each filter, we selected only NDVI time series).

\hypertarget{savitzkygolay-filter}{%
\subsection{Savitzky--Golay filter}\label{savitzkygolay-filter}}

The Savitzky-Golay filter works by fitting a successive array of \(2n+1\) adjacent data points with a \(d\)-degree polynomial through linear least squares. The central point \(i\) of the window array assumes the value of the interpolated polynomial. An equivalent and much faster solution than this convolution procedure is given by the closed expression
\[
  {\hat{x}_{i}=\sum _{j=-n}^{n}C_{j}\,x_{i+j}},
\]
where \(\hat{x}\) is the the filtered time series, \(C_{j}\) are the Savitzky-Golay smoothing coefficients, and \(x\) is the original time series.

The coefficients \(C_{j}\) depend uniquely on the polynomial degree (\(d\)) and the length of the window data points (given by parameter \(n\)). If \({d=0}\), the coefficients are constants \({C_{j}=1/(2n+1)}\) and the Savitzky-Golay filter will be equivalent to moving average filter. When the time series are equally spaced, the coefficients have an analytical solution. According to \citet{Madden1978}, for \({d\in{}[2,3]}\) each \(C_{j}\) smoothing coefficients can be obtained by
\[
  C_{j}=\frac{3(3n^2+3n-1-5j^2)}{(2n+3)(2n+1)(2n-1)}.
\]

In general, the Savitzky-Golay filter produces smoother results for a larger value of \(n\) and/or a smaller value of \(d\) \citep{Chen2004}. The optimal value for these two parameters can vary from case to case. In SITS, the user can set the order of the polynomial using the parameter \texttt{order} (default = 3), the size of the temporal window with the parameter \texttt{length} (default = 5), and the temporal expansion with the parameter \texttt{scaling} (default = 1). The following example shows the effect of Savitsky-Golay filter on the original time series.

\begin{quote}
The code below uses the \texttt{samples\_para\_mixl8mod} dataset provided by the \href{https://github.com/e-sensing/sitsdata}{sitsdata} package.
\end{quote}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data}\NormalTok{(}\StringTok{"samples\_para\_mixl8mod"}\NormalTok{)}

\CommentTok{\# Take NDVI band of the first sample data set}
\NormalTok{point.tb }\OtherTok{\textless{}{-}} \FunctionTok{sits\_select}\NormalTok{(samples\_para\_mixl8mod[}\DecValTok{1}\NormalTok{,], }\StringTok{"ndvi"}\NormalTok{)}
\CommentTok{\# apply Savitzky–Golay filter}
\NormalTok{point\_sg.tb }\OtherTok{\textless{}{-}} \FunctionTok{sits\_filter}\NormalTok{(point.tb, }\AttributeTok{filter =} \FunctionTok{sits\_sgolay}\NormalTok{())}
\CommentTok{\# plot the series}
\FunctionTok{sits\_merge}\NormalTok{(point\_sg.tb, point.tb) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{plot}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{sitsbook_files/figure-latex/unnamed-chunk-33-1} 

}

\caption[Savitzky-Golay filter applied on a one-year NDVI time series]{Savitzky-Golay filter applied on a one-year NDVI time series.}\label{fig:unnamed-chunk-33}
\end{figure}

\hypertarget{whittaker-filter}{%
\subsection{Whittaker filter}\label{whittaker-filter}}

The Whittaker smoother attempts to fit a curve that represents the raw data, but is penalized if subsequent points vary too much \citep{Atzberger2011}. The Whittaker filter is a balancing between the residual to the original data and the ``smoothness'' of the fitted curve. The residual, as measured by the sum of squares of all \(n\) time series points deviations, is given by
\[
  RSS=\sum_{i}(x_{i} - \hat{x_{i}})^2,
\]
where \(x\) and \(\hat{x}\) are the original and the filtered time series vectors, respectively. The smoothness is assumed to be the measure of the sum of the squares of the third-order differences of the time series \citep{Whittaker1922}, which is given by
\[
  \begin{split}
S\!S\!D = (\hat{x}_4 - 3\hat{x}_3 + 3\hat{x}_2 - \hat{x}_1)^2 + (\hat{x}_5 - 3\hat{x}_4 + 3\hat{x}_3 - \hat{x}_2)^2 \\ + \ldots + (\hat{x}_n - 3\hat{x}_{n-1} + 3\hat{x}_{n-2} - \hat{x}_{n-3})^2.
\end{split}
\]

The filter is obtained by finding a new time series \(\hat{x}\) whose points minimize the expression
\[
  RSS+\lambda{}S\!S\!D,
\]
where \(\lambda{}\), a scalar, works as a ``smoothing weight'' parameter. The minimization can be obtained by differentiating the expression with respect to \(\hat{x}\) and equating it to zero. The solution of the resulting linear system of equations gives the filtered time series, which, in matrix form, can be expressed as

\[
  \hat{x} = ({\rm I} + \lambda {D}^{\intercal} D)^{-1}x,
\]
where \({\rm I}\) is the identity matrix and
\[
  D = \left[\begin{array}{ccccccc}
             1 & -3 & 3 & -1 & 0 & 0 &\cdots \\
             0 & 1 & -3 & 3 & -1 & 0 &\cdots \\
             0 & 0 & 1 & -3 & 3 & -1 & \cdots \\
             \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \ddots
             \end{array}
             \right]
\]
\#\# Using filters for time series and data cube classification

We tested different methods of extracting attributes from time series data, including those reported by \citet{Pelletier2016} and \citet{Kastens2017}. We conclude that part of the information in the raw time series is lost after filtering. Thus, the method we developed uses all the data available in the time series samples. The idea is to have as many temporal attributes as possible, increasing the classification space's dimension. Our experiments found that modern statistical models such as support vector machines and random forests perform better in high-dimensional spaces than in lower-dimensional ones.

\hypertarget{part-clustering}{%
\part{Clustering}\label{part-clustering}}

\hypertarget{time-series-clustering-to-improve-the-quality-of-training-samples}{%
\chapter{Time Series Clustering to Improve the Quality of Training Samples}\label{time-series-clustering-to-improve-the-quality-of-training-samples}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

One of the key challenges when using samples to train machine learning classification models is assessing their quality. Noisy and imperfect training samples can have a negative effect on classification performance. Therefore, it is useful to apply pre-processing methods to improve the quality of the samples and to remove those that might have been wrongly labeled or that have low discriminatory power. Representative samples lead to good classification maps. \texttt{sits} provides support for two clustering methods to test sample quality, which is agglomerative hierarchical clustering (AHC) and self-organizing maps (SOM).

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{clustering-for-sample-quality-control}{%
\section{Clustering for sample quality control}\label{clustering-for-sample-quality-control}}

Recent results show that it is feasible to apply machine learning methods to SITS analysis in large areas of 100 million ha or more \citep{Picoli2018, Simoes2020, Parente2019a, Griffiths2019a}. Experience with machine learning methods has established that the limiting factor in obtaining good results is the number and quality of training samples. Large and accurate data sets are better, no matter the algorithm used \citep{Maxwell2018}; increasing the training sample size results in better classification accuracy \citep{ThanhNoi2018}. Therefore, using machine learning for SITS analysis requires large and good quality training sets.

One of the key challenges when using samples to train machine learning classification models is assessing their quality. Noisy and imperfect training samples can have a negative effect on classification performance \citep{Frenay2014}. There are two main sources of noise and errors in satellite image time series. One effect is \emph{feature noise}, caused by clouds and inconsistencies in data calibration. The second effect is \emph{class noise}, when the label assigned to the sample is wrongly attributed. Class noise effects are common on large data sets. In particular, interpreters tend to group samples with different properties in the same category. For this reason, one needs good methods for quality control of large training data sets associated with satellite image time series. Our work thus addresses the question: \emph{How to reduce class noise in large training sets of satellite image time series?}

Many factors lead to \emph{class noise} in SITS. One of the main problems is the inherent variability of class signatures in space and time. When training data is collected over a large geographic region, natural variability of vegetation phenology can result in different patterns being assigned to the same label. Phenological patterns can vary spatially across a region and are strongly correlated with climate variations. A related issue is the limitation of crisp boundaries to describe the natural world. Class definition use idealised descriptions (e.g., ``a savanna woodland has tree cover of 50\% to 90\% ranging from 8 to 15 meters in height''). However, in practice, the boundaries between classes are fuzzy and sometimes overlap, making it hard to distinguish between them. Class noise can also result from labeling errors. Even trained analysts can make errors in class attributions. Despite the fact that machine learning techniques are robust to errors and inconsistencies in the training data, quality control of training data can make a significant difference in the resulting maps.

Therefore, it is useful to apply pre-processing methods to improve the quality of the samples and to remove those that might have been wrongly labeled or that have low discriminatory power. Representative samples lead to good classification maps. \texttt{sits} provides support for two clustering methods to test sample quality: (a) Agglomerative Hierarchical Clustering (AHC); (b) Self-organizing Maps (SOM).

\hypertarget{hierachical-clustering-for-sample-quality-control}{%
\section{Hierachical clustering for Sample Quality Control}\label{hierachical-clustering-for-sample-quality-control}}

\hypertarget{creating-a-dendogram}{%
\subsection{Creating a dendogram}\label{creating-a-dendogram}}

Cluster analysis has been used for many purposes in satellite image time series literature ranging from unsupervised classification and pattern detection \citep{Petitjean2011}. Here, we are interested in the second use of clustering, using it as a way to improve training data to feed machine learning classification models. In this regard, cluster analysis can assist the identification of structural \emph{time series patterns} and anomalous samples \citep{Frenay2014}.

Agglomerative hierarchical clustering (AHC) is a family of methods that groups elements using a distance function to associate a real value to a pair of elements. From this distance measure, we can compute the dissimilarity between any two elements from a data set. Depending on the distance functions and linkage criteria, the algorithm decides which two clusters are merged at each iteration. AHC approach is suitable for the purposes of samples data exploration due to its visualization power and ease of use \citep{Keogh2003}. Moreover, AHC does not require a predefined number of clusters as an initial parameter. This is an important feature in satellite image time series clustering since defining the number of clusters present in a set of multi-attribute time series is not straightforward \citep{Aghabozorgi2015}.

The main result of the AHC method is a \emph{dendrogram}. It is the ultrametric relation formed by the successive merges in the hierarchical process that can be represented by a tree. Dendrograms are quite useful to decide the number of clusters to partition the data. It shows the height where each merging happens, which corresponds to the minimum distance between two clusters defined by a \emph{linkage criterion}. The most common linkage criteria are: \emph{single-linkage}, \emph{complete-linkage}, \emph{average-linkage}, and \emph{Ward-linkage}. Complete-linkage prioritizes the within-cluster dissimilarities, producing clusters with shorter distance samples. Complete-linkage clustering can be sensitive to outliers, which can increase the resulting intracluster data variance. As an alternative, Ward proposes criteria to minimize the data variance by means of either \emph{sum-of-squares} or \emph{sum-of-squares-error} \citep{Ward1963}. Ward's intuition is that clusters of multivariate observations, such as time series, should be approximately elliptical in shape \citep{Hennig2015}. In \texttt{sits}, a dendrogram can be generated by \texttt{sits\_dendrogram()}. The following codes illustrate how to create, visualize, and cut a dendrogram (for details, see \texttt{?sits\_dendrogram()}).

\hypertarget{using-a-dendrogram-to-evaluate-sample-quality}{%
\subsection{Using a dendrogram to evaluate sample quality}\label{using-a-dendrogram-to-evaluate-sample-quality}}

After creating a dendrogram, an important question emerges: \emph{where to cut the dendrogram?} The answer depends on what are the purposes of the cluster analysis. We need to balance two objectives: get clusters as large as possible, and get clusters as homogeneous as possible with respect to their known classes. To help this process, \texttt{sits} provides \texttt{sits\_dendro\_bestcut()} function that computes an external validity index \emph{Adjusted Rand Index} (ARI) for a series of the different number of generated clusters. This function returns the height where the cut of the dendrogram maximizes the index.

In this example, the height optimizes the ARI and generates \(6\) clusters. The ARI considers any pair of distinct samples and computes the following counts:
(a) the number of distinct pairs whose samples have the same label and are in the same cluster;
(b) the number of distinct pairs whose samples have the same label and are in different clusters;
(c) the number of distinct pairs whose samples have different labels and are in the same cluster; and
(d) the number of distinct pairs whose samples have the different labels and are in different clusters.
Here, \(a\) and \(d\) consist in all agreements, and \(b\) and \(c\) all disagreements. The ARI is obtained by:

\[
ARI=\frac{a+d-E}{a+d+b+c-E},
\]
where \(E\) is the expected agreement, a random chance correction calculated by
\[
E=(a+b)(b+c)+(c+d)(b+d).
\]

Unlike other validity indexes such as Jaccard (\({J=a/(a+b+c)}\)), Fowlkes-Mallows (\({FM=a/(a^2+a(b+c)+bc)^{1/2}}\)), and Rand (the same as ARI without the \(E\) adjustment) indices, ARI is more appropriate either when the number of clusters is outweighed by the number of labels (and \emph{vice versa}) or when the number of samples in labels and clusters are imbalanced \citep{Hubert1985}, which is usually the case.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# take a set of patterns for 2 classes}
\CommentTok{\# create a dendrogram, plot, and get the optimal cluster based on ARI index}
\NormalTok{clusters }\OtherTok{\textless{}{-}}\NormalTok{ sits}\SpecialCharTok{::}\FunctionTok{sits\_cluster\_dendro}\NormalTok{(cerrado\_2classes, }
                                         \AttributeTok{bands =} \FunctionTok{c}\NormalTok{(}\StringTok{"ndvi"}\NormalTok{, }\StringTok{"evi"}\NormalTok{))}

\CommentTok{\# show clusters samples frequency}
\NormalTok{sits}\SpecialCharTok{::}\FunctionTok{sits\_cluster\_frequency}\NormalTok{(clusters)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
#>          
#>             1   2   3   4   5   6 Total
#>   Cerrado 203  13  23  80   1  80   400
#>   Pasture   2 176  28   0 140   0   346
#>   Total   205 189  51  80 141  80   746
\end{verbatim}

\begin{center}\includegraphics[width=0.7\linewidth]{sitsbook_files/figure-latex/dendrogram-1} \end{center}

Note in this example that almost all clusters have a predominance of either ``Cerrado'' or ``Pasture'' classes with the exception of cluster \(3\). The contingency table plotted by \texttt{sits\_cluster\_frequency()} shows how the samples are distributed across the clusters and help to identify two kinds of confusion. The first is relative to those small amounts of samples in clusters dominated by another class (\emph{e.g.} clusters \(1\), \(2\), \(4\), \(5\), and \(6\)), while the second is relative to those samples in non-dominated clusters (\emph{e.g.} cluster \(3\)). These confusions can be an indication of samples with poor quality, and inadequacy of selected parameters for cluster analysis, or even a natural confusion due to the inherent variability of the land classes.

The result of the \texttt{sits\_cluster} operation is a \texttt{sits\_tibble} with one additional column, called ``cluster''. Thus, it is possible to remove clusters with mixed classes using standard \texttt{R} such as those in the \texttt{dplyr} package. In the example above, removing cluster \(3\) can be done using the \texttt{dplyr::filter} function.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# remove cluster 3 from the samples}
\NormalTok{clusters\_new }\OtherTok{\textless{}{-}}\NormalTok{ dplyr}\SpecialCharTok{::}\FunctionTok{filter}\NormalTok{(clusters, cluster }\SpecialCharTok{!=} \DecValTok{3}\NormalTok{)}

\CommentTok{\# show new clusters samples frequency}
\NormalTok{sits}\SpecialCharTok{::}\FunctionTok{sits\_cluster\_frequency}\NormalTok{(clusters\_new)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
#>          
#>             1   2   4   5   6 Total
#>   Cerrado 203  13  80   1  80   377
#>   Pasture   2 176   0 140   0   318
#>   Total   205 189  80 141  80   695
\end{verbatim}

The resulting clusters still contained mixed labels, possibly resulting from outliers. In this case, users may want to remove the outliers and leave only the most frequent class. To do this, one can use \texttt{sits\_cluster\_clean()}, which removes all minority samples, as shown below.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# clear clusters, leaving only the majority class in each cluster}
\NormalTok{clean }\OtherTok{\textless{}{-}}\NormalTok{ sits}\SpecialCharTok{::}\FunctionTok{sits\_cluster\_clean}\NormalTok{(clusters)}
\CommentTok{\# show clusters samples frequency}
\FunctionTok{sits\_cluster\_frequency}\NormalTok{(clean)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
#>          
#>             1   2   3   4   5   6 Total
#>   Cerrado 203   0   0  80   0  80   363
#>   Pasture   0 176  28   0 140   0   344
#>   Total   203 176  28  80 140  80   707
\end{verbatim}

\hypertarget{using-self-organizing-maps-for-sample-quality}{%
\section{Using Self-organizing Maps for Sample Quality}\label{using-self-organizing-maps-for-sample-quality}}

\hypertarget{introduction-to-self-organizing-maps}{%
\subsection{Introduction to Self-organizing Maps}\label{introduction-to-self-organizing-maps}}

As an alternative for hierarchical clustering for quality control of training samples, SITS provides a clustering technique based on self-organizing maps (SOM). SOM is a dimensionality reduction technique \citep{Kohonen1990}, where high-dimensional data is mapped into two dimensions, keeping the topological relations between data patterns. The input data is a set of training samples that are typical of a high dimension. For example, a time series of 25 instances of 4 spectral bands is a 100-dimensional data set. The general idea of SOM-based clustering is that, by projecting the high-dimensional data set of training samples into a 2D map, the units of the map (called ``neurons'') compete for each sample. It is expected that good quality samples of each class should be close together in the resulting map. The neighbors of each neuron of a SOM map provide information on intra-class and inter-class variability.

The main steps of our proposed method for quality assessment of satellite image time series are shown in the figure below. The method uses self-organizing maps (SOM) to perform dimensionality reduction while preserving the topology of original datasets. Since SOM preserves the topological structure of neighborhoods in multiple dimensions, the resulting 2D map can be used as a set of clusters. Training samples that belong to the same class will usually be neighbors in 2D space. The neighbors of each neuron of a SOM map are also expected to be similar.

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth,height=0.9\textheight]{images/methodology_bayes_som} 

}

\caption[Using SOM for class noise reduction]{Using SOM for class noise reduction}\label{fig:unnamed-chunk-37}
\end{figure}

As the figure shows, a SOM grid is composed of units called \emph{neurons}. The algorithm computes the distances of each member of the training set to all neurons and finds the neuron closest to the input, called the best matching unit (BMU). The weights of the BMU and its neighbors are updated so as to preserve their similarity {[}Kohonen2013{]}. This mapping and adjustment procedure is done in several iterations. At each step, the extent of the change in the neurons diminishes until a convergence threshold is reached. The result is a 2D mapping of the training set, where similar elements of the input are mapped to the same neuron or to nearby ones. The resulting SOM grid combines dimensionality reduction with topological preservation.

\hypertarget{using-som-for-removing-class-noise}{%
\subsection{Using SOM for removing class noise}\label{using-som-for-removing-class-noise}}

The process of clustering with SOM is done by \texttt{sits\_som\_map()}, which creates a self-organizing map and assesses the quality of the samples. The function has two parts. First, it computes a SOM grid, as discussed previously, where each sample is assigned to a neuron, and neurons are placed in the grid based on similarity. The second step is the quality assessment. Each neuron will be associated with a discrete probability distribution. Homogeneous neurons (those with a single class) are assumed to be composed of good quality samples. Heterogeneous neurons (those with two or more classes with significant probability) are likely to contain noisy samples.

Considering that each sample of the training set is assigned to a neuron, the algorithm computes two values for each sample:

\begin{itemize}
\tightlist
\item
  prior probability: the probability that the label assigned to the sample is correct, considering only the samples in the same neuron. For example, if a neuron has 20 samples, of which 15 are labeled as ``Pasture'' and 5 as ``Forest'', all samples labeled ``Forest'' are assigned a prior probability of 25\%. This is an indication that the ``Forest'' samples in this neuron are not of good quality.
\item
  posterior probability: the probability that the label assigned to the sample is correct, considering the neighboring neurons. Take the case of the above-mentioned neuron whose samples labeled ``Pasture'' have a prior probability of 75\%. What happens if all the neighboring samples have ``Forest'' as a majority label? Are the samples labeled ``Pasture'' in this neuron noisy? To answer this question, we use information from the neighbours. Bayesian inference we estimate if these samples are noisy based on the samples of the neighboring neurons {[}Santos2021{]}.
\end{itemize}

As an example of the use of SOM clustering for quality control of samples, we take a dataset containing a tibble with time series samples for the Cerrado region of Brazil, the second largest biome in South America with an area of more than 2 million km2. The training samples were collected by ground surveys and high-resolution image interpretation by experts from the Brazilian National Institute for Space Research (INPE) team and partners. This set ranges from 2000 to 2017 and includes 61,073 land use and cover samples divided into 14 classes: Natural Non-vegetated, Fallow-Cotton, Millet-Cotton, Soy-Corn, Soy-Cotton, Soy-Fallow, Pasture, Shrublands (in Portuguese \textit{Cerrado Rupestre}), Savanna (in Portuguese \textit{Cerrado}, Dense Tree Savanna (in Portuguese \textit{Cerradao}), Open Savanna (in Portuguese \textit{Campo Cerrado}), Planted Forest, and (14) Wetlands. In the example below, we take only 10\% of the samples
for faster processing. Users are encouraged to run the example with the full
set of samples.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# take only 10\% of the samples}
\NormalTok{samples\_cerrado\_mod13q1\_reduced }\OtherTok{\textless{}{-}} \FunctionTok{sits\_sample}\NormalTok{(samples\_cerrado\_mod13q1, }\AttributeTok{frac =} \FloatTok{0.1}\NormalTok{)}
\CommentTok{\# clustering time series using SOM}
\NormalTok{som\_cluster }\OtherTok{\textless{}{-}}
    \FunctionTok{sits\_som\_map}\NormalTok{(}
\NormalTok{        samples\_cerrado\_mod13q1\_reduced,}
        \AttributeTok{grid\_xdim =} \DecValTok{15}\NormalTok{,}
        \AttributeTok{grid\_ydim =} \DecValTok{15}\NormalTok{,}
        \AttributeTok{alpha =} \FloatTok{1.0}\NormalTok{,}
        \AttributeTok{distance =} \StringTok{"euclidean"}\NormalTok{,}
        \AttributeTok{rlen =} \DecValTok{100}
\NormalTok{    )}
\end{Highlighting}
\end{Shaded}

The output of the \texttt{sits\_som\_map} is a list with 4 tibbles:

\begin{itemize}
\item
  the original set of time series with two additional columns for each time series: \texttt{id\_sample} (the original id of each sample) and \texttt{id\_neuron} (the id of the neuron to which it belongs).
\item
  a tibble with information on the neuron. For each neuron, it gives the prior and posterior probabilities of all labels which occur in the samples assigned to it.
\item
  the SOM grid
  To plot the SOM grid, use \texttt{plot()}. The neurons are labelled using the majority voting.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(som\_cluster)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{sitsbook_files/figure-latex/unnamed-chunk-39-1} \end{center}

Looking at the SOM grid, one can see that most of the neurons of a class are located close to each other. There are outliers, e.g., some ``Open Savanna'' neurons are located amidst ``Shrublands'' neurons. This mixture is a consequence of the continuous nature of natural vegetation cover in the Brazilian Cerrado. The transition between areas of open savanna and shrublands is not always well defined; moreover, it is dependent on factors such as climate and latitude.

To identifies noisy samples, we take the result of the \texttt{sits\_som\_map} function as the first argument to the function \texttt{sits\_som\_clean\_samples}. This function finds out which samples are noisy, those that are clean, and some that need to be further examined by the user. It uses the \texttt{prior\_threshold} and \texttt{posterior\_threshold} parameters according to the following rules:

\begin{itemize}
\tightlist
\item
  If the prior probability of a sample is less than \texttt{prior\_threshold}, the sample is assumed to be noisy and tagged as ``remove'';
\item
  If the prior probability is greater or equal to \texttt{prior\_threshold} and the posterior probability is greater or equal to \texttt{posterior\_threshold}, the sample is assumed not to be noisy and thus is tagged as ``clean'';
\item
  If the prior probability is greater or equal to \texttt{prior\_threshold} and the posterior probability is less than \texttt{posterior\_threshold}, we have a situation the sample is part of the majority level of those assigned to its neuron, but its label is not consistent with most of its neighbors. This is an anomalous condition and is tagged as ``analyze''. Users are encouraged to inspect
  such samples to find out whether they are in fact noisy or not.
\end{itemize}

The default value for both \texttt{prior\_threshold} and \texttt{posterior\_threshold} is 60\%. The \texttt{sits\_som\_clean\_samples} has an additional parameter (\texttt{keep}) which indicates which samples should be kept in the set based on their prior and posterior probabilities of being noisy and the assigned label. The default value for \texttt{keep} is \texttt{c("clean",\ "analyze")}. As a result of the cleaning, about 900 samples have been considered to be noisy and thus removed.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{new\_samples }\OtherTok{\textless{}{-}} \FunctionTok{sits\_som\_clean\_samples}\NormalTok{(som\_cluster, }
                                      \AttributeTok{prior\_threshold =} \FloatTok{0.6}\NormalTok{,}
                                      \AttributeTok{posterior\_threshold =} \FloatTok{0.6}\NormalTok{,}
                                      \AttributeTok{keep =} \FunctionTok{c}\NormalTok{(}\StringTok{"clean"}\NormalTok{, }\StringTok{"analyze"}\NormalTok{))}
\CommentTok{\# find out how many samples are evaluated as "clean" or "analyze"}
\NormalTok{new\_samples }\SpecialCharTok{\%\textgreater{}\%} 
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{group\_by}\NormalTok{(eval) }\SpecialCharTok{\%\textgreater{}\%} 
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{summarise}\NormalTok{(}\AttributeTok{count =}\NormalTok{ dplyr}\SpecialCharTok{::}\FunctionTok{n}\NormalTok{(), }\AttributeTok{.groups =} \StringTok{"drop"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|r}
\hline
eval & count\\
\hline
analyze & 652\\
\hline
clean & 4416\\
\hline
\end{tabular}

\hypertarget{comparing-global-accuracy-of-original-and-clean-samples}{%
\subsection{Comparing Global Accuracy of Original and Clean Samples}\label{comparing-global-accuracy-of-original-and-clean-samples}}

To compare the accuracy of the original and clean samples, we run
a 5-fold validation on the original and on the cleaned sample. We use the function
\texttt{sits\_kfold\_validate}. As the results show, the SOM procedure is useful, since
the global accuracy improves from 91\% to 95\%.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{assess\_orig }\OtherTok{\textless{}{-}} \FunctionTok{sits\_kfold\_validate}\NormalTok{(samples\_cerrado\_mod13q1\_reduced, }
                                   \AttributeTok{ml\_method =} \FunctionTok{sits\_svm}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{assess\_new }\OtherTok{\textless{}{-}} \FunctionTok{sits\_kfold\_validate}\NormalTok{(new\_samples, }
                                   \AttributeTok{ml\_method =} \FunctionTok{sits\_svm}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

An additional way of evaluating the quality of samples is to examine the internal
mixture inside neurons with the same label. We call a group of neurons sharing
the same label as a ``cluster''. Given a SOM map, the function \texttt{sits\_som\_evaluate\_cluster}
examines all clusters to find out the percentage of samples contained in it which do not share its label. This information is saved as a tibble and can also
be visualized.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# evaluate the misture in the SOM clusters}
\NormalTok{cluster\_mixture }\OtherTok{\textless{}{-}} \FunctionTok{sits\_som\_evaluate\_cluster}\NormalTok{(som\_cluster)}
\CommentTok{\# plot the mixture information.}
\FunctionTok{plot}\NormalTok{(cluster\_mixture)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{sitsbook_files/figure-latex/unnamed-chunk-43-1} \end{center}

\hypertarget{conclusion}{%
\section{Conclusion}\label{conclusion}}

Machine learning methods are now established as a useful technique for remote sensing image analysis. Despite the well-known fact that the quality of the training data is a key factor in the accuracy of the resulting maps, the literature on methods for detecting and removing class noise in SITS training sets is limited. To contribute to solving this challenge, this paper proposed a new technique. The proposed method uses the SOM neural network to group similar samples in a 2D map for dimensionality reduction. The method identifies both mislabeled samples and outliers that are flagged to further investigation. The results demonstrate the positive impact on the overall classification accuracy. Although the class noise removal adds an extra cost to the entire classification process, we believe that it is essential to improve the accuracy of classified maps using SITS analysis mainly for large areas.

\hypertarget{part-classification}{%
\part{Classification}\label{part-classification}}

\hypertarget{machine-learning-for-data-cubes-using-the-sits-package}{%
\chapter{Machine Learning for Data Cubes using the SITS package}\label{machine-learning-for-data-cubes-using-the-sits-package}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

This chapter presents the machine learning techniques available in SITS. The main use for machine learning in SITS is for classification of land use and land cover. These machine learning methods available in SITS include linear and quadratic discrimination analysis, support vector machines, random forests, deep learning and neural networks.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{machine-learning-classification}{%
\section{Machine learning classification}\label{machine-learning-classification}}

\texttt{sits} has support for a variety of machine learning techniques: linear discriminant analysis, quadratic discriminant analysis, multinomial logistic regression, random forests, boosting, support vector machines, and deep learning. The deep learning methods include multi-layer perceptrons, 1D convolution neural networks and mixed approaches such as TempCNN \citep{Pelletier2019} . In a recent review of machine learning methods to classify remote sensing data \citep{Maxwell2018}, the authors note that many factors influence the performance of these classifiers, including the size and quality of the training dataset, the dimension of the feature space, and the choice of the parameters. We support both \emph{space-first, time-later} and \emph{time-first, space-later} approaches. Therefore, the \texttt{sits} package provides functionality to explore the full depth of satellite image time series data.

When used in \emph{time-first, space-later} approach, \texttt{sits} treats time series as a feature vector. To be consistent, the procedure aligns all time series from different years by its time proximity considering an given cropping schedule. Once aligned, the feature vector is formed by all pixel ``bands''. The idea is to have as many temporal attributes as possible, increasing the dimension of the classification space. In this scenario, statistical learning models are the natural candidates to deal with high-dimensional data: learning to distinguish all land cover and land use classes from trusted samples exemplars (the training data) to infer classes of a larger data set.

SITS provides support for the classification of both individual time series as well as data cubes. The following machine learning methods are available in SITS:

\begin{itemize}
\tightlist
\item
  Linear discriminant analysis (\texttt{sits\_lda})
\item
  Quadratic discriminant analysis (\texttt{sits\_qda})
\item
  Multinomial logit and its variants `lasso' and `ridge' (\texttt{sits\_mlr})
\item
  Support vector machines (\texttt{sits\_svm})
\item
  Random forests (\texttt{sits\_rfor})
\item
  Extreme gradient boosting (\texttt{sits\_xgboost})
\item
  Deep learning (DL) using multi-layer perceptrons (\texttt{sits\_deeplearning})
\item
  DL with 1D convolutional neural networks (\texttt{sits\_FCN})
\item
  DL using 1D version of ResNet (\texttt{sits\_ResNet})
\item
  DL combining 1D CNN and multi-layer perceptron networks (\texttt{sits\_TempCNN})
\item
  DL using a combination of long-short term memory (LSTM) and 1D CNN (\texttt{sits\_LSTM-FCN})
\end{itemize}

\hypertarget{data-used-in-the-machine-learning-examples}{%
\section{Data used in the machine learning examples}\label{data-used-in-the-machine-learning-examples}}

For the machine learning examples, we use a data set containing a sits tibble with time series samples from Brazilian Mato Grosso State (Amazon and Cerrado biomes). The samples are from many sources. It has 9 classes (``Cerrado'', ``Fallow\_Cotton'', ``Forest'', ``Millet\_Cotton'', ``Pasture'', ``Soy\_Corn'', ``Soy\_Cotton'', ``Soy\_Fallow'', ``Soy\_Millet''). Each time series comprehends 12 months (23 data points) from MOD13Q1 product, and has 6 bands (``ndvi'', ``evi'', ``blue'', ``red'', ``nir'', ``mir''. The dataset was used in the paper ``Big Earth observation time series analysis for monitoring Brazilian agriculture'' \citep{Picoli2018}, and is available in the R package ``sitsdata'', which is downloadable from the website associated to the ``e-sensing'' project. The examples below use two out of six bands (``ndvi'', ``evi'') for training and classification. In practice, we suggest that users include additionally at least the ``nir'' and ``mir'' bands.

\hypertarget{visualizing-samples}{%
\section{Visualizing Samples}\label{visualizing-samples}}

One useful way of describing and understanding the samples is by plotting them. A direct way of doing so is using the \texttt{plot} function. When applied to a large data sample, the result is the set of all samples for each label and each band, as shown in the example below, where we plot the raw distribution of the samples with ``Forest'' label in the ``ndvi'' band.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data}\NormalTok{(}\StringTok{"samples\_matogrosso\_mod13q1"}\NormalTok{)}

\CommentTok{\# Select a subset of the samples to be plotted}
\CommentTok{\# Retrieve the set of samples for the Mato Grosso region }
\NormalTok{samples\_matogrosso\_mod13q1 }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{sits\_select}\NormalTok{(}\AttributeTok{bands =} \StringTok{"NDVI"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
\NormalTok{    dplyr}\SpecialCharTok{::}\FunctionTok{filter}\NormalTok{(label }\SpecialCharTok{==} \StringTok{"Forest"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{plot}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{sitsbook_files/figure-latex/unnamed-chunk-45-1} \end{center}

In the above plot, the thick red line is the median value for each time instance and the yellow lines are the first and third interquartile ranges. Visually, one can see that samples labelled as ``Forest'' are distinguishable from those of ``Cerrado'' and ``Pasture''; in turn, these latter classes have many similar features and required sophisticated methods for distinction.

An alternative to visualise the samples is to estimate a statistical approximation to an idealized pattern based on a generalised additive model (GAM). A GAM is a linear model in which the linear predictor depends linearly on a smooth function of the predictor variables
\[
y = \beta_{i} + f(x) + \epsilon, \epsilon \sim N(0, \sigma^2).
\]
The function \texttt{sits\_patterns} uses a GAM to predict a smooth, idealized approximation to the time series associated to the each label, for all bands. This function is based on the R package \texttt{dtwSat}\citep{Maus2019}, which implements the TWDTW time series matching method described in \citet{Maus2016}. The resulting patterns can be viewed using \texttt{plot}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Select a subset of the samples to be plotted}
\NormalTok{samples\_matogrosso\_mod13q1 }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{sits\_patterns}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{plot}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{sitsbook_files/figure-latex/unnamed-chunk-46-1} \end{center}

The resulting plots provide some insights over the time series behaviour of each class. While the response of the ``Forest'' class is quite distinctive, there are similarities between the double-cropping classes (``Soy-Corn'', ``Soy-Millet'', ``Soy-Sunflower'' and ``Soy-Corn'') and between the ``Cerrado'' and ``Pasture'' classes. This could suggest that additional information, more bands, or higher-resolution data could be considered to provide a better basis for time series samples that can better distinguish the intended classes. Despite these limitations, the best machine learning algorithms can provide good performance even in the above case.

\hypertarget{common-interface-to-machine-learning-and-deeplearning-models}{%
\section{Common interface to machine learning and deeplearning models}\label{common-interface-to-machine-learning-and-deeplearning-models}}

The SITS package provides a common interface to all machine learning models, using the \texttt{sits\_train} function. this function takes two parameters: the input data samples and the ML method (\texttt{ml\_method}), as shown below. After the model is estimated, it can be used to classify individual time series or full data cubes using the \texttt{sits\_classify} function. In the examples that follow, we show how to apply each method for the classification of a single time series. Then, we disscuss how to classify full data cubes.

When a dataset of time series organised as a SITS tibble is taken as input to the classifier, the result is the same tibble with one additional column (``predicted''), which contains the information on what labels are have been assigned for each interval. The following examples illustrate how to train a dataset and classify an individual time series using the different machine learning techniques. First we use the \texttt{sits\_train} function with two parameters: the training dataset (described above) and the chosen machine learning model (in this case, a random forest classifier). The trained model is then used to classify a time series from Mato Grosso Brazilian state, using \texttt{sits\_classify}. The results can be shown in text format using the function \texttt{sits\_show\_prediction} or graphically using \texttt{plot}.

\hypertarget{random-forests}{%
\section{Random forests}\label{random-forests}}

The Random forest uses the idea of \emph{decision trees} as its base model. It combines many decision trees via \emph{bootstrap} procedure and \emph{stochastic feature selection}, developing a population of somewhat uncorrelated base models. The final classification model is obtained by a majority voting schema. This procedure decreases the classification variance, improving prediction of individual decision trees.

Random forest training process is essentially nondeterministic. It starts by growing trees through repeatedly random sampling-with-replacement the observations set. At each growing tree, the random forest considers only a fraction of the original attributes to decide where to split a node, according to a \emph{purity criterion}. This criterion is used to identify relevant features and to perform variable selection. This decreases the correlation among trees and improves the prediction performance. Two often-used impurity criteria are the \emph{Gini} index and the \emph{permutation} measure. The Gini index considers the contribution of each variable which improves the spliting criteria for building tress. Permutation increases the importance of variables that have a positive effect on the prediction accuracy. The splitting process continues until the tree reaches some given minimum nodes size or a minimum impurity index value.

One of the advantages of the random forest model is that the classification performance is mostly dependent on the number of decision trees to grow and of the ``importance'' parameter, which controls the purity variable importance measures. SITS provides a \texttt{sits\_rfor} function which is a front-end to the \texttt{randomForest} package\citep{Wright2017}; its main parameters is \texttt{num\_trees} (number of trees to grow).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Retrieve the set of samples (provided by EMBRAPA) from the }
\CommentTok{\# Mato Grosso region for train the Random Forest model.}
\NormalTok{rfor\_model }\OtherTok{\textless{}{-}} \FunctionTok{sits\_train}\NormalTok{(samples\_matogrosso\_mod13q1, }\FunctionTok{sits\_rfor}\NormalTok{(}\AttributeTok{num\_trees =} \DecValTok{500}\NormalTok{))}
\CommentTok{\# Classify using Random Forest model and plot the result}
\NormalTok{point\_mt\_4bands }\OtherTok{\textless{}{-}} \FunctionTok{sits\_select}\NormalTok{(point\_mt\_6bands, }\AttributeTok{bands =} \FunctionTok{c}\NormalTok{(}\StringTok{"NDVI"}\NormalTok{, }\StringTok{"EVI"}\NormalTok{, }\StringTok{"NIR"}\NormalTok{, }\StringTok{"MIR"}\NormalTok{))}
\NormalTok{class.tb }\OtherTok{\textless{}{-}}\NormalTok{ point\_mt\_4bands }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{sits\_whittaker}\NormalTok{(}\AttributeTok{lambda =} \FloatTok{0.2}\NormalTok{, }\AttributeTok{bands\_suffix =} \StringTok{""}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{sits\_classify}\NormalTok{(rfor\_model)}
\CommentTok{\# plot classification}
\NormalTok{class.tb }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{plot}\NormalTok{(}\AttributeTok{bands =} \FunctionTok{c}\NormalTok{(}\StringTok{"NDVI"}\NormalTok{, }\StringTok{"EVI"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{sitsbook_files/figure-latex/eval-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# show the results of the prediction}
\FunctionTok{sits\_show\_prediction}\NormalTok{(class.tb)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|l|l}
\hline
from & to & class\\
\hline
2000-09-13 & 2001-08-29 & Forest\\
\hline
2001-09-14 & 2002-08-29 & Forest\\
\hline
2002-09-14 & 2003-08-29 & Forest\\
\hline
2003-09-14 & 2004-08-28 & Pasture\\
\hline
2004-09-13 & 2005-08-29 & Pasture\\
\hline
2005-09-14 & 2006-08-29 & Pasture\\
\hline
2006-09-14 & 2007-08-29 & Pasture\\
\hline
2007-09-14 & 2008-08-28 & Pasture\\
\hline
2008-09-13 & 2009-08-29 & Pasture\\
\hline
2009-09-14 & 2010-08-29 & Soy\_Corn\\
\hline
2010-09-14 & 2011-08-29 & Soy\_Corn\\
\hline
2011-09-14 & 2012-08-28 & Soy\_Corn\\
\hline
2012-09-13 & 2013-08-29 & Soy\_Corn\\
\hline
2013-09-14 & 2014-08-29 & Soy\_Corn\\
\hline
2014-09-14 & 2015-08-29 & Soy\_Corn\\
\hline
2015-09-14 & 2016-08-28 & Soy\_Corn\\
\hline
2016-09-13 & 2017-08-29 & Soy\_Corn\\
\hline
\end{tabular}

The result shows the tendency of the random forest classifier to be robust to outliers and to be able to deal with irrelevant inputs \citep{Hastie2009}. Performs internal variable selection helps the results be robust to outliers and noise, a common feature in image time series. However, despite being robust, random forest tend to overemphasize some variables and thus rarely turn out to be the classifier with the smallest error. One reason is that the performance of random forest tends to stabilise after a part of the trees are grown \citep{Hastie2009}. Random forest classifiers can be quite useful to provide a baseline to compare with more sophisticated methods.

\hypertarget{support-vector-machines}{%
\section{Support Vector Machines}\label{support-vector-machines}}

Given a multidimensional data set, the Support Vector Machine (SVM) method finds an optimal separation hyperplane that minimizes misclassifications \citep{Cortes1995}. Hyperplanes are linear \({(p-1)}\)-dimensional boundaries and define linear partitions in the feature space. The solution for the hyperplane coefficients depends only on those samples that violates the maximum margin criteria, the so-called \emph{support vectors}. All other points far away from the hyperplane does not exert any influence on the hyperplane coefficients which let SVM less sensitive to outliers.

For data that is not linearly separable, SVM includes kernel functions that map the original feature space into a higher dimensional space, providing nonlinear boundaries to the original feature space. In this manner, the new classification model, despite having a linear boundary on the enlarged feature space, generally translates its hyperplane to a nonlinear boundaries in the original attribute space. The use of kernels are an efficient computational strategy to produce nonlinear boundaries in the input attribute space an hence can improve training-class separation. SVM is one of the most widely used algorithms in machine learning applications and has been widely applied to classify remote sensing data \citep{Mountrakis2011}.

In \texttt{sits}, SVM is implemented as a wrapper of \texttt{e1071} R package that uses the \texttt{LIBSVM} implementation \citep{Chang2011}, \texttt{sits} adopts the \emph{one-against-one} method for multiclass classification. For a \(q\) class problem, this method creates \({q(q-1)/2}\) SVM binary models, one for each class pair combination and tests any unknown input vectors throughout all those models. The overall result is computed by a voting scheme.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Train a machine learning model for the mato grosso dataset using SVM}
\CommentTok{\# The parameters are those of the "e1071:svm" method}
\NormalTok{svm\_model }\OtherTok{\textless{}{-}} \FunctionTok{sits\_train}\NormalTok{(samples\_matogrosso\_mod13q1, }
                        \AttributeTok{ml\_method =} \FunctionTok{sits\_svm}\NormalTok{(}\AttributeTok{kernel =} \StringTok{"radial"}\NormalTok{,}
                                             \AttributeTok{cost =} \DecValTok{10}\NormalTok{))}
\CommentTok{\# Classify using SVM model and plot the result}
\NormalTok{class.tb }\OtherTok{\textless{}{-}}\NormalTok{ point\_mt\_4bands }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{sits\_whittaker}\NormalTok{(}\AttributeTok{lambda =} \FloatTok{0.25}\NormalTok{, }\AttributeTok{bands\_suffix =} \StringTok{""}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{sits\_classify}\NormalTok{(svm\_model) }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{plot}\NormalTok{(}\AttributeTok{bands =} \FunctionTok{c}\NormalTok{(}\StringTok{"NDVI"}\NormalTok{, }\StringTok{"EVI"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{sitsbook_files/figure-latex/unnamed-chunk-48-1} \end{center}

The result is mostly consistent of what one could expect by visualising the time series. The area started out as a forest in 2000, it was deforested from 2004 to 2005, used as pasture from 2006 to 2007, and for double-cropping agriculture from 2008 onwards. However, the result shows some inconsistencies. First, since the training dataset does not contain a samples of deforested areas, places where forest is removed will tend to be classified as ``Cerrado'', which is the nearest kind of vegetation cover where trees and grasslands are mixed. This misinterpretation needs to be corrected in post-processing by applying a time-dependent rule (see the main SITS vignette and the post-processing methods vignette). Also, the classification for year 2009 is ``Soy-Millet'', which is different from the ``Soy-Corn'' label assigned from the other years from 2008 to 2017. To test if this result is inconsistent, one could apply spatial post-processing techniques, as discussed in the main SITS vignette and in the post-processing one.

One of the drawbacks of using the \texttt{sits\_svm} method is its sensitivity to its parameters. Using a linear or a polynomial kernel fails to produce good results. If one varies the parameter \texttt{cost} (cost of contraints violation) from 100 to 1, the results can be strinkgly different. Such sensitity to the input parameters points to a limitation when using the SVM method for classifying time series.

\hypertarget{extreme-gradient-boosting}{%
\section{Extreme Gradient Boosting}\label{extreme-gradient-boosting}}

Boosting techniques are based on the idea of starting from a weak predictor and then improving performance sequentially by fitting better model at each iteration. It starts by fitting a simple classifier to the training data. Then it uses the residuals of the regression to build a better prediction. Typically, the base classifier is a regression tree. Although both random forests and boosting use trees for classification, there is an important difference. In the random forest classifier, the same random logic for tree selections is applied at every step \citep{Efron2016}. Boosting trees are built to improve on previous result, by applying finer divisions that improve the performance. The performance of random forests generally increases with the number of trees until it becomes stable; however, the number of trees grown by boosting techniques cannot be too large, at the risk of overfitting the model.

Gradient boosting is a variant of boosting methods where the cost function is minimized by agradient descent algorithm. Extreme gradient boosting \citep{Chen2016}, called ``XGBoost'', improves by using an efficient approximation to the gradient loss function. The algorithm is fast and accurate. XGBoost is considered one of the best statistical learning algorithms available and has won many competitions; it is generally considered to be better than SVM and random forests. However, actual performance is controlled by the quality of the training dataset.

In SITS, the XGBoost method is implemented by the \texttt{sits\_xbgoost()} function, which is based on ``XGBoost'' R package and has five parameters that require tuning. The learning rate \texttt{eta} varies from 0 to 1, but show be kept small (default is 0.3) to avoid overfitting. The minimim loss value \texttt{gamma} specifies the minimum reduction required to make a split. Its default is 0, but increasing it makes the algorithm more conservative. The maximum depth of a tree \texttt{max\_depth} controls how deep tress are to be built. In principle, it should not be largem since higher depth trees lead to overfitting (default is 6.0). The \texttt{subsample} parameter controls the percentage of samples supplied to a tree. Its default is 1 (maximum). Setting it to lower values means that xgboost randomly collects only part of the data instances to grow trees, thus preventing overfitting. The \texttt{nrounds} parameters controls the maximum number of boosting interactions; its default is 100, which has proven to be sufficient in the SITS. In order to follow the convergence of the algorithm, users can turn the \texttt{verbose} parameter on.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Train a machine learning model for the mato grosso dataset using XGBOOST}
\CommentTok{\# The parameters are those of the "xgboost" package}
\NormalTok{xgb\_model }\OtherTok{\textless{}{-}} \FunctionTok{sits\_train}\NormalTok{(samples\_matogrosso\_mod13q1, }\FunctionTok{sits\_xgboost}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
#> [1]  train-mlogloss:2.004165+0.000949    test-mlogloss:2.017935+0.002472 
#> Multiple eval metrics are present. Will use test_mlogloss for early stopping.
#> Will train until test_mlogloss hasn't improved in 20 rounds.
#> 
#> [11] train-mlogloss:0.580213+0.001979    test-mlogloss:0.706275+0.018587 
#> [21] train-mlogloss:0.171118+0.001494    test-mlogloss:0.308789+0.020085 
#> [31] train-mlogloss:0.070622+0.001013    test-mlogloss:0.202104+0.020693 
#> [41] train-mlogloss:0.042007+0.000739    test-mlogloss:0.166077+0.022038 
#> [51] train-mlogloss:0.033411+0.000679    test-mlogloss:0.155640+0.021961 
#> [61] train-mlogloss:0.031596+0.000450    test-mlogloss:0.154295+0.022720 
#> [71] train-mlogloss:0.030872+0.000637    test-mlogloss:0.153480+0.022550 
#> [81] train-mlogloss:0.030470+0.000672    test-mlogloss:0.152929+0.022390 
#> [91] train-mlogloss:0.030242+0.000645    test-mlogloss:0.152482+0.022380 
#> [100]    train-mlogloss:0.029946+0.000430    test-mlogloss:0.152208+0.022703
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Classify using SVM model and plot the result}
\NormalTok{class.tb }\OtherTok{\textless{}{-}}\NormalTok{ point\_mt\_4bands }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{sits\_whittaker}\NormalTok{(}\AttributeTok{lambda =} \FloatTok{0.25}\NormalTok{, }\AttributeTok{bands\_suffix =} \StringTok{""}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{sits\_classify}\NormalTok{(xgb\_model) }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{plot}\NormalTok{(}\AttributeTok{bands =} \FunctionTok{c}\NormalTok{(}\StringTok{"NDVI"}\NormalTok{, }\StringTok{"EVI"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{sitsbook_files/figure-latex/unnamed-chunk-49-1} \end{center}

In general, the results from the extreme gradient boosting model are similar to the Random Forest model. However, for each specific study, users need to perform validation. See the function \texttt{sits\_kfold\_validate} for more details.

\hypertarget{deep-learning-using-multi-layer-perceptrons}{%
\section{Deep learning using multi-layer perceptrons}\label{deep-learning-using-multi-layer-perceptrons}}

Using the \texttt{keras} package \citep{Chollet2018} as a backend, SITS supports the following =deep learning techniques, as described in this section and the next ones. The first method is that of feedforward neural networks, or multi-layer perceptron (MLPs). These are the quintessential deep learning models. The goal of a multilayer perceptrons is to approximate some function \(f\). For example, for a classifier \(y =f(x)\) maps an input \(x\) to a category \(y\). A feedforward network defines a mapping \(y = f(x;\theta)\) and learns the value of the parameters \(\theta\) that result in the best function approximation. These models are called feedforward because information flows through the function being evaluated from \(x\), through the intermediate computations used to define \(f\), and finally to the output \(y\). There are no feedback connections in which outputs of the model are fed back into itself \citep{Goodfellow2016}.

Specifying a MLP requires some work on customization, which requires some amount of trial-and-error by the user, since there is no proven model for classification of satellite image time series. The most important decision is the number of layers in the model. Initial tests indicate that 3 to 5 layers are enough to produce good results. The choice of the number of layers depends on the inherent separability of the data set to be classified. For data sets where the classes have different signatures, a shallow model (with 3 layers) may provide appropriate responses. More complex situations require models of deeper hierarchy. The user should be aware that some models with many hidden layers may take a long time to train and may not be able to converge. The suggestion is to start with 3 layers and test different options of number of neurons per layer, before increasing the number of layers.

Three other important parameters for an MLP are: (a) the activation function; (b) the optimization method; (c) the dropout rate. The activation function the activation function of a node defines the output of that node given an input or set of inputs. Following standard practices \citep{Goodfellow2016}, we recommend the use of the ``relu'' and ``elu'' functions. The optimization method is a crucial choice, and the most common choices are gradient descent algorithm. These methods aim to maximize an objective function by updating the parameters in the opposite direction of the gradient of the objective function \citep{Ruder2016}. Based on experience with image time series, we recommend that users start by using the default method provided by \texttt{sits}, which is the \texttt{optimizer\_adam} method. Please refer to the \texttt{keras} package documentation for more information.

The dropout rates have a huge impact on the performance of MLP classifiers. Dropout is a technique for randomly dropping units from the neural network during training \citep{Srivastava2014}. By randomly discarding some neurons, dropout reduces overfitting. It is a counter-intuitive idea that works well. Since the purpose of a cascade of neural nets is to improve learning as more data is acquired, discarding some of these neurons may seem a waste of resources. In fact, as experience has shown \citep{Goodfellow2016}, this procedures prevents an early convergence of the optimization to a local minimum. Thus, in practice, dropout rates between 50\% and 20\% are recommended for each layer.

In the following example, we classify the same data set using an example of the \texttt{deep\ learning} method. The parameters for the MLP are: (a) Three layers with 512 neurons each, specified by the parameter \texttt{layers}; (b) Using the `elu' activation function; (c) dropout rates of 50\%, 40\% and 30\% for the layers; (d) the ``optimizer\_adam'' as optimizer (default value); (e) a number of training steps (\texttt{epochs}) of 75; (f) a \texttt{batch\_size} of 128, which indicates how many time series are used for input at a given steps; (g) a validation percentage of 20\%, which means 20\% of the samples will be randomly set side for validation. In practice, users may want to increase the number of epochs and the number of layers. In our experience, if the training dataset is of good quality, using 3 to 5 layers is a reasonable compromise. Further increase on the number of layers will not improve the model. If a better performance is required, users should try to use the convolutional models descibed below. To simplify the vignette generation, the \texttt{verbose} option has been turned off. The default value is on. After the model has been generated, we plot its training history.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# train a machine learning model for the Mato Grosso data using an MLP}
\NormalTok{mlp\_model }\OtherTok{\textless{}{-}} \FunctionTok{sits\_train}\NormalTok{(samples\_matogrosso\_mod13q1, }
                        \FunctionTok{sits\_deeplearning}\NormalTok{(}
                        \AttributeTok{layers           =} \FunctionTok{c}\NormalTok{(}\DecValTok{128}\NormalTok{, }\DecValTok{128}\NormalTok{, }\DecValTok{128}\NormalTok{),}
                        \AttributeTok{activation       =} \StringTok{"elu"}\NormalTok{,}
                        \AttributeTok{dropout\_rates    =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.50}\NormalTok{, }\FloatTok{0.40}\NormalTok{, }\FloatTok{0.30}\NormalTok{),}
                        \AttributeTok{epochs           =} \DecValTok{80}\NormalTok{,}
                        \AttributeTok{batch\_size       =} \DecValTok{128}\NormalTok{,}
                        \AttributeTok{verbose          =} \DecValTok{0}\NormalTok{,}
                        \AttributeTok{validation\_split =} \FloatTok{0.2}\NormalTok{) )}

\CommentTok{\# show training evolution}
\FunctionTok{plot}\NormalTok{(mlp\_model)}
\end{Highlighting}
\end{Shaded}

Then, we classify a 16-year time series using the DL model

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Classify using DL model and plot the result}
\NormalTok{point\_mt\_4bands }\OtherTok{\textless{}{-}} \FunctionTok{sits\_select}\NormalTok{(point\_mt\_6bands, }
                               \AttributeTok{bands =} \FunctionTok{c}\NormalTok{(}\StringTok{"NDVI"}\NormalTok{, }\StringTok{"EVI"}\NormalTok{, }\StringTok{"NIR"}\NormalTok{, }\StringTok{"MIR"}\NormalTok{))}
\NormalTok{class.tb }\OtherTok{\textless{}{-}}\NormalTok{ point\_mt\_4bands }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{sits\_classify}\NormalTok{(mlp\_model) }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{plot}\NormalTok{(}\AttributeTok{bands =} \FunctionTok{c}\NormalTok{(}\StringTok{"ndvi"}\NormalTok{, }\StringTok{"evi"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{sitsbook_files/figure-latex/unnamed-chunk-51-1} \end{center}

\hypertarget{d-convolutional-neural-networks}{%
\section{1D Convolutional Neural Networks}\label{d-convolutional-neural-networks}}

Convolutional neural networks (CNN) are a variety of deep learning methods where a convolution filter (sliding window) is applied to the input data. In the case of time series, a 1D CNN works by applying a moving window to the series. Using convolution filters is a way to incorporate temporal autocorrelation information in the classification. The result of the convolution is another time series. \citet{Russwurm2017} states that the use of 1D-CNN for time series classification improves on the use of multi-layer perceptrons, since the classifier is able to represent temporal relationships. Also, 1D-CNNs with a suitable convolution window make the classifier more robust to moderate noise, e.g.~intermittent presence of clouds.

SITS includes four different variations of 1D-CNN, described in what follows. The first one is a ``full Convolutional Neural Network''\citep{Wang2017}, implemented in the \texttt{sits\_FCN} function. FullCNNs are cascading networks, where the size of the input data is kept constant during the convolution. After the nvolutions have been applied, the model includes a global average pooling layer which reduces the number of parameters, and highlights which parts of the input time series contribute the most to the classification \citep{Fawaz2019}. The fullCNN architecture proposed in \citet{Wang2017} has three convolutional layers. Each layer performs a convolution in its input and uses batch normalization for avoiding premature convergence to a local minimum. Batch normalisation is an alternative to dropout \citep{Ioffe2015}. The result is to a ReLU activation function. The result of the third convolutional block is averaged over the whole time dimension which corresponds to a global average pooling layer. Finally, a traditional softmax classifier is used to get the classification results (see figure below).

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth,height=0.8\textheight]{images/fullcnn} 

}

\caption[Structure of fullCNN architecture (source]{Structure of fullCNN architecture (source: Wang et al.(2017))}\label{fig:unnamed-chunk-52}
\end{figure}

The \texttt{sits\_FCN} function uses the architecture proposed by Wang as its default, and allows the users to experiment with different settings. The \texttt{layers} parameter controls the number of layers and the number of filters in each layer. The \texttt{kernels} parameters controls the size of the convolution kernels for earh layer. In the example below, the first convolution uses 64 filters with a kernel size of 8, followed by a second convolution of 128 filters with a kernel size of 5, and a third and final convolutional layer with 64 filters, each one with a kernel size to 3.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# train a machine learning model using deep learning}
\NormalTok{fcn\_model }\OtherTok{\textless{}{-}} \FunctionTok{sits\_train}\NormalTok{(samples\_matogrosso\_mod13q1, }
                        \FunctionTok{sits\_FCN}\NormalTok{(}
                            \AttributeTok{layers           =} \FunctionTok{c}\NormalTok{(}\DecValTok{64}\NormalTok{, }\DecValTok{256}\NormalTok{, }\DecValTok{64}\NormalTok{),}
                            \AttributeTok{kernels          =} \FunctionTok{c}\NormalTok{(}\DecValTok{8}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{),}
                            \AttributeTok{activation       =} \StringTok{\textquotesingle{}relu\textquotesingle{}}\NormalTok{,}
                            \AttributeTok{L2\_rate          =} \FloatTok{1e{-}06}\NormalTok{,}
                            \AttributeTok{epochs           =} \DecValTok{100}\NormalTok{,}
                            \AttributeTok{batch\_size       =} \DecValTok{128}\NormalTok{,}
                            \AttributeTok{verbose          =} \DecValTok{0}\NormalTok{) )}
\CommentTok{\# show training evolution}
\FunctionTok{plot}\NormalTok{(fcn\_model)}
\end{Highlighting}
\end{Shaded}

Then, we classify a 16-year time series using the FCN model

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Classify using DL model and plot the result}
\NormalTok{point\_mt\_4bands }\OtherTok{\textless{}{-}} \FunctionTok{sits\_select}\NormalTok{(point\_mt\_6bands, }
                               \AttributeTok{bands =} \FunctionTok{c}\NormalTok{(}\StringTok{"NDVI"}\NormalTok{, }\StringTok{"EVI"}\NormalTok{, }\StringTok{"NIR"}\NormalTok{, }\StringTok{"MIR"}\NormalTok{))}
\NormalTok{class.tb }\OtherTok{\textless{}{-}}\NormalTok{ point\_mt\_4bands }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{sits\_classify}\NormalTok{(fcn\_model) }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{plot}\NormalTok{(}\AttributeTok{bands =} \FunctionTok{c}\NormalTok{(}\StringTok{"ndvi"}\NormalTok{, }\StringTok{"evi"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{sitsbook_files/figure-latex/unnamed-chunk-54-1} \end{center}

\hypertarget{residual-1d-cnn-networks-resnet}{%
\section{Residual 1D CNN Networks (ResNet)}\label{residual-1d-cnn-networks-resnet}}

The Residual Network (ResNet) is a variation of the fullCNN network proposed by \citet{Wang2017}. ResNet is composed of 11 layers (see figure below). ResNet is a deep network, by default divided in three blocks of three 1D CNN layers each. Each block corresponds to a fullCNN network archicture. The output of each block is combined with a shortcut that links its output to its input. The idea is avoid the so-called ``vanishing gradient'', which occurs when a deep learning network is trained based gradient optimization methods\citep{Hochreiter1998}. As the networks get deeper, otimising them becomes more difficult. Including the input layer of the block at its end is a heuristic that has shown to be effective. In a recent review of time series classification methods using deep learning, Fawaz et al.~state the RestNet and fullCNN have the best performance on the UCR/UEA time series test archive \citep{Fawaz2019}.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth,height=0.8\textheight]{images/resnet} 

}

\caption[Structure of ResNet architecture (source]{Structure of ResNet architecture (source: Wang et al.(2017))}\label{fig:unnamed-chunk-55}
\end{figure}

In SITS, the ResNet is implemented using the \texttt{sits\_resnet} function. The default parameters are those proposed by \citet{Wang2017}, and we also benefited from the code provided by \citet{Fawaz2019} ( \url{https://github.com/hfawaz/dl-4-tsc}). The first parameter is \texttt{blocks}, which controls the number of blocks and the size of filters in each block. By default, the model implements three blocks, the first with 64 filters and the others with 128 filters. Users can control the number of blocks and filter size by changing this parameter. The parameter \texttt{kernels} controls the size the of kernels of the three layers inside each block. We have found out that it is useful to experiment a bit with these kernel sizes in the case of satellite image time series. The default activation is ``relu'', which is recommended in the literature to reduce the problem of vanishing gradients. The default optimizer is the same as proposed in \citet{Wang2017} and \citet{Fawaz2019}. In the case of the 2-band Mato Grosso data set, the estimated accuracy is 95.8\%.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# train a machine learning model using ResNet}
\NormalTok{point\_mt\_4bands }\OtherTok{\textless{}{-}} \FunctionTok{sits\_select}\NormalTok{(point\_mt\_6bands, }
                               \AttributeTok{bands =} \FunctionTok{c}\NormalTok{(}\StringTok{"NDVI"}\NormalTok{, }\StringTok{"EVI"}\NormalTok{, }\StringTok{"NIR"}\NormalTok{, }\StringTok{"MIR"}\NormalTok{))}
\NormalTok{resnet\_model }\OtherTok{\textless{}{-}} \FunctionTok{sits\_train}\NormalTok{(samples\_matogrosso\_mod13q1, }
                       \FunctionTok{sits\_ResNet}\NormalTok{(}
                          \AttributeTok{blocks               =} \FunctionTok{c}\NormalTok{(}\DecValTok{32}\NormalTok{, }\DecValTok{64}\NormalTok{, }\DecValTok{64}\NormalTok{),}
                          \AttributeTok{kernels              =} \FunctionTok{c}\NormalTok{(}\DecValTok{9}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{3}\NormalTok{),}
                          \AttributeTok{activation           =} \StringTok{\textquotesingle{}relu\textquotesingle{}}\NormalTok{,}
                          \AttributeTok{epochs               =} \DecValTok{100}\NormalTok{,}
                          \AttributeTok{batch\_size           =} \DecValTok{128}\NormalTok{,}
                          \AttributeTok{validation\_split     =} \FloatTok{0.2}\NormalTok{,}
                          \AttributeTok{verbose              =} \DecValTok{0}\NormalTok{) )}
\CommentTok{\# show training evolution}
\FunctionTok{plot}\NormalTok{(resnet\_model)}
\end{Highlighting}
\end{Shaded}

Then, we classify a 16-year time series using the DL model

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Classify using DL model and plot the result}
\NormalTok{point\_mt\_4bands }\OtherTok{\textless{}{-}} \FunctionTok{sits\_select}\NormalTok{(point\_mt\_6bands, }
                               \AttributeTok{bands =} \FunctionTok{c}\NormalTok{(}\StringTok{"NDVI"}\NormalTok{, }\StringTok{"EVI"}\NormalTok{, }\StringTok{"NIR"}\NormalTok{, }\StringTok{"MIR"}\NormalTok{))}
\NormalTok{class.tb }\OtherTok{\textless{}{-}}\NormalTok{ point\_mt\_4bands }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{sits\_classify}\NormalTok{(resnet\_model) }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{plot}\NormalTok{(}\AttributeTok{bands =} \FunctionTok{c}\NormalTok{(}\StringTok{"NDVI"}\NormalTok{, }\StringTok{"EVI"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{sitsbook_files/figure-latex/unnamed-chunk-57-1} \end{center}

\hypertarget{combined-1d-cnn-and-multi-layer-perceptron-networks}{%
\section{Combined 1D CNN and multi-layer perceptron networks}\label{combined-1d-cnn-and-multi-layer-perceptron-networks}}

The combination of 1D CNNs and multi-layer perceptron models for satellite image time series classification was first proposed in \citet{Pelletier2019}. The so-called ``tempCNN'' architecture consists of a number of 1D-CNN layers, similar to the fullCNN model discussed above, whose output is fed into a set of multi-layer perceptrons. The original tempCNN architecture is composed of three 1D convolutional layers (each with 64 units), one dense layer of 256 units and a final softmax layer for classification (see figure). The kernel size of the convolution filters is set to 5. The authors use a combination of different methods to avoid overfitting and reduce the vanishing gradiente effect, including dropout, regularization, and batch normalisation. In the tempCNN paper \citep{Pelletier2019}, the authors compare favourably the tempCNN model with the Recurrent Neural Network proposed by \citet{Russwurm2018} for land use classification. The figure below shows the architecture of the tempCNN model.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth,height=0.8\textheight]{images/tempcnn} 

}

\caption[Structure of tempCNN architecture (source]{Structure of tempCNN architecture (source: Pelletier et al.(2019))}\label{fig:unnamed-chunk-58}
\end{figure}

The function \texttt{sits\_tempCNN} implements the model, using the default parameters proposed by \citet{Pelletier2019}. The code has been derived from the Python source provided by the authors (\url{https://github.com/charlotte-pel/temporalCNN}). The parameter \texttt{cnn\_layers} controls the number of 1D-CNN layers and the size of the filters applied at each layer; the parameter \texttt{cnn\_kernels} indicates the size of the convolution kernels. Activation, regularisation for all 1D-CNN layers are set, respectively, by the \texttt{cnn\_activation}, \texttt{cnn\_L2\_rate}. The dropout rates for each 1D-CNN layer are controlled individually by the parameter \texttt{cnn\_dropout\_rates}. The parameters \texttt{mlp\_layers} and \texttt{mlp\_dropout\_rates} allow the user to set the number and size of the desired MLP layers, as well as their dropout\_rates. The activation of the MLP layers is controlled by \texttt{mlp\_activation}. By default, the function uses the ADAM optimizer, but any of the optimizers available in the \texttt{keras} package can be used. The \texttt{validation\_split} controls the size of the test set, relative to the full data set. We recommend to set aside at least 20\% of the samples for validation. In the case of the 2-band Mato Grosso data set, the estimated accuracy is 95.5\%.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# train a machine learning model using tempCNN}
\NormalTok{tCNN\_model }\OtherTok{\textless{}{-}} \FunctionTok{sits\_train}\NormalTok{(samples\_matogrosso\_mod13q1, }
                       \FunctionTok{sits\_TempCNN}\NormalTok{(}
                          \AttributeTok{cnn\_layers           =} \FunctionTok{c}\NormalTok{(}\DecValTok{32}\NormalTok{, }\DecValTok{32}\NormalTok{, }\DecValTok{32}\NormalTok{),}
                          \AttributeTok{cnn\_kernels          =} \FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{),}
                          \AttributeTok{cnn\_activation       =} \StringTok{\textquotesingle{}relu\textquotesingle{}}\NormalTok{,}
                          \AttributeTok{cnn\_L2\_rate          =} \FloatTok{1e{-}06}\NormalTok{,}
                          \AttributeTok{cnn\_dropout\_rates    =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.50}\NormalTok{, }\FloatTok{0.50}\NormalTok{, }\FloatTok{0.50}\NormalTok{),}
                          \AttributeTok{mlp\_layers           =} \FunctionTok{c}\NormalTok{(}\DecValTok{256}\NormalTok{),}
                          \AttributeTok{mlp\_activation       =} \StringTok{\textquotesingle{}relu\textquotesingle{}}\NormalTok{,}
                          \AttributeTok{mlp\_dropout\_rates    =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.50}\NormalTok{),}
                          \AttributeTok{epochs               =} \DecValTok{60}\NormalTok{,}
                          \AttributeTok{batch\_size           =} \DecValTok{128}\NormalTok{,}
                          \AttributeTok{validation\_split     =} \FloatTok{0.2}\NormalTok{,}
                          \AttributeTok{verbose              =} \DecValTok{0}\NormalTok{) )}

\CommentTok{\# show training evolution}
\FunctionTok{plot}\NormalTok{(tCNN\_model)}
\end{Highlighting}
\end{Shaded}

Then, we classify a 16-year time series using the DL model

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Classify using DL model and plot the result}
\NormalTok{point\_mt\_4bands }\OtherTok{\textless{}{-}} \FunctionTok{sits\_select}\NormalTok{(point\_mt\_6bands, }
                               \AttributeTok{bands =} \FunctionTok{c}\NormalTok{(}\StringTok{"NDVI"}\NormalTok{, }\StringTok{"EVI"}\NormalTok{, }\StringTok{"NIR"}\NormalTok{, }\StringTok{"MIR"}\NormalTok{))}
\NormalTok{class.tb }\OtherTok{\textless{}{-}}\NormalTok{ point\_mt\_4bands }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{sits\_classify}\NormalTok{(tCNN\_model) }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{plot}\NormalTok{(}\AttributeTok{bands =} \FunctionTok{c}\NormalTok{(}\StringTok{"ndvi"}\NormalTok{, }\StringTok{"evi"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{sitsbook_files/figure-latex/unnamed-chunk-60-1} \end{center}

\hypertarget{lstm-convolutional-networks-for-time-series-classification}{%
\section{LSTM Convolutional Networks for Time Series Classification}\label{lstm-convolutional-networks-for-time-series-classification}}

Given the success of 1D-CNN networks for time series classification, there have been a number of variants proposed in the literature. One of these variants is the LSTM-CNN network \citep{Karim2018}, where a fullCNN is combined with long short term memory (LSTM) recurrent neural network. LSTMs are an improved version of recurrent neural networks (RNN). An RNN is a neural network that includes a state vector, which is updated every time step. In this way, a RNN combines an input vector with information that is kept from all previous inputs. One can conceive of RNN as networks that have loops, allowing information to be passed from one step to to the next. In theory, a RNN would be able to handle long-term dependencies between elements of the input vectors. In practice, they are prone to the exhibit the ``vanishing gradient'' effect. As discussed above, in deep neural networks architectures with gradient descent optimization the gradient function can approach zero, thus impeding training to be done efficiently. LSTM improve on RNN architecture by including the additional feature of being able to regulate whether or not new information should be included on the cell state. LSTM unit also include a forget gate, which is able to discard the previous information stored in the cell state. Thus, a LSTM unit is able to remember values over arbitrary time intervals.

\citet{Karim2019} consider that LSTM networks are ``well-suited to classifying, processing and making predictions based on time series data, since there can be lags of unknown duration between important events in a time series''. The authors proposed a mixed LSTM-CNN architecture, composed of two paralel data streams: a 3-step CNN such as the one implemented in \texttt{sits\_FCN} (see above) combined with a data stream consisting of an LSTM unit, as shown in the figure below. In \citet{Karim2018}, the authors argue the LSTM-CNN model is capable of a better performance in the UCR/UEA time series test set than architectures such as ResNet and fullCNN.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth,height=0.8\textheight]{images/lstm-cnn} 

}

\caption[LSTM Fully Convolutional Networks for Time Series Classification (source]{LSTM Fully Convolutional Networks for Time Series Classification (source: Karim et al.(2019))}\label{fig:unnamed-chunk-61}
\end{figure}

In the SITS package, the combined LSTM-CNN architecture is implemented by the \texttt{sits\_LSTM\_CNN} function. The default values are similar those proposed by \citet{Karim2019}. The parameter \texttt{lstm\_units} controls the number of units in the LSTM cell at every time step of the network. \citet{Karim2019b} proposes an LSTM with 8 units, each with a dropout rate of 80\%, which are controlled by parameters \texttt{lstm\_units} and \texttt{lstm\_dropout}. In initial experiments, we got a better performance with an LSTM with 16 units. As proposed by \citet{Karim2019b}, the CNN layers have filter sizes of \{128, 256, 128\} and kernel convolution sizes of \{8, 5, 3\}, controlled by the parameters \texttt{cnn\_layers} and \texttt{cnn\_kernels}. One should experiment with these parameters, and consider the simulations carried out by \citet{Pelletier2019} (see above), where the authors found that an FCN network of sizes \{64, 64, 64\} with kernels sizes of \{5, 5, 5\} had best performance in their case study. In this example, the estimated accuracy of the model was 94.7\%.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lstm\_fcn\_model }\OtherTok{\textless{}{-}} \FunctionTok{sits\_train}\NormalTok{(samples\_matogrosso\_mod13q1, }
                       \FunctionTok{sits\_LSTM\_FCN}\NormalTok{(}
                          \AttributeTok{lstm\_units          =} \DecValTok{16}\NormalTok{,}
                          \AttributeTok{lstm\_dropout        =} \FloatTok{0.80}\NormalTok{,}
                          \AttributeTok{cnn\_layers          =} \FunctionTok{c}\NormalTok{(}\DecValTok{64}\NormalTok{, }\DecValTok{64}\NormalTok{, }\DecValTok{64}\NormalTok{),}
                          \AttributeTok{cnn\_kernels         =} \FunctionTok{c}\NormalTok{(}\DecValTok{8}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{),}
                          \AttributeTok{activation          =} \StringTok{\textquotesingle{}relu\textquotesingle{}}\NormalTok{,}
                          \AttributeTok{epochs              =} \DecValTok{120}\NormalTok{,}
                          \AttributeTok{batch\_size          =} \DecValTok{128}\NormalTok{,}
                          \AttributeTok{validation\_split    =} \FloatTok{0.2}\NormalTok{,}
                          \AttributeTok{verbose             =} \DecValTok{0}\NormalTok{) )}

\CommentTok{\# show training evolution}
\FunctionTok{plot}\NormalTok{(lstm\_fcn\_model)}
\end{Highlighting}
\end{Shaded}

Then, we classify a 16-year time series using the DL model

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Classify using DL model and plot the result}
\NormalTok{point\_mt\_4bands }\OtherTok{\textless{}{-}} \FunctionTok{sits\_select}\NormalTok{(point\_mt\_6bands, }
                               \AttributeTok{bands =} \FunctionTok{c}\NormalTok{(}\StringTok{"NDVI"}\NormalTok{, }\StringTok{"EVI"}\NormalTok{, }\StringTok{"NIR"}\NormalTok{, }\StringTok{"MIR"}\NormalTok{))}
\NormalTok{class.tb }\OtherTok{\textless{}{-}}\NormalTok{ point\_mt\_4bands }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{sits\_classify}\NormalTok{(lstm\_fcn\_model) }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{plot}\NormalTok{(}\AttributeTok{bands =} \FunctionTok{c}\NormalTok{(}\StringTok{"ndvi"}\NormalTok{, }\StringTok{"evi"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{sitsbook_files/figure-latex/unnamed-chunk-63-1} \end{center}

\hypertarget{classification-of-images-in-data-cubes-using-satellite-image-time-series}{%
\chapter{Classification of Images in Data Cubes using Satellite Image Time Series}\label{classification-of-images-in-data-cubes-using-satellite-image-time-series}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

This chapter shows the use of the SITS package for classification of satellite images that are associated to Earth observation data cubes.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{image-data-cubes-as-the-basis-for-big-earth-observation-data-analysis-1}{%
\section{Image data cubes as the basis for big Earth observation data analysis}\label{image-data-cubes-as-the-basis-for-big-earth-observation-data-analysis-1}}

In broad terms, the cloud computing model is one where large satellite-generated data sets are archived on cloud services, which also provide computing facilities to process them. By using cloud services, users can share big Earth observation databases and minimize the amount of data download. Investment in infrastructure is minimised and sharing of data and software increases. However, data available in the cloud is best organised for analysis by creating data cubes.

Generalising \citet{Appel2019}, we consider that a data cube is a four-dimensional structure with dimensions x (longitude or easting), y (latitude or northing), time, and bands. Its spatial dimensions refer to a single spatial reference system (SRS). Cells of a data cube have a constant spatial size (with regard to the cube's SRS). The temporal dimension is specified by a set of intervals. For every combination of dimensions, a cell has a single value. Data cubes are particularly amenable for machine learning techniques; their data cane be transformed into arrays in memory, which can be fed to training and classification algorithms. Given the widespread availability of large data sets of Earth observation data, there is a growing interest in organising large sets of data into ``data cubes''.

As explained below, a data cube is the data type used in \texttt{sits} to handle dense raster data. Many of the operations involve creating, transforming and analysing data cubes.

\hypertarget{defining-a-data-cube-using-files-organised-as-raster-bricks}{%
\section{Defining a data cube using files organised as raster bricks}\label{defining-a-data-cube-using-files-organised-as-raster-bricks}}

The SITS package enables uses to create data cube based on files. In this case, these files should be organized as \texttt{raster\ bricks}. A RasterBrick is a multi-layer raster object used by the \emph{R} \texttt{raster} package. Each brick is a multi-layer file, containing different time instances of one spectral band. To allow users to create data cubes based on files, SITS needs to know what is the timeline of the data sets and what are the names of the files that contain the RasterBricks. The example below shows one bricks containing 392 time instances of the ``ndvi'' band for the years 2000 to 2016. The timeline is available as part of the SITS package. In this example, as in most cases using raster bricks, images are stored as GeoTiff files.

Since GeoTiff files do not contain information about satellites and sensors, it is best practice to provide information on satellite and sensor.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Obtain a raster cube with 23 instances for one year}
\CommentTok{\# Select the band "ndvi", "evi" from images available in the "sitsdata" package}
\NormalTok{data\_dir }\OtherTok{\textless{}{-}} \FunctionTok{system.file}\NormalTok{(}\StringTok{"extdata/sinop"}\NormalTok{, }\AttributeTok{package =} \StringTok{"sitsdata"}\NormalTok{)}

\CommentTok{\# create a raster metadata file based on the information about the files}
\NormalTok{raster\_cube }\OtherTok{\textless{}{-}} \FunctionTok{sits\_cube}\NormalTok{(}\AttributeTok{source =} \StringTok{"LOCAL"}\NormalTok{,}
                         \AttributeTok{satellite =} \StringTok{"TERRA"}\NormalTok{,}
                         \AttributeTok{sensor  =} \StringTok{"MODIS"}\NormalTok{,}
                         \AttributeTok{name =} \StringTok{"Sinop"}\NormalTok{,}
                         \AttributeTok{data\_dir =}\NormalTok{ data\_dir,}
                         \AttributeTok{parse\_info =} \FunctionTok{c}\NormalTok{(}\StringTok{"X1"}\NormalTok{, }\StringTok{"X2"}\NormalTok{, }\StringTok{"band"}\NormalTok{, }\StringTok{"date"}\NormalTok{),}
\NormalTok{)}

\CommentTok{\# get information on the data cube }
\NormalTok{raster\_cube }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(source, satellite, sensor)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|l|l}
\hline
source & satellite & sensor\\
\hline
LOCAL & TERRA & MODIS\\
\hline
\end{tabular}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# get information on the coverage}
\NormalTok{raster\_cube }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(xmin, xmax, ymin, ymax)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{r|r|r|r}
\hline
xmin & xmax & ymin & ymax\\
\hline
-6087719 & -5984864 & -1355172 & -1256255\\
\hline
\end{tabular}

To create the raster cube, we a set of consistent raster bricks (one for each satellite band) and a \texttt{timeline} that matches the input images of the raster brick. Once created, the coverage can be used either to retrieve time series data from the raster bricks using \texttt{sits\_get\_data()} or to do the raster classification by calling the function \texttt{sits\_classify}.

\hypertarget{classification-using-machine-learning-1}{%
\section{Classification using machine learning}\label{classification-using-machine-learning-1}}

There has been much recent interest in using classifiers such as support vector machines \citep{Mountrakis2011} and random forests \citep{Belgiu2016} for remote sensing images. Most often, researchers use a \emph{space-first, time-later} approach, in which the dimension of the decision space is limited to the number of spectral bands or their transformations. Sometimes, the decision space is extended with temporal attributes. To do this, researchers filter the raw data to get smoother time series \citep{Brown2013, Kastens2017}. Then, using software such as TIMESAT \citep{Jonsson2004}, they derive a small set of phenological parameters from vegetation indexes, like the beginning, peak, and length of the growing season \citep{Estel2015, Pelletier2016}.

In a recent review of machine learning methods to classify remote sensing data \citep{Maxwell2018}, the authors note that many factors influence the performance of these classifiers, including the size and quality of the training dataset, the dimension of the feature space, and the choice of the parameters. We support both \emph{space-first, time-later} and \emph{time-first, space-later} approaches. Therefore, the \texttt{sits} package provides functionality to explore the full depth of satellite image time series data.

When used in \emph{time-first, space-later} approache, \texttt{sits} treats time series as a feature vector. To be consistent, the procedure aligns all time series from different years by its time proximity considering an given cropping schedule. Once aligned, the feature vector is formed by all pixel ``bands''. The idea is to have as many temporal attributes as possible, increasing the dimension of the classification space. In this scenario, statistical learning models are the natural candidates to deal with high-dimensional data: learning to distinguish all land cover and land use classes from trusted samples exemplars (the training data) to infer classes of a larger data set.

The SITS package provides a common interface to all machine learning models, using the \texttt{sits\_train} function. this function takes two parameters: the input data samples and the ML method (\texttt{ml\_method}), as shown below. After the model is estimated, it can be used to classify individual time series or full data cubes using the \texttt{sits\_classify} function. In the examples that follow, we show how to apply each method for the classification of a single time series. Then, we disscuss how to classify full data cubes.

The following methods are available in SITS for training machine learning models:

\begin{itemize}
\tightlist
\item
  Linear discriminant analysis (\texttt{sits\_lda})
\item
  Quadratic discriminant analysis (\texttt{sits\_qda})
\item
  Multinomial logit and its variants `lasso' and `ridge' (\texttt{sits\_mlr})
\item
  Support vector machines (\texttt{sits\_svm})
\item
  Random forests (\texttt{sits\_rfor})
\item
  Extreme gradient boosting (\texttt{sits\_xgboost})
\item
  Deep learning (DL) using multi-layer perceptrons (\texttt{sits\_deeplearning})
\item
  DL with 1D convolutional neural networks (\texttt{sits\_CNN}),
\item
  DL combining 1D CNN and multi-layer perceptron networks (\texttt{sits\_tempCNN})
\item
  DL using 1D version of ResNet (\texttt{sits\_ResNet}).
\item
  DL using a combination of long-short term memory (LSTM) and 1D CNN (\texttt{sits\_LSTM\_FCN})
\end{itemize}

For more details on each method, please see the vignette ``Machine Learning for Data Cubes using the SITS package''.

\hypertarget{cube-classification-1}{%
\section{Cube classification}\label{cube-classification-1}}

The continuous observation of the Earth surface provided by orbital sensors is unprecedented in history. Just for the sake of illustration, a unique tile from MOD13Q1 product, a square of \(4800\) pixels provided every 16 days since February 2000 takes around \(18\)GB of uncompressed data to store only one band or vegetation index. This data deluge puts the field into a big data era and imposes challenges to design and build technologies that allow the Earth observation community to analyse those data sets \citep{Camara2017}.

To classify a data cube, use the function \texttt{sits\_classify()} as described below. This function works with cubes built from raster bricks. The classification algorithms allows users to choose how many process will run the task in parallel, and also the size of each data chunk to be consumed at each iteration. This strategy enables \texttt{sits} to work on average desktop computers without depleting all computational resources. The code bellow illustrates how to classify a small raster brick image that accompany the package.

\hypertarget{steps-for-cube-classification}{%
\subsection{Steps for cube classification}\label{steps-for-cube-classification}}

Once a data cube which has associated files is defined, the steps for classification are:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Select a set of training samples.
\item
  Train a machine learning model
\item
  Classify the data cubes using the model, producing a data cube with class probabilities.
\item
  Label the cube with probabilities, including data smoothing if desired.
\end{enumerate}

\hypertarget{adjustments-for-improved-performance}{%
\subsection{Adjustments for improved performance}\label{adjustments-for-improved-performance}}

To reduce processing time, it is necessary to adjust \texttt{sits\_classify()} according to the capabilities of the server. The package tries to keep memory use to a minimum, performing garbage collection to free memory as often as possible. Nevertheless, there is an inevitable trade-off between computing time, memory use, and I/O operations. The best trade-off has to be determined by the user, considering issues such disk read speed, number of cores in the server, and CPU performance.

The first parameter is \texttt{memsize}. It controls the size of the main memory (in GBytes) to be used for classification. The user must specify how much free memory will be available. The second factor controlling performance of raster classification is \texttt{multicores}. Once a block of data is read from disk into main memory, it is split into different cores, as specified by the user. In general, the more cores are assigned to classification, the faster the result will be. However, there are overheads in switching time, especially when the server has other processes running.

Based on current experience, the classification of a MODIS tile (4800 x 4800) with four bands and 400 time instances, covering 15 years of data, using SVM with a training data set of about 10,000 samples, takes about 24 hours using 20 cores and a memory size of 60 GB, in a server with 2.4GHz Xeon CPU and 96 GB of memory to produce the yearly classification maps.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# select the bands "ndvi", "evi"}
\NormalTok{samples\_2bands }\OtherTok{\textless{}{-}} \FunctionTok{sits\_select}\NormalTok{(samples\_matogrosso\_mod13q1, }\AttributeTok{bands =} \FunctionTok{c}\NormalTok{(}\StringTok{"NDVI"}\NormalTok{, }\StringTok{"EVI"}\NormalTok{))}

\CommentTok{\#select a rfor model}
\NormalTok{xgb\_model }\OtherTok{\textless{}{-}} \FunctionTok{sits\_train}\NormalTok{(samples\_2bands, }\AttributeTok{ml\_method =} \FunctionTok{sits\_xgboost}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
#> [1]  train-mlogloss:2.009944+0.000892    test-mlogloss:2.022906+0.001491 
#> Multiple eval metrics are present. Will use test_mlogloss for early stopping.
#> Will train until test_mlogloss hasn't improved in 20 rounds.
#> 
#> [11] train-mlogloss:0.620737+0.002764    test-mlogloss:0.755199+0.005152 
#> [21] train-mlogloss:0.207436+0.001456    test-mlogloss:0.364395+0.009251 
#> [31] train-mlogloss:0.094411+0.000752    test-mlogloss:0.251361+0.008440 
#> [41] train-mlogloss:0.059334+0.000473    test-mlogloss:0.211024+0.009399 
#> [51] train-mlogloss:0.048914+0.000651    test-mlogloss:0.197786+0.009918 
#> [61] train-mlogloss:0.045721+0.000552    test-mlogloss:0.194586+0.010300 
#> [71] train-mlogloss:0.044009+0.000838    test-mlogloss:0.192748+0.010751 
#> [81] train-mlogloss:0.043003+0.000582    test-mlogloss:0.191353+0.011066 
#> [91] train-mlogloss:0.042301+0.000387    test-mlogloss:0.190409+0.011007 
#> [100]    train-mlogloss:0.042005+0.000349    test-mlogloss:0.189918+0.011470
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_dir }\OtherTok{\textless{}{-}} \FunctionTok{system.file}\NormalTok{(}\StringTok{"extdata/sinop"}\NormalTok{, }\AttributeTok{package =} \StringTok{"sitsdata"}\NormalTok{)}

\CommentTok{\# create a raster metadata file based on the information about the files}
\NormalTok{sinop }\OtherTok{\textless{}{-}} \FunctionTok{sits\_cube}\NormalTok{(}\AttributeTok{source =} \StringTok{"LOCAL"}\NormalTok{,}
                   \AttributeTok{satellite =} \StringTok{"TERRA"}\NormalTok{,}
                   \AttributeTok{sensor  =} \StringTok{"MODIS"}\NormalTok{,}
                   \AttributeTok{name =} \StringTok{"Sinop"}\NormalTok{,}
                   \AttributeTok{data\_dir =}\NormalTok{ data\_dir,}
                   \AttributeTok{parse\_info =} \FunctionTok{c}\NormalTok{(}\StringTok{"X1"}\NormalTok{, }\StringTok{"X2"}\NormalTok{, }\StringTok{"band"}\NormalTok{, }\StringTok{"date"}\NormalTok{))}

\CommentTok{\# classify the raster image}
\NormalTok{sinop\_probs }\OtherTok{\textless{}{-}} \FunctionTok{sits\_classify}\NormalTok{(sinop, }\AttributeTok{ml\_model =}\NormalTok{ xgb\_model, }
                             \AttributeTok{memsize =} \DecValTok{4}\NormalTok{, }\AttributeTok{multicores =} \DecValTok{1}\NormalTok{, }
                             \AttributeTok{output\_dir =} \FunctionTok{tempdir}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
#> 
#> Attaching package: 'purrr'
\end{verbatim}

\begin{verbatim}
#> The following object is masked from 'package:magrittr':
#> 
#>     set_names
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# label the probability file }
\CommentTok{\# (by default selecting the class with higher probability)}
\NormalTok{sinop\_label }\OtherTok{\textless{}{-}} \FunctionTok{sits\_label\_classification}\NormalTok{(sinop\_probs, }\AttributeTok{output\_dir =} \FunctionTok{tempdir}\NormalTok{())}
\FunctionTok{plot}\NormalTok{(sinop\_label, }\AttributeTok{title =} \StringTok{"Sinop{-}label"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.7\linewidth]{sitsbook_files/figure-latex/unnamed-chunk-66-1} \end{center}

\hypertarget{final-remarks}{%
\section{Final remarks}\label{final-remarks}}

Current approaches to image time series analysis still use limited number of attributes. A common approach is deriving a small set of phenological parameters from vegetation indices, like beginning, peak, and length of growing season \citep{Brown2013}, \citep{Kastens2017}, \citep{Estel2015}, \citep{Pelletier2016}. These phenological parameters are then fed in specialized classifiers such as TIMESAT \citep{Jonsson2004}. These approaches do not use the power of advanced statistical learning techniques to work on high-dimensional spaces with big training data sets \citep{James2013}.

Package \texttt{sits} can use the full depth of satellite image time series to create larger dimensional spaces. We tested different methods of extracting attributes from time series data, including those reported by \citet{Pelletier2016} and \citet{Kastens2017}. Our conclusion is that part of the information in raw time series is lost after filtering. Thus, the method we developed uses all the data available in the time series samples. The idea is to have as many temporal attributes as possible, increasing the dimension of the classification space. Our experiments found out that modern statistical models such as support vector machines, and random forests perform better in high-dimensional spaces than in lower dimensional ones.

\hypertarget{part-post-classification}{%
\part{Post classification}\label{part-post-classification}}

\hypertarget{post-classification-smoothing-using-bayesian-techniques-in-sits}{%
\chapter{Post classification smoothing using Bayesian techniques in SITS}\label{post-classification-smoothing-using-bayesian-techniques-in-sits}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

This chapter describes a Bayesian smoothing method to reclassify the pixels,
based on the machine learning probabilities. We consider that the output of the
machine learning algorithm provides, for each pixel, the information on the probability
of such pixel belonging to each of the target classes. Usually, we label a pixel
as being of a given class if the associated class probability is higher than the
probability of it belonging to any of the other classes. The observation of the
class probabilities of each pixel is taken as our initial belief on what the actual
class of the pixel is. We then use Bayes' rule to consider how much the class probabilities
of the neighbouring pixels affect our original belief.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{introduction-1}{%
\section{Introduction}\label{introduction-1}}

Image classification post-processing has been defined as ``a refinement of the labelling in a classified image in order to enhance its classification accuracy'' \citep{Huang2014}. In remote sensing image analysis, these procedures are used to combine pixel-based classification methods with a spatial post-processing method to remove outliers and misclassified pixels. For pixel-based classifiers, post-processing methods enable the inclusion of spatial information in the final results.

Post-processing is a desirable step in any classification process. Most statistical classifiers use training samples derived from ``pure'' pixels, that have been selected by users as representative of the desired output classes. However, images contain many mixed pixels irrespective of the resolution. Also, there is a considerable degree of data variability in each class. These effects lead to outliers whose chance of misclassification is significant. To offset these problems, most post-processing methods use the ``smoothness assumption'' \citep{Schindler2012}: nearby pixels tend to have the same label. To put this assumption in practice, smoothing methods use the neighbourhood information to remove outliers and enhance consistency in the resulting product.

Smoothing methods are an important complement to machine learning algorithms for image classification. Since these methods are mostly pixel-based, it is useful to complement them with post-processing smoothing to include spatial information in the result. A traditional choice for smoothing classified images is the majority filter, where the class of the central pixel is replaced by the most frequent class of the neighbourhood. This technique is rather simplistic; more sophisticated methods use class probabilities. For each pixel, machine learning and other statistical algorithms provide the probabilities of that pixel belonging to each of the classes. As a first step in obtaining a result, each pixel is assigned to the class whose probability is higher. After this step, smoothing methods use class probabilities to detect and correct outliers or misclassified pixels.

In this vignette, we introduce a Bayesian smoothing method, which provides the means to incorporate prior knowledge in data analysis. Bayesian inference can be thought of as way of coherently updating our uncertainty in the light of new evidence. It allows the inclusion of expert knowledge on the derivation of probabilities. As stated by \cite{Spiegelhalter2009}: ``In the Bayesian paradigm, degrees of belief in states of nature are specified. Bayesian statistical methods start with existing `prior' beliefs, and update these using data to give `posterior' beliefs, which may be used as the basis for inferential decisions''. Bayesian inference has now been established as a major method for assessing probability.

\hypertarget{overview-of-bayesian-estimattion}{%
\section{Overview of Bayesian estimattion}\label{overview-of-bayesian-estimattion}}

Most applications of machine learning methods for image classification use only the categorical result of the classifier which is the most probable class. The proposed method uses all class probabilities to compute our confidence in the result. In a Bayesian context, probability is taken as a subjective belief. The observation of the class probabilities of each pixel is taken as our initial belief on what the actual class of the pixel is. We then use Bayes' rule to consider how much the class probabilities of the neighbouring pixels affect our original belief. In the case of continuous probability distributions, Bayesian inference is expressed by the rule:

\[
\pi(\theta|x) \propto \pi(x|\theta)\pi(\theta)
\]

Bayesian inference involves the estimation of an unknown parameter \(\theta\), which is the random variable that describe what we are trying to measure. In the case of smoothing of image classification, \(\theta\) is the class probability for a given pixel. We model our initial belief about this value by a probability distribution, \(\pi(\theta)\), called the \emph{prior} distribution. It represents what we know about \(\theta\) \emph{before} observing the data. The distribution \(\pi(x|\theta)\), called the \emph{likelihood}, is estimated based on the observed data. It represents the added information provided by our observations. The \emph{posterior} distribution \(\pi(\theta|x)\) is our improved belief of \(\theta\) \emph{after} seeing the data. Bayes's rule states that the \emph{posterior} probability is proportional to the product of the \emph{likelihood} and the \emph{prior} probability.

\hypertarget{smmothing-using-bayes-rule}{%
\subsection{Smmothing using Bayes' rule}\label{smmothing-using-bayes-rule}}

Given the general principles of Bayesian inference, smoothing of classified images requires estimating the \emph{likelihood} and the \emph{prior} probability of each pixel belonging to each class. In order to express our problem in a more tractable form, we perform data transformations.
More formally, consider a set of \(K\) classes that are candidates for labelling each pixel. Let \(p_{i,k}\) be the probability of pixel \(i\) belonging to class \(k\), \(k = 1, \dots, K\). We have
\[
\sum_{k=1}^K p_{i,k} = 1, p_{i,k} > 0
\]
We label a pixel \(p_i\) as being of class \(k\) if
\[
    p_{i,k} > p_{i,m}, \forall m = 1, \dots, K, m \neq k
\]

For each pixel \(i\), we take the odds of the classification for class \(k\), expressed as
\[
    O_{i,k} = p_{i,k} / (1-p_{i,k})
\]
where \(p_{i,k}\) is the probability of class \(k\). We have more confidence in pixels with higher odds since their class assignment is stronger. There are situations, such as border pixels or mixed ones, where the odds of different classes are similar in magnitude. We take them as cases of low confidence in the classification result. To assess and correct these cases, Bayesian smoothing methods borrow strength from the neighbours and reduced the variance of the estimated class for each pixel.

We further make the transformation
\[
    x_{i,k} = \log [O_{i,k}]
\]
which measures the \emph{logit} (log of the odds) associated to classifying the pixel \(i\) as being of class \(k\). The support of \(x_{i,k}\) is \(\mathbb{R}\). Let \(V_{i}\) be a spatial neighbourhood for pixel \(i\). We use Bayes' rule to update the value \(x_{i,k}\) based on the neighbourhood, assuming independence between the classes. In this way, the update is performed for each class \(k\) at a time.

For each pixel, the random variable that describes the class probability is denoted by \(\theta_{i,k}\). Therefore, we can express Bayes' rule for each combination of pixel and class as

\[
\pi(\theta_{i,k}|x_{i,k}) \propto \pi(x_{i,k}|\theta_{i,k})\pi(\theta_{i,k}).   
\]

We assume the prior distribution \(\pi(\theta_{i,k})\) and the likelihood \(\pi(x_{i,k}|\theta_{i,k})\) are modelled by Gaussian distributions. In this case, the posterior will also be a Gaussian distribution. To estimate the prior distribution for a pixel, we consider that all pixels in the spatial neighbourhood \(V_{i}\) of pixel \(i\) follow the same Gaussian distribution with parameters \(m_{i,k}\) and \(s^2_{i,k}\). Thus, the prior is expressed as
\[
\theta_{i,k} \sim N(m_{i,k}, s^2_{i,k}).    
\]

In the above equation, the parameter \(m_{i,k}\) is the local mean of the probability distribution of values for class \(k\) and \(s^2_{i,k}\) is the local variance for class \(k\). We estimate the local mean and variance by considering the neighbouring pixels in space. Let \(\#(V_{i})\) be the number of elements in the spatial neighbourhood \(V _{i}\). The local mean is calculated by:

\[
    m_{i,k} = \frac{\displaystyle\sum_{j \in V_{i}} x_{j,k}}{\#(V_{i})}
\]

and the local variance by
\[
s^2_{i,k} = \frac{\displaystyle\sum_{j \in V_{i}} [x_{j,k} - m_{i,k}]^2}{\#(V_{i})-1}.  
\]

We also consider that the likelihood follows a normal distribution. We take the likelihood as being the distribution of \(x_{i,k}\), conditioned by the local variable \(\theta_{i,k}\). This conditional distribution is also taken as normal with parameters \(\theta_{i,k}\) and \(\sigma^2_{k}\), expressed as
\[
x_{i,k} | \theta_{i,k} \sim N(\theta_{i,k}, \sigma^2_{k})
\]

In the likelihood equation above, \(\sigma^2_{k}\) is a hyper-parameter that controls the level of smoothness.The Bayesian smoothing estimates the value of \(\theta _{i,k}\) conditioned by the data \(x_{i,k}\). This is the updated value of the logit of class probability for class \(k\) of pixel \(i\). Since both the prior and the likelihood are assumed as Gaussian distribution, based on Bayesian statistics the value of conditional mean for a normal distribution is given by:
\[
{E}[\theta_{i,k} | x_{i,k}] =
\frac{m_{i,t} \times \sigma^2_{k} + 
x_{i,k} \times s^2_{i,k}}{ \sigma^2_{k} +s^2_{i,k}} 
\]

which can also be expressed as
\[
    {E}[\theta_{i,k} | x_{i,k}] =
\Biggl [ \frac{s^2_{i,k}}{\sigma^2_{k} +s^2_{i,k}} \Biggr ] \times
x_{i,k} +
\Biggl [ \frac{\sigma^2_{k}}{\sigma^2_{k} +s^2_{i,k}} \Biggr ] \times m_{i,k}
\]

The updated value for the class probability of the pixel is a weighted average between the original logit value \(x_{i,k}\) and the mean of the class logits \(m_{i,k}\) for the neighboring pixels. When the local class variance of the neighbors \(s^2_{i,k}\) is high relative to the smoothing factor \(\sigma^2_k\), our confidence on the influence of the neighbors is low, and the smoothing algorithm gives more weight to the original pixel value \(x_{i,k}\). When the local class variance \(s^2_{i,k}\) decreases relative to the smoothness factor \(\sigma^2_k\), then our confidence on the influence of the neighborhood increases. The smoothing procedure will be most relevant in situations where the original classification odds ratio is low, showing a low level of separability between classes. In these cases, the updated values of the classes will be influenced by the local class variances.

The hyperparameter \(\sigma^2_k\) sets the level of smoothness. If \(\sigma^2_k\) is zero, the smoothed value \({E}[\mu_{i,,k} | l_{i,k}]\) is equal to the pixel value \(l_{i,k}\). Higher values of \(\sigma^2_k\) will cause the assignment of the local mean to the pixel updated probability. In practice, \(\sigma^2_k\) is a user-controlled parameter that will be set by users based on their knowledge of the region to be classified. In our case, after some classification tests, we decided to set the parameters \(V\) as the Moore neighborhood where each pixel is connected to all those pixels with Chebyshev distance of \(1\), and \(\sigma^2_k=20\) for all \(k\). This level of smoothness showed the best performance in the technical validation.

\hypertarget{use-of-bayesian-smoothing-in-sits}{%
\section{Use of Bayesian smoothing in SITS}\label{use-of-bayesian-smoothing-in-sits}}

Doing post-processing using Bayesian smoothing in SITS is straightforward. The result of the \texttt{sits\_classify} function applied to a data cube is set of more probability images, one per requested clasification interval. The next step is to apply the \texttt{sits\_label\_classification} function. By default, this function selects the most likely class for each pixel considering only the probabilities of each class for each pixel. To allow for Bayesian smooting, it suffices to include the \texttt{smoothing\ =\ bayesian} parameter. If desired, the \texttt{variance} parameter (associated to the hyperparameter \(\sigma^2_k\) described above) can control the degree of smoothness.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Retrieve the data for the Mato Grosso state}
\FunctionTok{data}\NormalTok{(}\StringTok{"samples\_matogrosso\_mod13q1"}\NormalTok{)}

\CommentTok{\# select the bands "ndvi", "evi"}
\NormalTok{samples\_2bands }\OtherTok{\textless{}{-}} \FunctionTok{sits\_select}\NormalTok{(samples\_matogrosso\_mod13q1, }\AttributeTok{bands =} \FunctionTok{c}\NormalTok{(}\StringTok{"NDVI"}\NormalTok{, }\StringTok{"EVI"}\NormalTok{))}

\CommentTok{\#select a rfor model}
\NormalTok{xgb\_model }\OtherTok{\textless{}{-}} \FunctionTok{sits\_train}\NormalTok{(samples\_2bands, }\AttributeTok{ml\_method =} \FunctionTok{sits\_xgboost}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
#> [1]  train-mlogloss:2.009944+0.000892    test-mlogloss:2.022906+0.001491 
#> Multiple eval metrics are present. Will use test_mlogloss for early stopping.
#> Will train until test_mlogloss hasn't improved in 20 rounds.
#> 
#> [11] train-mlogloss:0.620737+0.002764    test-mlogloss:0.755199+0.005152 
#> [21] train-mlogloss:0.207436+0.001456    test-mlogloss:0.364395+0.009251 
#> [31] train-mlogloss:0.094411+0.000752    test-mlogloss:0.251361+0.008440 
#> [41] train-mlogloss:0.059334+0.000473    test-mlogloss:0.211024+0.009399 
#> [51] train-mlogloss:0.048914+0.000651    test-mlogloss:0.197786+0.009918 
#> [61] train-mlogloss:0.045721+0.000552    test-mlogloss:0.194586+0.010300 
#> [71] train-mlogloss:0.044009+0.000838    test-mlogloss:0.192748+0.010751 
#> [81] train-mlogloss:0.043003+0.000582    test-mlogloss:0.191353+0.011066 
#> [91] train-mlogloss:0.042301+0.000387    test-mlogloss:0.190409+0.011007 
#> [100]    train-mlogloss:0.042005+0.000349    test-mlogloss:0.189918+0.011470
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_dir }\OtherTok{\textless{}{-}} \FunctionTok{system.file}\NormalTok{(}\StringTok{"extdata/sinop"}\NormalTok{, }\AttributeTok{package =} \StringTok{"sitsdata"}\NormalTok{)}

\CommentTok{\# create a raster metadata file based on the information about the files}
\NormalTok{raster\_cube }\OtherTok{\textless{}{-}} \FunctionTok{sits\_cube}\NormalTok{(}\AttributeTok{source =} \StringTok{"LOCAL"}\NormalTok{,}
                   \AttributeTok{satellite =} \StringTok{"TERRA"}\NormalTok{,}
                   \AttributeTok{sensor  =} \StringTok{"MODIS"}\NormalTok{,}
                   \AttributeTok{name =} \StringTok{"Sinop"}\NormalTok{,}
                   \AttributeTok{data\_dir =}\NormalTok{ data\_dir,}
                   \AttributeTok{parse\_info =} \FunctionTok{c}\NormalTok{(}\StringTok{"X1"}\NormalTok{, }\StringTok{"X2"}\NormalTok{, }\StringTok{"band"}\NormalTok{, }\StringTok{"date"}\NormalTok{),}
\NormalTok{)}

\CommentTok{\# classify the raster image and generate a probability file}
\NormalTok{raster\_probs }\OtherTok{\textless{}{-}} \FunctionTok{sits\_classify}\NormalTok{(raster\_cube, }\AttributeTok{ml\_model =}\NormalTok{ xgb\_model, }
                              \AttributeTok{memsize =} \DecValTok{4}\NormalTok{, }\AttributeTok{multicores =} \DecValTok{2}\NormalTok{, }
                              \AttributeTok{output\_dir =} \FunctionTok{tempdir}\NormalTok{())}

\CommentTok{\# smooth the result with a bayesian filter}
\NormalTok{raster\_probs\_bayes }\OtherTok{\textless{}{-}} \FunctionTok{sits\_smooth}\NormalTok{(raster\_probs, }\AttributeTok{output\_dir =} \FunctionTok{tempdir}\NormalTok{())}

\CommentTok{\# label the smoothed probability images}
\NormalTok{raster\_class }\OtherTok{\textless{}{-}} \FunctionTok{sits\_label\_classification}\NormalTok{(raster\_probs\_bayes, }\AttributeTok{output\_dir =} \FunctionTok{tempdir}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

The result is shown below.

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{sitsbook_files/figure-latex/unnamed-chunk-70-1} 

}

\caption[Classified image post-processed with Bayesian smoothing]{Classified image post-processed with Bayesian smoothing. The image coordinates ({\it meters}) shown at vertical and horizontal axis are in MODIS sinusoidal projection.}\label{fig:unnamed-chunk-70}
\end{figure}

\hypertarget{validation-and-accuracy-measurements-in-sits}{%
\chapter{Validation and accuracy measurements in SITS}\label{validation-and-accuracy-measurements-in-sits}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

This chapter presents the validation and accuracy measures available in the SITS package.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{validation-techniques-1}{%
\section{Validation techniques}\label{validation-techniques-1}}

Validation is a process undertaken on models to estimate some error associated with them, and hence has been used widely in different scientific disciplines. Here, we are interested in estimating the prediction error associated to some model. For this purpose, we concentrate on the \emph{cross-validation} approach, probably the most used validation technique \citep{Hastie2009}.

To be sure, cross-validation estimates the expected prediction error. It uses part of the available samples to fit the classification model, and a different part to test it. The so-called \emph{k-fold} validation, we split the data into \(k\) partitions with approximately the same size and proceed by fitting the model and testing it \(k\) times. At each step, we take one distinct partition for test and the remaining \({k-1}\) for training the model, and calculate its prediction error for classifying the test partition. A simple average gives us an estimation of the expected prediction error.

A natural question that arises is: \emph{how good is this estimation?} According to \citet{Hastie2009}, there is a bias-variance trade-off in choice of \(k\). If \(k\) is set to the number of samples, we obtain the so-called \emph{leave-one-out} validation, the estimator gives a low bias for the true expected error, but produces a high variance expectation. This can be computational expensive as it requires the same number of fitting process as the number of samples. On the other hand, if we choose \({k=2}\), we get a high biased expected prediction error estimation that overestimates the true prediction error, but has a low variance. The recommended choices of \(k\) are \(5\) or \(10\) \citep{Hastie2009}, which somewhat overestimates the true prediction error.

\texttt{sits\_kfold\_validate()} gives support the k-fold validation in \texttt{sits}. The following code gives an example on how to proceed a k-fold cross-validation in the package. It perform a five-fold validation using SVM classification model as a default classifier. We can see in the output text the corresponding confusion matrix and the accuracy statistics (overall and by class).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# perform a five fold validation for the "cerrado\_2classes" data set}
\CommentTok{\# Random Forest machine learning method using default parameters}
\NormalTok{prediction.mx }\OtherTok{\textless{}{-}} \FunctionTok{sits\_kfold\_validate}\NormalTok{(cerrado\_2classes, }
                                     \AttributeTok{folds =} \DecValTok{5}\NormalTok{, }
                                     \AttributeTok{ml\_method =} \FunctionTok{sits\_rfor}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\hypertarget{comparing-different-validation-methods}{%
\section{Comparing different validation methods}\label{comparing-different-validation-methods}}

One useful function in SITS is the capacity to compare different validation methods and store them in an XLS file for further analysis. The following example shows how to do this, using the Mato Grosso data set.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Retrieve the set of samples for the Mato Grosso region (provided by EMBRAPA)}
\FunctionTok{data}\NormalTok{(}\StringTok{"samples\_matogrosso\_mod13q1"}\NormalTok{)}

\CommentTok{\# create a list to store the results}
\NormalTok{results }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{()}

\CommentTok{\# adjust the multicores parameters to suit your machine}

\DocumentationTok{\#\# SVM model}
\NormalTok{conf\_svm.tb }\OtherTok{\textless{}{-}} \FunctionTok{sits\_kfold\_validate}\NormalTok{(}
\NormalTok{    samples\_matogrosso\_mod13q1,}
    \AttributeTok{folds =} \DecValTok{5}\NormalTok{,}
    \AttributeTok{multicores =} \DecValTok{2}\NormalTok{,}
    \AttributeTok{ml\_method =} \FunctionTok{sits\_svm}\NormalTok{(}\AttributeTok{kernel =} \StringTok{"radial"}\NormalTok{, }\AttributeTok{cost =} \DecValTok{10}\NormalTok{))}

\CommentTok{\# Give a name to the SVM model}
\NormalTok{conf\_svm.tb}\SpecialCharTok{$}\NormalTok{name }\OtherTok{\textless{}{-}} \StringTok{"svm\_10"}

\CommentTok{\# store the result}
\NormalTok{results[[}\FunctionTok{length}\NormalTok{(results) }\SpecialCharTok{+} \DecValTok{1}\NormalTok{]] }\OtherTok{\textless{}{-}}\NormalTok{ conf\_svm.tb}


\NormalTok{conf\_rfor.tb }\OtherTok{\textless{}{-}} \FunctionTok{sits\_kfold\_validate}\NormalTok{(}
\NormalTok{    samples\_matogrosso\_mod13q1,}
    \AttributeTok{folds =} \DecValTok{5}\NormalTok{,}
    \AttributeTok{multicores =} \DecValTok{1}\NormalTok{,}
    \AttributeTok{ml\_method =} \FunctionTok{sits\_rfor}\NormalTok{(}\AttributeTok{num\_trees =} \DecValTok{500}\NormalTok{))}

\CommentTok{\# Give a name to the model}
\NormalTok{conf\_rfor.tb}\SpecialCharTok{$}\NormalTok{name }\OtherTok{\textless{}{-}} \StringTok{"rfor\_500"}

\CommentTok{\# store the results in a list}
\NormalTok{results[[}\FunctionTok{length}\NormalTok{(results) }\SpecialCharTok{+} \DecValTok{1}\NormalTok{]] }\OtherTok{\textless{}{-}}\NormalTok{ conf\_rfor.tb}

\CommentTok{\# Save to an XLS file}
\FunctionTok{sits\_to\_xlsx}\NormalTok{(results, }\AttributeTok{file =} \FunctionTok{tempfile}\NormalTok{(}\AttributeTok{fileext =} \StringTok{".xlsx"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
#> Saved Excel file /var/folders/21/g8ty6rhs2b350tzkmknqgwv00000gn/T//RtmpIsEpAG/file15fcc70666586.xlsx
\end{verbatim}

\bibliography{references-sits.bib}



\end{document}
