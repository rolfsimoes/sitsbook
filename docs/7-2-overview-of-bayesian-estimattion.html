<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="7.2 Overview of Bayesian estimattion | sits: Data Analysis and Machine Learning for Data Cubes using Satellite Image Time Series" />
<meta property="og:type" content="book" />

<meta property="og:image" content="images/cover.png" />
<meta property="og:description" content="<p>This is a minimal example of using the bookdown package to write a book.
The output format for this example is bookdown::gitbook.</p>" />



<meta name="date" content="2021-03-30" />

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="<p>This is a minimal example of using the bookdown package to write a book.
The output format for this example is bookdown::gitbook.</p>">

<title>7.2 Overview of Bayesian estimattion | sits: Data Analysis and Machine Learning for Data Cubes using Satellite Image Time Series</title>

<script src="libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="libs/navigation-1.1/tabsets.js"></script>
<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
</style>
</head>

<body>

<div class="container-fluid main-container">


<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#preface">Preface</a></li>
<li class="has-sub"><a href="1-introduction.html#introduction"><span class="toc-section-number">1</span> Introduction</a><ul>
<li><a href="1-1-workflow.html#workflow"><span class="toc-section-number">1.1</span> Workflow</a></li>
<li class="has-sub"><a href="1-2-handling-data-cubes-in-sits.html#handling-data-cubes-in-sits"><span class="toc-section-number">1.2</span> Handling Data Cubes in <strong>sits</strong></a><ul>
<li><a href="1-2-handling-data-cubes-in-sits.html#image-data-cubes-as-the-basis-for-big-earth-observation-data-analysis"><span class="toc-section-number">1.2.1</span> Image data cubes as the basis for big Earth observation data analysis</a></li>
<li><a href="1-2-handling-data-cubes-in-sits.html#using-stac-to-access-image-data-cubes"><span class="toc-section-number">1.2.2</span> Using STAC to Access Image Data Cubes</a></li>
<li><a href="1-2-handling-data-cubes-in-sits.html#defining-a-data-cube-using-files"><span class="toc-section-number">1.2.3</span> Defining a data cube using files</a></li>
</ul></li>
<li class="has-sub"><a href="1-3-handling-satellite-image-time-series-in-sits.html#handling-satellite-image-time-series-in-sits"><span class="toc-section-number">1.3</span> Handling satellite image time series in <strong>sits</strong></a><ul>
<li><a href="1-3-handling-satellite-image-time-series-in-sits.html#data-structure"><span class="toc-section-number">1.3.1</span> Data structure</a></li>
<li><a href="1-3-handling-satellite-image-time-series-in-sits.html#obtaining-time-series-data"><span class="toc-section-number">1.3.2</span> Obtaining time series data</a></li>
</ul></li>
<li><a href="1-4-filtering-techniques.html#filtering-techniques"><span class="toc-section-number">1.4</span> Filtering techniques</a></li>
<li><a href="1-5-clustering-for-sample-quality-control-using-self-organizing-maps.html#clustering-for-sample-quality-control-using-self-organizing-maps"><span class="toc-section-number">1.5</span> Clustering for sample quality control using self-organizing maps</a></li>
<li><a href="1-6-classification-using-machine-learning.html#classification-using-machine-learning"><span class="toc-section-number">1.6</span> Classification using machine learning</a></li>
<li><a href="1-7-validation-techniques.html#validation-techniques"><span class="toc-section-number">1.7</span> Validation techniques</a></li>
<li class="has-sub"><a href="1-8-cube-classification.html#cube-classification"><span class="toc-section-number">1.8</span> Cube classification</a><ul>
<li><a href="1-8-cube-classification.html#steps-for-cube-classification"><span class="toc-section-number">1.8.1</span> Steps for cube classification</a></li>
<li><a href="1-8-cube-classification.html#adjustments-for-improved-performance"><span class="toc-section-number">1.8.2</span> Adjustments for improved performance</a></li>
</ul></li>
<li><a href="1-9-smoothing-and-labelling-of-raster-data-after-classification.html#smoothing-and-labelling-of-raster-data-after-classification"><span class="toc-section-number">1.9</span> Smoothing and Labelling of raster data after classification</a></li>
<li><a href="1-10-final-remarks.html#final-remarks"><span class="toc-section-number">1.10</span> Final remarks</a></li>
<li><a href="1-11-acknowledgements.html#acknowledgements"><span class="toc-section-number">1.11</span> Acknowledgements</a></li>
</ul></li>
<li class="has-sub"><a href="2-acessing-time-series-information-in-sits.html#acessing-time-series-information-in-sits"><span class="toc-section-number">2</span> Acessing time series information in SITS</a><ul>
<li><a href="2-1-data-structures-for-satellite-time-series.html#data-structures-for-satellite-time-series"><span class="toc-section-number">2.1</span> Data structures for satellite time series</a></li>
<li><a href="2-2-utilities-for-handling-time-series.html#utilities-for-handling-time-series"><span class="toc-section-number">2.2</span> Utilities for handling time series</a></li>
<li><a href="2-3-time-series-visualisation.html#time-series-visualisation"><span class="toc-section-number">2.3</span> Time series visualisation</a></li>
<li><a href="2-4-obtaining-time-series-data-from-data-cubes.html#obtaining-time-series-data-from-data-cubes"><span class="toc-section-number">2.4</span> Obtaining time series data from data cubes</a></li>
</ul></li>
<li class="has-sub"><a href="3-satellite-image-time-series-filtering-with-sits.html#satellite-image-time-series-filtering-with-sits"><span class="toc-section-number">3</span> Satellite Image Time Series Filtering with SITS</a><ul>
<li><a href="3-1-filtering-techniques-in-sits.html#filtering-techniques-in-sits"><span class="toc-section-number">3.1</span> Filtering techniques in SITS</a></li>
<li class="has-sub"><a href="3-2-common-interface-to-sits-filter-functions.html#common-interface-to-sits-filter-functions"><span class="toc-section-number">3.2</span> Common interface to SITS filter functions</a><ul>
<li><a href="3-2-common-interface-to-sits-filter-functions.html#savitzkygolay-filter"><span class="toc-section-number">3.2.1</span> Savitzky–Golay filter</a></li>
<li><a href="3-2-common-interface-to-sits-filter-functions.html#whittaker-filter"><span class="toc-section-number">3.2.2</span> Whittaker filter</a></li>
<li><a href="3-2-common-interface-to-sits-filter-functions.html#envelope-filter"><span class="toc-section-number">3.2.3</span> Envelope filter</a></li>
</ul></li>
</ul></li>
<li class="has-sub"><a href="4-time-series-clustering-to-improve-the-quality-of-training-samples.html#time-series-clustering-to-improve-the-quality-of-training-samples"><span class="toc-section-number">4</span> Time Series Clustering to Improve the Quality of Training Samples</a><ul>
<li><a href="4-1-clustering-for-sample-quality-control.html#clustering-for-sample-quality-control"><span class="toc-section-number">4.1</span> Clustering for sample quality control</a></li>
<li class="has-sub"><a href="4-2-hierachical-clustering-for-sample-quality-control.html#hierachical-clustering-for-sample-quality-control"><span class="toc-section-number">4.2</span> Hierachical clustering for Sample Quality Control</a><ul>
<li><a href="4-2-hierachical-clustering-for-sample-quality-control.html#creating-a-dendogram"><span class="toc-section-number">4.2.1</span> Creating a dendogram</a></li>
<li><a href="4-2-hierachical-clustering-for-sample-quality-control.html#using-a-dendrogram-to-evaluate-sample-quality"><span class="toc-section-number">4.2.2</span> Using a dendrogram to evaluate sample quality</a></li>
</ul></li>
<li class="has-sub"><a href="4-3-using-self-organizing-maps-for-sample-quality.html#using-self-organizing-maps-for-sample-quality"><span class="toc-section-number">4.3</span> Using Self-organizing Maps for Sample Quality</a><ul>
<li><a href="4-3-using-self-organizing-maps-for-sample-quality.html#introduction-to-self-organizing-maps"><span class="toc-section-number">4.3.1</span> Introduction to Self-organizing Maps</a></li>
<li><a href="4-3-using-self-organizing-maps-for-sample-quality.html#using-som-for-removing-class-noise"><span class="toc-section-number">4.3.2</span> Using SOM for removing class noise</a></li>
<li><a href="4-3-using-self-organizing-maps-for-sample-quality.html#comparing-global-accuracy-of-original-and-clean-samples"><span class="toc-section-number">4.3.3</span> Comparing Global Accuracy of Original and Clean Samples</a></li>
</ul></li>
<li><a href="4-4-conclusion.html#conclusion"><span class="toc-section-number">4.4</span> Conclusion</a></li>
</ul></li>
<li class="has-sub"><a href="5-machine-learning-for-data-cubes-using-the-sits-package.html#machine-learning-for-data-cubes-using-the-sits-package"><span class="toc-section-number">5</span> Machine Learning for Data Cubes using the SITS package</a><ul>
<li><a href="5-1-machine-learning-classification.html#machine-learning-classification"><span class="toc-section-number">5.1</span> Machine learning classification</a></li>
<li><a href="5-2-data-used-in-the-machine-learning-examples.html#data-used-in-the-machine-learning-examples"><span class="toc-section-number">5.2</span> Data used in the machine learning examples</a></li>
<li><a href="5-3-visualizing-samples.html#visualizing-samples"><span class="toc-section-number">5.3</span> Visualizing Samples</a></li>
<li><a href="5-4-common-interface-to-machine-learning-and-deeplearning-models.html#common-interface-to-machine-learning-and-deeplearning-models"><span class="toc-section-number">5.4</span> Common interface to machine learning and deeplearning models</a></li>
<li><a href="5-5-random-forests.html#random-forests"><span class="toc-section-number">5.5</span> Random forests</a></li>
<li><a href="5-6-support-vector-machines.html#support-vector-machines"><span class="toc-section-number">5.6</span> Support Vector Machines</a></li>
<li><a href="5-7-extreme-gradient-boosting.html#extreme-gradient-boosting"><span class="toc-section-number">5.7</span> Extreme Gradient Boosting</a></li>
<li><a href="5-8-deep-learning-using-multi-layer-perceptrons.html#deep-learning-using-multi-layer-perceptrons"><span class="toc-section-number">5.8</span> Deep learning using multi-layer perceptrons</a></li>
<li><a href="5-9-d-convolutional-neural-networks.html#d-convolutional-neural-networks"><span class="toc-section-number">5.9</span> 1D Convolutional Neural Networks</a></li>
<li><a href="5-10-residual-1d-cnn-networks-resnet.html#residual-1d-cnn-networks-resnet"><span class="toc-section-number">5.10</span> Residual 1D CNN Networks (ResNet)</a></li>
</ul></li>
<li class="has-sub"><a href="6-classification-of-images-in-data-cubes-using-satellite-image-time-series.html#classification-of-images-in-data-cubes-using-satellite-image-time-series"><span class="toc-section-number">6</span> Classification of Images in Data Cubes using Satellite Image Time Series</a><ul>
<li><a href="6-1-image-data-cubes-as-the-basis-for-big-earth-observation-data-analysis-1.html#image-data-cubes-as-the-basis-for-big-earth-observation-data-analysis-1"><span class="toc-section-number">6.1</span> Image data cubes as the basis for big Earth observation data analysis</a></li>
<li><a href="6-2-defining-a-data-cube-using-files-organised-as-raster-bricks.html#defining-a-data-cube-using-files-organised-as-raster-bricks"><span class="toc-section-number">6.2</span> Defining a data cube using files organised as raster bricks</a></li>
<li><a href="6-3-classification-using-machine-learning-1.html#classification-using-machine-learning-1"><span class="toc-section-number">6.3</span> Classification using machine learning</a></li>
<li class="has-sub"><a href="6-4-cube-classification-1.html#cube-classification-1"><span class="toc-section-number">6.4</span> Cube classification</a><ul>
<li><a href="6-4-cube-classification-1.html#steps-for-cube-classification-1"><span class="toc-section-number">6.4.1</span> Steps for cube classification</a></li>
<li><a href="6-4-cube-classification-1.html#adjustments-for-improved-performance-1"><span class="toc-section-number">6.4.2</span> Adjustments for improved performance</a></li>
</ul></li>
<li><a href="6-5-final-remarks-1.html#final-remarks-1"><span class="toc-section-number">6.5</span> Final remarks</a></li>
</ul></li>
<li class="has-sub"><a href="7-post-classification-smoothing-using-bayesian-techniques-in-sits.html#post-classification-smoothing-using-bayesian-techniques-in-sits"><span class="toc-section-number">7</span> Post classification smoothing using Bayesian techniques in SITS</a><ul>
<li><a href="7-1-introduction-1.html#introduction-1"><span class="toc-section-number">7.1</span> Introduction</a></li>
<li class="has-sub"><a href="7-2-overview-of-bayesian-estimattion.html#overview-of-bayesian-estimattion"><span class="toc-section-number">7.2</span> Overview of Bayesian estimattion</a><ul>
<li><a href="7-2-overview-of-bayesian-estimattion.html#smmothing-using-bayes-rule"><span class="toc-section-number">7.2.1</span> Smmothing using Bayes’ rule</a></li>
</ul></li>
<li><a href="7-3-use-of-bayesian-smoothing-in-sits.html#use-of-bayesian-smoothing-in-sits"><span class="toc-section-number">7.3</span> Use of Bayesian smoothing in SITS</a></li>
</ul></li>
<li class="has-sub"><a href="8-validation-and-accuracy-measurements-in-sits.html#validation-and-accuracy-measurements-in-sits"><span class="toc-section-number">8</span> Validation and accuracy measurements in SITS</a><ul>
<li><a href="8-1-validation-techniques-1.html#validation-techniques-1"><span class="toc-section-number">8.1</span> Validation techniques</a></li>
<li><a href="8-2-comparing-different-validation-methods.html#comparing-different-validation-methods"><span class="toc-section-number">8.2</span> Comparing different validation methods</a></li>
</ul></li>
<li><a href="references.html#references">References</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="overview-of-bayesian-estimattion" class="section level2">
<h2><span class="header-section-number">7.2</span> Overview of Bayesian estimattion</h2>
<p>Most applications of machine learning methods for image classification use only the categorical result of the classifier which is the most probable class. The proposed method uses all class probabilities to compute our confidence in the result. In a Bayesian context, probability is taken as a subjective belief. The observation of the class probabilities of each pixel is taken as our initial belief on what the actual class of the pixel is. We then use Bayes’ rule to consider how much the class probabilities of the neighbouring pixels affect our original belief. In the case of continuous probability distributions, Bayesian inference is expressed by the rule:</p>
<p><span class="math display">\[
\pi(\theta|x) \propto \pi(x|\theta)\pi(\theta)
\]</span></p>
<p>Bayesian inference involves the estimation of an unknown parameter <span class="math inline">\(\theta\)</span>, which is the random variable that describe what we are trying to measure. In the case of smoothing of image classification, <span class="math inline">\(\theta\)</span> is the class probability for a given pixel. We model our initial belief about this value by a probability distribution, <span class="math inline">\(\pi(\theta)\)</span>, called the  distribution. It represents what we know about <span class="math inline">\(\theta\)</span>  observing the data. The distribution <span class="math inline">\(\pi(x|\theta)\)</span>, called the , is estimated based on the observed data. It represents the added information provided by our observations. The  distribution <span class="math inline">\(\pi(\theta|x)\)</span> is our improved belief of <span class="math inline">\(\theta\)</span>  seeing the data. Bayes’s rule states that the  probability is proportional to the product of the  and the  probability.</p>
<div id="smmothing-using-bayes-rule" class="section level3">
<h3><span class="header-section-number">7.2.1</span> Smmothing using Bayes’ rule</h3>
<p>Given the general principles of Bayesian inference, smoothing of classified images requires estimating the  and the  probability of each pixel belonging to each class. In order to express our problem in a more tractable form, we perform data transformations.
More formally, consider a set of <span class="math inline">\(K\)</span> classes that are candidates for labelling each pixel. Let <span class="math inline">\(p_{i,k}\)</span> be the probability of pixel <span class="math inline">\(i\)</span> belonging to class <span class="math inline">\(k\)</span>, <span class="math inline">\(k = 1, \dots, K\)</span>. We have
<span class="math display">\[
\sum_{k=1}^K p_{i,k} = 1, p_{i,k} &gt; 0
\]</span>
We label a pixel <span class="math inline">\(p_i\)</span> as being of class <span class="math inline">\(k\)</span> if
<span class="math display">\[
    p_{i,k} &gt; p_{i,m}, \forall m = 1, \dots, K, m \neq k
\]</span></p>
<p>For each pixel <span class="math inline">\(i\)</span>, we take the odds of the classification for class <span class="math inline">\(k\)</span>, expressed as
<span class="math display">\[
    O_{i,k} = p_{i,k} / (1-p_{i,k})
\]</span>
where <span class="math inline">\(p_{i,k}\)</span> is the probability of class <span class="math inline">\(k\)</span>. We have more confidence in pixels with higher odds since their class assignment is stronger. There are situations, such as border pixels or mixed ones, where the odds of different classes are similar in magnitude. We take them as cases of low confidence in the classification result. To assess and correct these cases, Bayesian smoothing methods borrow strength from the neighbours and reduced the variance of the estimated class for each pixel.</p>
<p>We further make the transformation
<span class="math display">\[
    x_{i,k} = \log [O_{i,k}]
\]</span>
which measures the  (log of the odds) associated to classifying the pixel <span class="math inline">\(i\)</span> as being of class <span class="math inline">\(k\)</span>. The support of <span class="math inline">\(x_{i,k}\)</span> is <span class="math inline">\(\mathbb{R}\)</span>. Let <span class="math inline">\(V_{i}\)</span> be a spatial neighbourhood for pixel <span class="math inline">\(i\)</span>. We use Bayes’ rule to update the value <span class="math inline">\(x_{i,k}\)</span> based on the neighbourhood, assuming independence between the classes. In this way, the update is performed for each class <span class="math inline">\(k\)</span> at a time.</p>
<p>For each pixel, the random variable that describes the class probability is denoted by <span class="math inline">\(\theta_{i,k}\)</span>. Therefore, we can express Bayes’ rule for each combination of pixel and class as</p>
<p><span class="math display">\[
\pi(\theta_{i,k}|x_{i,k}) \propto \pi(x_{i,k}|\theta_{i,k})\pi(\theta_{i,k}).   
\]</span></p>
<p>We assume the prior distribution <span class="math inline">\(\pi(\theta_{i,k})\)</span> and the likelihood <span class="math inline">\(\pi(x_{i,k}|\theta_{i,k})\)</span> are modelled by Gaussian distributions. In this case, the posterior will also be a Gaussian distribution. To estimate the prior distribution for a pixel, we consider that all pixels in the spatial neighbourhood <span class="math inline">\(V_{i}\)</span> of pixel <span class="math inline">\(i\)</span> follow the same Gaussian distribution with parameters <span class="math inline">\(m_{i,k}\)</span> and <span class="math inline">\(s^2_{i,k}\)</span>. Thus, the prior is expressed as
<span class="math display">\[
\theta_{i,k} \sim N(m_{i,k}, s^2_{i,k}).    
\]</span></p>
<p>In the above equation, the parameter <span class="math inline">\(m_{i,k}\)</span> is the local mean of the probability distribution of values for class <span class="math inline">\(k\)</span> and <span class="math inline">\(s^2_{i,k}\)</span> is the local variance for class <span class="math inline">\(k\)</span>. We estimate the local mean and variance by considering the neighbouring pixels in space. Let <span class="math inline">\(\#(V_{i})\)</span> be the number of elements in the spatial neighbourhood <span class="math inline">\(V _{i}\)</span>. The local mean is calculated by:</p>
<p><span class="math display">\[
    m_{i,k} = \frac{\displaystyle\sum_{j \in V_{i}} x_{j,k}}{\#(V_{i})}
\]</span></p>
<p>and the local variance by
<span class="math display">\[
s^2_{i,k} = \frac{\displaystyle\sum_{j \in V_{i}} [x_{j,k} - m_{i,k}]^2}{\#(V_{i})-1}.  
\]</span></p>
<p>We also consider that the likelihood follows a normal distribution. We take the likelihood as being the distribution of <span class="math inline">\(x_{i,k}\)</span>, conditioned by the local variable <span class="math inline">\(\theta_{i,k}\)</span>. This conditional distribution is also taken as normal with parameters <span class="math inline">\(\theta_{i,k}\)</span> and <span class="math inline">\(\sigma^2_{k}\)</span>, expressed as
<span class="math display">\[
x_{i,k} | \theta_{i,k} \sim N(\theta_{i,k}, \sigma^2_{k})
\]</span></p>
<p>In the likelihood equation above, <span class="math inline">\(\sigma^2_{k}\)</span> is a hyper-parameter that controls the level of smoothness.The Bayesian smoothing estimates the value of <span class="math inline">\(\theta _{i,k}\)</span> conditioned by the data <span class="math inline">\(x_{i,k}\)</span>. This is the updated value of the logit of class probability for class <span class="math inline">\(k\)</span> of pixel <span class="math inline">\(i\)</span>. Since both the prior and the likelihood are assumed as Gaussian distribution, based on Bayesian statistics the value of conditional mean for a normal distribution is given by:
<span class="math display">\[
{E}[\theta_{i,k} | x_{i,k}] =
\frac{m_{i,t} \times \sigma^2_{k} + 
x_{i,k} \times s^2_{i,k}}{ \sigma^2_{k} +s^2_{i,k}} 
\]</span></p>
<p>which can also be expressed as
<span class="math display">\[
    {E}[\theta_{i,k} | x_{i,k}] =
\Biggl [ \frac{s^2_{i,k}}{\sigma^2_{k} +s^2_{i,k}} \Biggr ] \times
x_{i,k} +
\Biggl [ \frac{\sigma^2_{k}}{\sigma^2_{k} +s^2_{i,k}} \Biggr ] \times m_{i,k}
\]</span></p>
<p>The updated value for the class probability of the pixel is a weighted average between the original logit value <span class="math inline">\(x_{i,k}\)</span> and the mean of the class logits <span class="math inline">\(m_{i,k}\)</span> for the neighboring pixels. When the local class variance of the neighbors <span class="math inline">\(s^2_{i,k}\)</span> is high relative to the smoothing factor <span class="math inline">\(\sigma^2_k\)</span>, our confidence on the influence of the neighbors is low, and the smoothing algorithm gives more weight to the original pixel value <span class="math inline">\(x_{i,k}\)</span>. When the local class variance <span class="math inline">\(s^2_{i,k}\)</span> decreases relative to the smoothness factor <span class="math inline">\(\sigma^2_k\)</span>, then our confidence on the influence of the neighborhood increases. The smoothing procedure will be most relevant in situations where the original classification odds ratio is low, showing a low level of separability between classes. In these cases, the updated values of the classes will be influenced by the local class variances.</p>
<p>The hyperparameter <span class="math inline">\(\sigma^2_k\)</span> sets the level of smoothness. If <span class="math inline">\(\sigma^2_k\)</span> is zero, the smoothed value <span class="math inline">\({E}[\mu_{i,,k} | l_{i,k}]\)</span> is equal to the pixel value <span class="math inline">\(l_{i,k}\)</span>. Higher values of <span class="math inline">\(\sigma^2_k\)</span> will cause the assignment of the local mean to the pixel updated probability. In practice, <span class="math inline">\(\sigma^2_k\)</span> is a user-controlled parameter that will be set by users based on their knowledge of the region to be classified. In our case, after some classification tests, we decided to set the parameters <span class="math inline">\(V\)</span> as the Moore neighborhood where each pixel is connected to all those pixels with Chebyshev distance of <span class="math inline">\(1\)</span>, and <span class="math inline">\(\sigma^2_k=20\)</span> for all <span class="math inline">\(k\)</span>. This level of smoothness showed the best performance in the technical validation.</p>
</div>
</div>
<p style="text-align: center;">
<a href="7-1-introduction-1.html"><button class="btn btn-default">Previous</button></a>
<a href="7-3-use-of-bayesian-smoothing-in-sits.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
